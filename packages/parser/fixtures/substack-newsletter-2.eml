Delivered-To: georgeck@gmail.com
Received: by 2002:a2e:2283:0:b0:387:97a:cd6c with SMTP id i125csp1036425lji;
        Fri, 13 Feb 2026 00:31:49 -0800 (PST)
X-Received: by 2002:a05:622a:2c4:b0:501:4cb1:9f3 with SMTP id d75a77b69052e-506a88a8714mr11087301cf.18.1770971509119;
        Fri, 13 Feb 2026 00:31:49 -0800 (PST)
ARC-Seal: i=1; a=rsa-sha256; t=1770971509; cv=none;
        d=google.com; s=arc-20240605;
        b=DDk+HkMp4ez2UZOIHvcVQ44u7kjM1Nb5i1mvkAhiec2RpwrfF6YRRNcsVQxySW7WXk
         WMkrDLGM0JSbtZNQw1HqYFvZ+6wguuYwqb6meWA8n7LAmeELpQ75EafIUuYnxSc8ii7y
         3rmKIdN2Wbvw5JRBdqMzHRaqYEEGHL7fznE6uIEEVPhoK3ZwAxUuGm0KJMPLw9XOMrrf
         AK/buPY4xC0apH3M1zkRPT9aP/UiXCmKMRSERLtgqcU/DGYrenRfgwU3Mw72Rg3tp0d1
         s8Z+1GceU9gw/dEVUIK9wtg7Pzm8436ZIlxoItxWv7Zjt0mB6EMJ/1xEPmLAIWjzbzH1
         rhog==
ARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=google.com; s=arc-20240605;
        h=list-unsubscribe-post:list-unsubscribe:list-post:list-id
         :list-archive:list-url:list-owner:reply-to:in-reply-to:references
         :sender:feedback-id:date:message-id:to:from:subject:mime-version
         :dkim-signature:dkim-signature;
        bh=qnYzkKUhiN7iv6jE6iMBIavCJZkefTbnUrBCE7PHHoo=;
        fh=e9WiNI4uwiTYzQxTrvjfP/ZBG69t50kHUW30fknd5Cg=;
        b=X8A7SqTDbKk5Axcolzdtqhcr1qlLOiVik6i5HmiDwnJZASelze8n/iBqt1esKXHO7l
         y72TcHCpa9mQ+cQuRMCuV/5NKJoMFx42kB4a92GLSOlK7tE2wJu8txpHDchli5+Wv/7c
         YHPels84rCIwx2dGKIjWWd1+phkugtZ5/KrqUFLxloOaJdAx1EXP1EW1Ypku5lo8kT4X
         Zjv8yAYbL5lt0qlCpwUzShwhntwfTyECeefBSPhx9PEZXxlh/eS8DuZMZuVqTnH1GSMG
         uL0IknF6rKPcE88C7T8StflyjhLdFg1F/rUmAdpC06aLNy7DvdhfqYXUONmtd1aFrZ9j
         hRlg==;
        dara=google.com
ARC-Authentication-Results: i=1; mx.google.com;
       dkim=pass header.i=@mg1.substack.com header.s=mailo header.b="U/KhLiQG";
       dkim=pass header.i=@mailgun.org header.s=mg header.b=DeVOgfjL;
       spf=pass (google.com: domain of bounce+43af6d.072c7b-georgeck=gmail.com@mg1.substack.com designates 161.38.195.132 as permitted sender) smtp.mailfrom="bounce+43af6d.072c7b-georgeck=gmail.com@mg1.substack.com";
       dmarc=pass (p=REJECT sp=REJECT dis=NONE) header.from=substack.com
Return-Path: <bounce+43af6d.072c7b-georgeck=gmail.com@mg1.substack.com>
Received: from mg-195-132.substack.com (mg-195-132.substack.com. [161.38.195.132])
        by mx.google.com with UTF8SMTPS id 6a1803df08f44-8971cdf3124si76038686d6.552.2026.02.13.00.31.48
        for <georgeck@gmail.com>
        (version=TLS1_2 cipher=ECDHE-ECDSA-AES128-GCM-SHA256 bits=128/128);
        Fri, 13 Feb 2026 00:31:49 -0800 (PST)
Received-SPF: pass (google.com: domain of bounce+43af6d.072c7b-georgeck=gmail.com@mg1.substack.com designates 161.38.195.132 as permitted sender) client-ip=161.38.195.132;
Authentication-Results: mx.google.com;
       dkim=pass header.i=@mg1.substack.com header.s=mailo header.b="U/KhLiQG";
       dkim=pass header.i=@mailgun.org header.s=mg header.b=DeVOgfjL;
       spf=pass (google.com: domain of bounce+43af6d.072c7b-georgeck=gmail.com@mg1.substack.com designates 161.38.195.132 as permitted sender) smtp.mailfrom="bounce+43af6d.072c7b-georgeck=gmail.com@mg1.substack.com";
       dmarc=pass (p=REJECT sp=REJECT dis=NONE) header.from=substack.com
DKIM-Signature: a=rsa-sha256; v=1; c=relaxed/relaxed; d=mg1.substack.com; q=dns/txt; s=mailo; t=1770971508; x=1770978708;
 h=List-Unsubscribe-Post: List-Unsubscribe: List-Post: List-Id: List-Archive: List-Owner: Reply-To: In-Reply-To: References: Sender: Sender: Date: Message-Id: To: To: From: From: Subject: Subject: Content-Type: Mime-Version: X-Feedback-Id;
 bh=qnYzkKUhiN7iv6jE6iMBIavCJZkefTbnUrBCE7PHHoo=;
 b=U/KhLiQGzFAWdEcTPS6cKYbKlzHLbEdZLaMtg62gm0SPqEqEos5R87vKEi4YXRQdCtSoJCaiU5EeXDW/9QDnULdvV+7vFqWVusPlRPb2yMJ9o1AUoPEi19kjNanGknibPrnOHXzvUMd5X9XLTAiH0F0UODAQ0Og3MOXOc8v6CqQ=
DKIM-Signature: a=rsa-sha256; v=1; c=relaxed/relaxed; d=mailgun.org; q=dns/txt; s=mg; t=1770971508; x=1770978708;
 h=List-Unsubscribe-Post: List-Unsubscribe: List-Post: List-Id: List-Archive: List-Owner: Reply-To: In-Reply-To: References: Sender: Sender: Date: Message-Id: To: To: From: From: Subject: Subject: Content-Type: Mime-Version: X-Feedback-Id;
 bh=qnYzkKUhiN7iv6jE6iMBIavCJZkefTbnUrBCE7PHHoo=;
 b=DeVOgfjLgH9z/bcnp/l1++zBKEEfy8fcHBFvEt7ECnWXoEB1wmAzFiOnSEbDGUPMzAAkfb4CIMKno6tzZalam1GSqGrO4BNz114tup9vp6rOXFw1mMo9zq9wFGU/YhOIqAkV5KSAVTSMJdOquiRSb1ygzzTBgMoO3AC7aH1FbKQ=
X-Mailgun-Sid: WyJkMzZkMiIsImdlb3JnZWNrQGdtYWlsLmNvbSIsIjA3MmM3YiJd
X-Feedback-Id: postmaster@mg1.substack.com:post:5a78a772b6d1e3000132bb09:mailgun
Received: by 17ce24caa72cd685aca0f1e63a01e501bbf402e61a8c6bab863c1cc66d15a3b6 with HTTP
 id 698ee174876aa3fd841d5db3; Fri, 13 Feb 2026 08:31:48 GMT
X-Mailgun-Sending-Ip: 161.38.195.132
X-Mailgun-Batch-Id: 698ee17460fd9fa8d199c249
Mime-Version: 1.0
Content-Type: multipart/alternative;
 boundary="53a1463f4835e6c56d10f4540ea2eec91d48eb51fa39e619ffccc2456a84"
Subject: [AINews] new Gemini 3 Deep Think, Anthropic $30B @ $380B, GPT-5.3-Codex Spark,
 MiniMax M2.5
From: AINews <swyx+ainews@substack.com>
To: georgeck@gmail.com
X-Mailgun-Tag: post
X-Mailgun-Track-Clicks: false
Message-Id: <20260213082919.3.92e0adaee27c9af1@mg1.substack.com>
Date: Fri, 13 Feb 2026 08:29:19 +0000
Feedback-Id: post-187832397:cat-post:pub-1084089:substack
Sender: AINews <swyx+ainews@substack.com>
References: <post-187832397@substack.com>
In-Reply-To: <post-187832397@substack.com>
Reply-To: AINews
 <reply+33twel&bpdnw&&0461ebd08a3341b223fcac1cdb14d2939d5a0ee78fa73af594bb15494659cc21@mg1.substack.com>
List-Owner: <mailto:swyx+ainews@substack.com>
List-Url: <https://www.latent.space/>
List-Archive: <https://www.latent.space/archive>
List-Id: <swyx.substack.com>
List-Post: <https://www.latent.space/p/ainews-new-gemini-3-deep-think-anthropic>
List-Unsubscribe: <https://www.latent.space/action/disable_email/disable?token=eyJ1c2VyX2lkIjoxOTY1OTg4NCwicG9zdF9pZCI6MTg3ODMyMzk3LCJpYXQiOjE3NzA5NzE1MDcsImV4cCI6MTgwMjUwNzUwNywiaXNzIjoicHViLTEwODQwODkiLCJzdWIiOiJkaXNhYmxlX2VtYWlsIn0.58kkx7YlWmLwduJ2w2wYB2iEo_DIVAhstgxl3_vi3A0&all_sections=true>
List-Unsubscribe-Post: List-Unsubscribe=One-Click
X-Mailgun-Variables: {"category": "post", "email_generated_at": "1770971507948", "post_audience":
 "only_paid", "post_id": "187832397", "post_type": "newsletter",
 "pub_community_enabled": "true", "publication_id": "1084089", "subdomain":
 "swyx", "user_id": "19659884"}

--53a1463f4835e6c56d10f4540ea2eec91d48eb51fa39e619ffccc2456a84
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: quoted-printable

View this post on the web at https://www.latent.space/p/ainews-new-gemini-3=
-deep-think-anthropic

China open model week kept going with MiniMax M2.5 claiming [ https://subst=
ack.com/redirect/66ceae9d-e0ad-4efe-8d2e-352891d5db52?j=3DeyJ1IjoiYnBkbncif=
Q.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ] an Opus-matching 80.2% on S=
WE-Bench Verified, however, as often happens on Thursdays, all 3 leading US=
 labs had updates - Anthropic closed their $380B round [ https://substack.c=
om/redirect/26e4e9b0-a1ca-4378-898e-ddb6bc743b34?j=3DeyJ1IjoiYnBkbncifQ.qTv=
oIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ] confirming a historic >10xing of=
 revenue to $14B [ https://substack.com/redirect/c53aab7c-45a1-42e3-bc0a-5c=
c057b3ef08?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8=
x0 ] as of today (remember in August Dario projected $10B [ https://substac=
k.com/redirect/e6a68e4b-163d-4eea-911e-48d76862cab9?j=3DeyJ1IjoiYnBkbncifQ.=
qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ]), with Claude Code=E2=80=99s =
ARR doubling, hitting 2.5B year to date. Not to be outdone, OpenAI rolled o=
ut their answer to Claude=E2=80=99s fast mode [ https://substack.com/redire=
ct/4e06696a-c11f-4d02-813a-efc50e1bfe16?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G=
9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ] (2.5x speedup) with GPT-5.3-Codex-Spark [=
 https://substack.com/redirect/adcc2df5-2c28-41c2-bb58-fe50deac1411?j=3DeyJ=
1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ], which delive=
rs >1000 tok/s (10x speedup), an impressively fast turnaround of the Cerebr=
as deal [ https://substack.com/redirect/b9580800-d03c-41e3-862e-15bca8a22c1=
3?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ].=20
All fantastic news, but we give the title story to the new Gemini 3 Deep Th=
ink today, and Jeff Dean dropped by the studio to give an update on the gen=
eral state of GDM:
This is the same model that scored that IMO Gold last summer [ https://subs=
tack.com/redirect/3e58e186-2205-4bfb-aa46-7942f51735ac?j=3DeyJ1IjoiYnBkbnci=
fQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ], and is simultaneously the=
 #8 best Codeforces programmer in the world [ https://substack.com/redirect=
/6eb55c3f-94e0-413a-89e3-e4f5ac510558?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9T=
d34CeFwYb7BfAOkO-PNiz7RTdD8x0 ] and helping new semiconductor research [ ht=
tps://substack.com/redirect/540a1b61-9b07-42f8-9d13-55072401679d?j=3DeyJ1Ij=
oiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ], but perhaps mos=
t impressive is that it reaches new SOTA levels (eg on ARC-AGI-2 [ https://=
substack.com/redirect/7e63172a-4bac-46f0-81e7-88d972cad408?j=3DeyJ1IjoiYnBk=
bncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ]) while also being very=
 efficient [ https://substack.com/redirect/73f4dd58-c46c-43c0-83d4-bbd45b23=
fbb4?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ] -=
 82% cheaper per task - something Jeff was very excited about in his pod.
AI Twitter Recap
Google DeepMind=E2=80=99s Gemini 3 Deep Think V2: benchmark jump + =E2=80=
=9Cscience/engineering reasoning mode=E2=80=9D shipping to users
Deep Think V2 rollout + access paths: Google is shipping an upgraded Gemini=
 3 Deep Think reasoning mode to Google AI Ultra subscribers in the Gemini a=
pp, and opening a Vertex AI / Gemini API early access program for select re=
searchers/enterprises (GoogleDeepMind [ https://substack.com/redirect/094a7=
ff1-4460-4f1e-b211-5f4e50be8f42?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeF=
wYb7BfAOkO-PNiz7RTdD8x0 ], Google [ https://substack.com/redirect/bcecc62c-=
6fdf-4ec7-8dc9-5ca9d59c4b93?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7=
BfAOkO-PNiz7RTdD8x0 ], GeminiApp [ https://substack.com/redirect/22b0310e-5=
508-4d03-9091-4a795c8a02ad?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7B=
fAOkO-PNiz7RTdD8x0 ], tulseedoshi [ https://substack.com/redirect/8b35ec2a-=
b2a3-4f7a-9d3e-59ed7ca73c09?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7=
BfAOkO-PNiz7RTdD8x0 ]). Multiple Googlers emphasized this is meant to be a =
productized test-time compute heavy mode rather than a lab-only demo (Oriol=
VinyalsML [ https://substack.com/redirect/d57b6dce-66dd-48d0-9c31-5fd47255a=
059?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ], J=
effDean [ https://substack.com/redirect/b3c65e4e-08e7-4648-b0b6-7361e3097f1=
5?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ], dem=
ishassabis [ https://substack.com/redirect/744215ea-28f3-4395-a568-db495ce3=
e471?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ], =
sundarpichai [ https://substack.com/redirect/150eedc9-c9e4-4e2b-a0ad-c6da10=
7534eb?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ]=
).
Key reported numbers (and what=E2=80=99s notable about them):
ARC-AGI-2: 84.6% (promoted as new SOTA; independently certified/verified by=
 the ARC community) (Google [ https://substack.com/redirect/21924c2a-f267-4=
99a-adf9-600d6b408343?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO=
-PNiz7RTdD8x0 ], arcprize [ https://substack.com/redirect/ed7664c6-e972-4cf=
2-894f-9cd2e93a08f0?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-P=
Niz7RTdD8x0 ], fchollet [ https://substack.com/redirect/3cd5393c-8a6f-4849-=
b09b-96418c4659e2?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNi=
z7RTdD8x0 ], scaling01 [ https://substack.com/redirect/ef87ab1c-e0f5-4740-8=
6ac-f6ea2b4dac18?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz=
7RTdD8x0 ]).
Humanity=E2=80=99s Last Exam (HLE): 48.4% without tools (sundarpichai [ htt=
ps://substack.com/redirect/150eedc9-c9e4-4e2b-a0ad-c6da107534eb?j=3DeyJ1Ijo=
iYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ], _philschmid [ ht=
tps://substack.com/redirect/b8d22fa0-77dc-4baa-b914-af1011c06bd1?j=3DeyJ1Ij=
oiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ], JeffDean [ http=
s://substack.com/redirect/b3c65e4e-08e7-4648-b0b6-7361e3097f15?j=3DeyJ1Ijoi=
YnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ]).
Codeforces Elo: 3455 (framed as =E2=80=9Conly ~7 humans=E2=80=9D above it; =
discussion about =E2=80=9Cno tools=E2=80=9D conditions and what that implie=
s for evaluation) (scaling01 [ https://substack.com/redirect/6a42c71c-a671-=
4e92-8217-992511fce5e0?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOk=
O-PNiz7RTdD8x0 ], YouJiacheng [ https://substack.com/redirect/a960b21c-1fca=
-4784-9319-2426c20075eb?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAO=
kO-PNiz7RTdD8x0 ], DeryaTR_ [ https://substack.com/redirect/8cc3fc3c-5e3a-4=
210-b022-1b3c8e7301b4?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO=
-PNiz7RTdD8x0 ]).
Olympiad-level written performance in Physics/Chemistry (and references to =
IMO/ICPC history) (Google [ https://substack.com/redirect/27977b47-58a6-454=
1-be0e-0361c71d5310?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-P=
Niz7RTdD8x0 ], NoamShazeer [ https://substack.com/redirect/d3334c9b-f926-41=
4e-9fc9-6903fb6a14bd?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-=
PNiz7RTdD8x0 ], demishassabis [ https://substack.com/redirect/744215ea-28f3=
-4395-a568-db495ce3e471?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAO=
kO-PNiz7RTdD8x0 ], _philschmid [ https://substack.com/redirect/b8d22fa0-77d=
c-4baa-b914-af1011c06bd1?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfA=
OkO-PNiz7RTdD8x0 ]).
Cost disclosures for ARC: ARC Prize posted semi-private eval pricing like $=
13.62/task for ARC-AGI-2 and $7.17/task for ARC-AGI-1 (arcprize [ https://s=
ubstack.com/redirect/ed7664c6-e972-4cf2-894f-9cd2e93a08f0?j=3DeyJ1IjoiYnBkb=
ncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ]).
Real-world =E2=80=9Cengineering=E2=80=9D demos and claimed impact: Several =
posts push the message that Deep Think=E2=80=99s value is in practical scie=
ntific/engineering workflows: finding errors in math papers, modeling physi=
cal systems in code, optimizing semiconductor crystal growth, and even a sk=
etch =E2=86=92 CAD/STL pipeline for 3D printing (e.g., laptop stand and tur=
bine-blade-esque components) (Google [ https://substack.com/redirect/93aea5=
4d-26cf-4da0-8cec-a613997d414e?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFw=
Yb7BfAOkO-PNiz7RTdD8x0 ], Google [ https://substack.com/redirect/bb186bc4-5=
b6e-423e-98b9-40c295486187?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7B=
fAOkO-PNiz7RTdD8x0 ], Google [ https://substack.com/redirect/04e896db-d9d6-=
44f7-a74e-aca548f1916d?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOk=
O-PNiz7RTdD8x0 ], GeminiApp [ https://substack.com/redirect/22b0310e-5508-4=
d03-9091-4a795c8a02ad?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO=
-PNiz7RTdD8x0 ], joshwoodward [ https://substack.com/redirect/fd5d8fee-f470=
-4688-abd2-5be24e6e2d26?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAO=
kO-PNiz7RTdD8x0 ], tulseedoshi [ https://substack.com/redirect/2ebe7534-de4=
4-49be-8c3e-7ce9159712bd?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfA=
OkO-PNiz7RTdD8x0 ], OriolVinyalsML [ https://substack.com/redirect/15c4c866=
-3c7d-486d-bb3e-2f671bed28f9?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb=
7BfAOkO-PNiz7RTdD8x0 ]).
ARC context / what =E2=80=9Csaturating ARC=E2=80=9D means: Fran=C3=A7ois Ch=
ollet (ARC=E2=80=99s creator) both celebrated certification and later reite=
rated that ARC=E2=80=99s purpose is to steer research toward test-time adap=
tation / fluid intelligence, not to =E2=80=9Cprove AGI=E2=80=9D (fchollet [=
 https://substack.com/redirect/3cd5393c-8a6f-4849-b09b-96418c4659e2?j=3DeyJ=
1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ], fchollet [ h=
ttps://substack.com/redirect/580a499c-6713-4f12-9428-d89a8a670ecf?j=3DeyJ1I=
joiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ]). In a separate=
 thread he defines =E2=80=9CAGI=E2=80=9D as the end of the human=E2=80=93AI=
 gap and argues benchmarks must evolve until humans can no longer propose t=
asks where they outperform AI, with a rough expectation of ~2030 for that s=
tate (fchollet [ https://substack.com/redirect/d64f66b8-8326-43cc-b887-f2eb=
af4f82ee?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0=
 ], fchollet [ https://substack.com/redirect/fd6dfd6a-29ef-4fa6-94c8-6b5cb5=
57762f?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ]=
).
Open coding/agent models shipping fast: MiniMax M2.5 + Zhipu=E2=80=99s GLM-=
5 battle for =E2=80=9Cbest open agentic coder=E2=80=9D
MiniMax M2.5: distribution + positioning: MiniMax=E2=80=99s new model is pu=
shed as an =E2=80=9Cagent-verse / long-horizon agent=E2=80=9D model, rapidl=
y appearing across aggregators and tools: OpenRouter (OpenRouterAI [ https:=
//substack.com/redirect/ee7579d0-024e-41a3-b060-da4293630b0a?j=3DeyJ1IjoiYn=
BkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ]), Arena (arena [ htt=
ps://substack.com/redirect/5931b9d0-7c07-495d-b3f5-73684250b6bd?j=3DeyJ1Ijo=
iYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ]), IDE/agents like=
 Cline (cline [ https://substack.com/redirect/6b0f79e7-7bb2-46c4-9e88-65766=
25ac522?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 =
]), Ollama cloud free promo (ollama [ https://substack.com/redirect/2ab64e6=
e-e4a2-44db-9126-22737e6f1bf5?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwY=
b7BfAOkO-PNiz7RTdD8x0 ]), Eigent agent scaffolds (Eigent_AI [ https://subst=
ack.com/redirect/7b3e11b4-4007-4e8d-9f07-fe8dd19656a8?j=3DeyJ1IjoiYnBkbncif=
Q.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ]), Qoder (qoder_ai_ide [ htt=
ps://substack.com/redirect/be423a22-27e4-42bb-a270-9da88fc6e438?j=3DeyJ1Ijo=
iYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ]), and Blackbox AI=
 (blackboxai [ https://substack.com/redirect/89f288ae-f24b-4234-9c67-a46384=
2f4258?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ]=
).
Benchmarks cited in the thread include claims like 80.2% SWE-Bench Verified=
 and strong performance vs closed models in coding settings; multiple tweet=
s stress throughput + cost as differentiators (e.g., 100 tokens/s and $0.06=
/M blended with caching are cited by Cline) (cline [ https://substack.com/r=
edirect/6b0f79e7-7bb2-46c4-9e88-6576625ac522?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDj=
k3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ], cline [ https://substack.com/redire=
ct/8522563d-fc03-45b8-b22b-4dde87bd1f22?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G=
9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ], guohao_li [ https://substack.com/redirec=
t/e2a92a9e-edef-4bb6-97df-b50409525668?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9=
Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ], shydev69 [ https://substack.com/redirect/=
f4c3a9a8-1e4c-4ebf-9312-d3d2e456c4b9?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td=
34CeFwYb7BfAOkO-PNiz7RTdD8x0 ]). Community vibe checks (e.g., Neubig) claim=
 it=E2=80=99s one of the first open-ish coding models he=E2=80=99d seriousl=
y consider switching to for daily work (gneubig [ https://substack.com/redi=
rect/e8fdf156-d4fc-4819-99e4-39409633d814?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U=
3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ]).
GLM-5: model scale + infra hints + =E2=80=9Copen model leaderboards=E2=80=
=9D:
Tooling ecosystem reports: GLM-5 is used on YouWare with a 200K context win=
dow for web projects (YouWareAI [ https://substack.com/redirect/cdd34771-39=
a9-40ff-bb7d-42c74ee8bdbe?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7Bf=
AOkO-PNiz7RTdD8x0 ]); one user reports ~14 tps on OpenRouter (scaling01 [ h=
ttps://substack.com/redirect/e5ce207e-cfbd-4a4e-8dde-a909d976db58?j=3DeyJ1I=
joiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ]).
A more detailed (but still third-party) technical summary claims GLM-5 is 7=
44B params with ~40B active, trained on 28.5T tokens, integrates DeepSeek S=
parse Attention, and uses =E2=80=9CSlime=E2=80=9D asynchronous RL infra to =
increase post-training iteration speed (cline [ https://substack.com/redire=
ct/d4d39695-81e9-4023-8130-4953ca4d9a15?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G=
9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ]). Another tweet nitpicks terminology conf=
usion around attention components (eliebakouch [ https://substack.com/redir=
ect/2f97be80-7ada-4864-94f9-b414b4ee1a02?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3=
G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ]).
Local inference datapoint: awnihannun reports running GLM-5 via mlx-lm on a=
 512GB M3 Ultra, generating a small game at ~15.4 tok/s using ~419GB memory=
 (awnihannun [ https://substack.com/redirect/8e884019-6415-49d6-a0d6-3b3072=
162720?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ]=
).
Arena signal: the Arena account says GLM-5 is #1 open model in Code Arena (=
tied with Kimi) and overall #6, still ~100+ points behind Claude Opus 4.6 o=
n =E2=80=9Cagentic webdev=E2=80=9D tasks (arena [ https://substack.com/redi=
rect/492b8af8-1aef-410b-a22c-23c11c7db898?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U=
3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ]).
A long Chinese-language-style analysis reposted via ZhihuFrontier argues GL=
M-5 improves hallucination control and programming fundamentals but is more=
 verbose/=E2=80=9Coverthinks,=E2=80=9D suggesting compute constraints (conc=
urrency limits) show through (ZhihuFrontier [ https://substack.com/redirect=
/20e5efa2-0607-4d60-ae14-57aea80f5b57?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9T=
d34CeFwYb7BfAOkO-PNiz7RTdD8x0 ]).
OpenAI=E2=80=99s GPT-5.3-Codex-Spark: ultra-low-latency coding via Cerebras=
 (and why UX becomes the bottleneck)
Product announcement: OpenAI released GPT-5.3-Codex-Spark as a =E2=80=9Cres=
earch preview=E2=80=9D for ChatGPT Pro users in the Codex app/CLI/IDE exten=
sion (OpenAI [ https://substack.com/redirect/81549586-2231-4d26-b03d-c3bf93=
68f408?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ]=
, OpenAIDevs [ https://substack.com/redirect/761f86ff-29bf-42bb-9c60-25adcc=
14a7f6?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ]=
). It=E2=80=99s explicitly framed as the first milestone in a partnership w=
ith Cerebras (also touted by Cerebras) (cerebras [ https://substack.com/red=
irect/4f9ae689-09f9-4599-bb4b-f32356709780?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3=
U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ]).
Performance envelope:
The headline is =E2=80=9C1000+ tokens per second=E2=80=9D and =E2=80=9Cnear=
-instant=E2=80=9D interaction (OpenAIDevs [ https://substack.com/redirect/7=
61f86ff-29bf-42bb-9c60-25adcc14a7f6?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td3=
4CeFwYb7BfAOkO-PNiz7RTdD8x0 ], sama [ https://substack.com/redirect/4e530c8=
e-7f73-48aa-bdc3-647b1796aae5?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwY=
b7BfAOkO-PNiz7RTdD8x0 ], kevinweil [ https://substack.com/redirect/d3e7da2b=
-bc0e-462d-8bdd-ab985e0a4e92?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb=
7BfAOkO-PNiz7RTdD8x0 ], gdb [ https://substack.com/redirect/31c9ff56-338b-4=
737-a2b6-b7fff094e6de?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO=
-PNiz7RTdD8x0 ]).
Initial capability details: text-only, 128k context, with plans for larger/=
longer/multimodal as infra capacity expands (OpenAIDevs [ https://substack.=
com/redirect/796c20ec-9341-42c5-9f50-eb281a1b641f?j=3DeyJ1IjoiYnBkbncifQ.qT=
voIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ]).
Anecdotal reviews highlight a new bottleneck: humans can=E2=80=99t read/val=
idate/steer as fast as the model can produce code, implying tooling/UX must=
 evolve (better diffs, task decomposition, guardrails, =E2=80=9Cagent inbox=
es,=E2=80=9D etc.) (danshipper [ https://substack.com/redirect/37b87397-aff=
b-4422-aff9-0012ae499db4?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfA=
OkO-PNiz7RTdD8x0 ], skirano [ https://substack.com/redirect/da2e5c3b-aea9-4=
878-8242-1c6d5ae05c15?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO=
-PNiz7RTdD8x0 ]).
Model size speculation: There are community attempts to back-calculate size=
 from throughput vs other MoEs; one estimate suggests ~30B active and perha=
ps 300B=E2=80=93700B total parameters (scaling01 [ https://substack.com/red=
irect/005faeac-2b1f-46c2-ab99-fc2307e9adf3?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3=
U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ]). Treat this as informed speculation, =
not an official disclosure.
Adoption/availability: Sam Altman later says Spark is rolling to Pro; OpenA=
I DevRel notes limited API early access for a small group (sama [ https://s=
ubstack.com/redirect/4e530c8e-7f73-48aa-bdc3-647b1796aae5?j=3DeyJ1IjoiYnBkb=
ncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ], OpenAIDevs [ https://s=
ubstack.com/redirect/1947d476-b771-40aa-9fae-42269bf9485b?j=3DeyJ1IjoiYnBkb=
ncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ]). There are also =E2=80=
=9CSpark now with 100% of pro users=E2=80=9D type rollout notes with infra =
instability caveats (thsottiaux [ https://substack.com/redirect/b20f5030-1e=
11-46bf-941f-cee142c509b3?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7Bf=
AOkO-PNiz7RTdD8x0 ]).
Agent frameworks & infra: long-running agents, protocol standardization, an=
d KV-cache as the new scaling wall
A2A protocol as =E2=80=9Cagent interoperability layer=E2=80=9D: Andrew Ng p=
romoted a new DeepLearning.AI course on Agent2Agent (A2A), positioning it a=
s a standard for discovery/communication across agent frameworks, mentionin=
g IBM=E2=80=99s ACP joining forces with A2A and integration patterns across=
 Google ADK, LangGraph, MCP, and deployment via IBM=E2=80=99s Agent Stack (=
AndrewYNg [ https://substack.com/redirect/ddaf2c2c-a9e4-4a84-8745-1a4004f10=
eb4?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ]).
Long-running agent harnesses are becoming product features:
Cursor launched long-running agents and explicitly ties it to a =E2=80=9Cne=
w harness=E2=80=9D that can complete larger tasks (cursor_ai [ https://subs=
tack.com/redirect/21a43324-6704-4f71-9cf8-90444f8006c4?j=3DeyJ1IjoiYnBkbnci=
fQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ]).
LangChain folks discuss =E2=80=9Charness engineering=E2=80=9D research: for=
cing self-verification/iteration, automated context prefetch, and reflectio=
n over traces as levers that change outcomes materially (Vtrivedy10 [ https=
://substack.com/redirect/3c3e5cb5-7581-4823-b23f-de43028f8b04?j=3DeyJ1IjoiY=
nBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ]).
Deepagents added bring-your-own sandboxes (Modal/Daytona/Runloop) for safe =
code execution contexts (sydneyrunkle [ https://substack.com/redirect/55b17=
55f-1c36-4742-846a-943177ada6b7?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeF=
wYb7BfAOkO-PNiz7RTdD8x0 ]).
Serving bottlenecks: KV cache & disaggregation:
PyTorch welcomed Mooncake into the ecosystem, describing it as targeting th=
e =E2=80=9Cmemory wall=E2=80=9D in LLM serving with KVCache transfer/storag=
e, enabling prefill/decode disaggregation, global cache reuse, elastic expe=
rt parallelism, and serving as a fault-tolerant distributed backend compati=
ble with SGLang, vLLM, TensorRT-LLM (PyTorch [ https://substack.com/redirec=
t/95ab5022-3d2a-490b-8bca-51dbc2a05a5d?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9=
Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ]).
Moonshot/Kimi highlighted Mooncake=E2=80=99s origins (Kimi + Tsinghua) and =
open-source trajectory (Kimi_Moonshot [ https://substack.com/redirect/5c208=
cb8-0efa-4c9a-be57-b8b0a164aa4f?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeF=
wYb7BfAOkO-PNiz7RTdD8x0 ]).
A surprisingly common theme: =E2=80=9Cfiles as queues=E2=80=9D: A viral thr=
ead describes a reliable distributed job queue using object storage + a que=
ue.json (FIFO, at-least-once) as a minimalist primitive (turbopuffer [ http=
s://substack.com/redirect/98e38228-35c5-4188-b422-83473a4d2042?j=3DeyJ1Ijoi=
YnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ]). Another tweet cl=
aims Claude Code =E2=80=9Cagent teams=E2=80=9D communicate by writing JSON =
files on disk, emphasizing =E2=80=9Cno Redis required=E2=80=9D CLI ergonomi=
cs (peter6759 [ https://substack.com/redirect/9e37b11d-6be6-4d41-a7be-0a352=
540a59b?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 =
]).
Research notes: small theorem provers + label-free vision training + RL alg=
orithms for verifiable reasoning
QED-Nano: 4B theorem proving with heavy test-time compute: A set of tweets =
introduces QED-Nano, a 4B natural-language theorem-proving model that match=
es larger systems on IMO-ProofBench and uses an agent scaffold scaling to >=
1M tokens per proof, with RL post-training =E2=80=9Crubrics as rewards.=E2=
=80=9D They promise open-source weights and training artifacts soon ( _lewt=
un [ https://substack.com/redirect/ad8e4d27-8b5a-4135-8582-d3dcc7fec2d1?j=
=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ], _lewtu=
n [ https://substack.com/redirect/14ccc588-3c86-4311-9327-8619d9b8df66?j=3D=
eyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ], setlur_am=
rith [ https://substack.com/redirect/5a26fe31-6d14-42fe-94c9-e87f78dedef6?j=
=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ], aviral=
_kumar2 [ https://substack.com/redirect/a887dee1-5e74-48b3-9768-e5e685a3a9c=
a?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ]).
LeJEPA: simplifying self-supervised vision: NYU Data Science highlights LeJ=
EPA (Yann LeCun + collaborators) as a simpler label-free training method th=
at drops many tricks but scales well and performs competitively on ImageNet=
 (NYUDataScience [ https://substack.com/redirect/528905b8-ab24-4f3b-8eb1-2d=
99c76418d9?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8=
x0 ]).
Recursive/agentic evaluation discourse: Multiple tweets debate recursive la=
nguage models (RLMs) and stateful REPL loops as a way to manage long-horizo=
n tasks outside the context window (lateinteraction [ https://substack.com/=
redirect/d114d27d-6972-42ee-94c6-4e4b0b122119?j=3DeyJ1IjoiYnBkbncifQ.qTvoID=
jk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ], deepfates [ https://substack.com/r=
edirect/7f444708-42a0-427c-a97a-3de8112ef9d9?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDj=
k3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ], lateinteraction [ https://substack.=
com/redirect/2789b609-af00-4316-b0e4-ac02cb262199?j=3DeyJ1IjoiYnBkbncifQ.qT=
voIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ]).
Top tweets (by engagement)
Gemini 3 Deep Think upgrade + sketch=E2=86=92STL demo: @GeminiApp [ https:/=
/substack.com/redirect/22b0310e-5508-4d03-9091-4a795c8a02ad?j=3DeyJ1IjoiYnB=
kbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ]
OpenAI Codex-Spark announcement: @OpenAI [ https://substack.com/redirect/81=
549586-2231-4d26-b03d-c3bf9368f408?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34=
CeFwYb7BfAOkO-PNiz7RTdD8x0 ], @OpenAIDevs [ https://substack.com/redirect/7=
61f86ff-29bf-42bb-9c60-25adcc14a7f6?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td3=
4CeFwYb7BfAOkO-PNiz7RTdD8x0 ], @sama [ https://substack.com/redirect/4e530c=
8e-7f73-48aa-bdc3-647b1796aae5?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFw=
Yb7BfAOkO-PNiz7RTdD8x0 ]
Anthropic funding/valuation: @AnthropicAI [ https://substack.com/redirect/4=
ec93e36-d831-4187-9ded-899a74a246f1?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td3=
4CeFwYb7BfAOkO-PNiz7RTdD8x0 ]
Gemini Deep Think =E2=80=9Cunprecedented 84.6% ARC-AGI-2=E2=80=9D: @sundarp=
ichai [ https://substack.com/redirect/150eedc9-c9e4-4e2b-a0ad-c6da107534eb?=
j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ]
Simile launch + $100M raise; simulation framing: @joon_s_pk [ https://subst=
ack.com/redirect/fcf7270e-251d-4c45-9f0e-dddd42082f28?j=3DeyJ1IjoiYnBkbncif=
Q.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ], @karpathy [ https://substa=
ck.com/redirect/82bdbf26-dbd6-4eeb-a07b-999e417b2618?j=3DeyJ1IjoiYnBkbncifQ=
=2EqTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ]
AI Reddit Recap
/r/LocalLlama + /r/localLLM Recap
1. GLM-5 Model Launch and Benchmarks
Unsloth just unleashed Glm 5! GGUF NOW! [ https://substack.com/redirect/e67=
b72b4-ac0e-4f07-b325-799a940d177f?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34C=
eFwYb7BfAOkO-PNiz7RTdD8x0 ] (Activity: 446): The image presents a benchmark=
 comparison table for various AI models, highlighting the performance of GL=
M-5 against other models like GLM-4.7, DeepSeek-V3.2, Kimi K2.5, Claude Opu=
s 4.5, Gemini 3.0 Pro, and GPT-5.2. The table categorizes performance into =
areas such as Reasoning, Coding, and General Agent, with GLM-5 showing part=
icularly strong results in the Reasoning category. Additionally, the table =
provides a cost comparison, suggesting that GLM-5 offers competitive perfor=
mance at a potentially lower cost. One comment humorously suggests the need=
 for a data center to run these models, indicating the high computational r=
equirements. Another comment questions the feasibility of running the model=
 on a low-end GPU like the GT 710, highlighting concerns about accessibilit=
y and hardware demands.
A user inquired whether the new Glm 5 model requires any implementation cha=
nges in llama.cpp, suggesting that the model might be compatible without ad=
ditional modifications. This could imply ease of integration for developers=
 already using llama.cpp for other models.
Another user humorously questioned if the Glm 5 model could run on a GT 710=
 graphics card, which is known for its limited computational power. This hi=
ghlights the potential hardware requirements and limitations for running su=
ch advanced models, suggesting that more powerful GPUs might be necessary.
The release of Glm 5 in GGUF format suggests a focus on optimized performan=
ce and compatibility. GGUF, being a format designed for efficient model sto=
rage and execution, indicates that Glm 5 might offer improved performance m=
etrics or reduced resource consumption compared to previous versions.
GLM-5 scores 50 on the Intelligence Index and is the new open weights leade=
r! [ https://substack.com/redirect/7b235842-d99f-4411-9c41-df14cf888d26?j=
=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ] (Activi=
ty: 892): The image highlights the performance of GLM-5, which scores 50 on=
 the Intelligence Index, positioning it as the leading model among open wei=
ghts. This is significant as it surpasses other models like Opus 4.5 and GP=
T-5.2-xhigh, indicating a strong performance in AI evaluations. Notably, GL=
M-5 also has the lowest hallucination rate on the AA-Omniscience benchmark,=
 showcasing its accuracy and reliability in generating outputs. The discuss=
ion suggests that open-source models are closing the gap with proprietary o=
nes, with upcoming models like Deepseek-V4 expected to use similar architec=
tures but on a larger scale. Commenters note the narrowing performance gap =
between open-source and closed-source models, with some anticipating furthe=
r advancements in open-source AI capabilities.
GLM-5 is noted for having the lowest hallucination rate on the AA-Omniscien=
ce benchmark, which is a significant achievement in reducing errors in AI-g=
enerated content. This positions GLM-5 as a leader in accuracy among open-w=
eight models, surpassing models like Opus 4.5 and GPT-5.2-xhigh.
The open-source AI community is rapidly closing the gap with closed-source =
models, now trailing by only about three months. This is evidenced by the u=
pcoming release of DeepSeek v4, which will utilize the same DSA architectur=
e as GLM-5 but on a larger scale, indicating a trend towards more powerful =
open-source models.
There is a desire within the community for transparency regarding the hardw=
are requirements of these advanced models, as expressed by users who wish f=
or detailed specifications, such as memory requirements, to be published al=
ongside model announcements.
2. MiniMax M2.5 Release and Discussion
MiniMaxAI MiniMax-M2.5 has 230b parameters and 10b active parameters [ http=
s://substack.com/redirect/6ce05a26-18af-434a-9fc9-3c303b504a67?j=3DeyJ1Ijoi=
YnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ] (Activity: 436): O=
penHands has announced the MiniMax-M2.5 model, which features 230 billion p=
arameters with 10 billion active parameters. This model is noted for its co=
mpetitive performance, ranking fourth in the OpenHands Index, and is signif=
icantly cost-effective, being 13 times cheaper than Claude Opus. It excels =
in software engineering tasks, particularly in app development and issue re=
solution, but has room for improvement in generalization tasks. The model i=
s accessible for free on the OpenHands Cloud for a limited time, enhancing =
its accessibility for developers. Commenters are optimistic about the poten=
tial of the MiniMax-M2.5 model, with suggestions to integrate it with Cereb=
ras technology for enhanced performance and efficiency, particularly for us=
ers with 128GB machines.
Look_0ver_There discusses the potential for a hybrid model using the MiniMa=
x-M2.5=E2=80=99s architecture, suggesting that a ~160B REAP/REAM hybrid cou=
ld be developed with minimal performance loss. They propose that such a mod=
el could be quantized to run efficiently on 128GB machines, allowing for de=
ep-context tool use, which would be beneficial for users with limited hardw=
are resources.
Rascazzione highlights the achievement of the MiniMax-M2.5 model, noting it=
s efficiency compared to other models like GLM, which required doubling its=
 parameters to evolve, and Kimi, which has 1T parameters. They emphasize th=
at if the quality and size of MiniMax-M2.5 are confirmed, it represents a s=
ignificant advancement in AI model development.
eviloni points out that with only 10b active parameters, the MiniMax-M2.5 s=
hould achieve decent speed even on non-high-end GPUs. They suggest that thi=
s performance could improve further with quantized versions, making the mod=
el more accessible to users without cutting-edge hardware.
Minimax M2.5 Officially Out [ https://substack.com/redirect/5a19e178-e650-4=
b7d-acb8-49890907152b?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO=
-PNiz7RTdD8x0 ] (Activity: 664): Minimax M2.5 has been officially released,=
 showcasing impressive benchmark results: SWE-Bench Verified at 80.2%, Mult=
i-SWE-Bench at 51.3%, and BrowseComp at 76.3%. The model is noted for its c=
ost efficiency, with operational costs significantly lower than competitors=
 like Opus, Gemini 3 Pro, and GPT-5. At 100 output tokens per second, the c=
ost is $1 per hour, and at 50 TPS, it drops to $0.3, allowing for four inst=
ances to run continuously for a year at $10,000. More details can be found =
on the official Minimax page [ https://substack.com/redirect/dfab3953-9d07-=
417d-808e-e437f231876a?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOk=
O-PNiz7RTdD8x0 ]. Commenters highlight the potential game-changing nature o=
f Minimax M2.5 due to its cost efficiency compared to other models, and the=
re is anticipation for the release of open weights on platforms like Huggin=
g Face.
The Minimax M2.5 is highlighted for its cost-effectiveness, with operationa=
l costs significantly lower than competitors like Opus, Gemini 3 Pro, and G=
PT-5. Specifically, running M2.5 at 100 tokens per second costs $1 per hour=
, and at 50 tokens per second, it costs $0.3 per hour. This translates to a=
 yearly cost of $10,000 for four instances running continuously, which is a=
 substantial reduction compared to other models.
There is anticipation for the release of open weights on Hugging Face, whic=
h would allow for broader experimentation and integration into various appl=
ications. This is a common expectation in the AI community for new models t=
o facilitate transparency and reproducibility.
The potential impact of Minimax M2.5 on existing models like GLM 5.0 and Ki=
mi 2.5 is discussed, with some users suggesting that if the benchmarks are =
accurate, M2.5 could surpass these models in popularity due to its ease of =
use and cost advantages. This could shift the landscape of preferred local =
models, as users currently favor models like Kimi 2.5 and DeepSeekv3.2.
GLM 5.0 & MiniMax 2.5 Just Dropped, Are We Entering China=E2=80=99s Agent W=
ar Era? [ https://substack.com/redirect/60a6b7fe-9ddb-4dc9-b7cc-ffe31da9ba5=
9?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ] (Act=
ivity: 465): GLM 5.0 and MiniMax 2.5 have been released, marking a shift to=
wards agent-style workflows in AI development. GLM 5.0 focuses on enhanced =
reasoning and coding capabilities, while MiniMax 2.5 is designed for task d=
ecomposition and extended execution times. This evolution suggests a compet=
itive landscape moving from generating better responses to completing compl=
ex tasks. Testing plans include API benchmarks, multi-agent orchestration w=
ith Verdent, IDE workflows similar to Cursor, and infrastructure routing wi=
th ZenMux to evaluate their performance on long-duration tasks and reposito=
ry-level changes. The comments highlight a broader context of AI developmen=
t in China, mentioning other recent releases like Seedance 2.0 and Qwen-ima=
ge 2.0, suggesting a vibrant and competitive AI ecosystem. There=E2=80=99s =
also a sentiment that this competition benefits end-users by driving innova=
tion.
3. AI Model Identity and Community Concerns
Why do we allow =E2=80=9Cun-local=E2=80=9D content [ https://substack.com/r=
edirect/4753aa3b-18b1-4a0a-b436-0fde132b09bc?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDj=
k3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ] (Activity: 466): The post discusses =
the concern of =E2=80=98un-local=E2=80=99 content in a subreddit focused on=
 local AI models, suggesting that posts linking to API resources should als=
o include links to downloadable model weights, such as those on Hugging Fac=
e. The author argues that this would prevent the subreddit from becoming a =
platform for marketing rather than technical discussion. The debate centers=
 on whether posts about models without released weights should be allowed, =
with some agreeing that such posts should be tied back to local relevance, =
even if the models are not immediately available for local use. The discuss=
ion highlights a need for a balance between maintaining the subreddit=E2=80=
=99s focus on local models and allowing discussions on potentially relevant=
 advancements. Commenters generally agree with the need for a framework to =
prioritize =E2=80=98local=E2=80=99 content, but acknowledge the difficulty =
in drawing strict boundaries. Some suggest that posts about models with pen=
ding weight releases should be allowed if they are likely to become relevan=
t to local use. The moderation team emphasizes the importance of staying tr=
ue to the sub=E2=80=99s spirit rather than strictly adhering to its origina=
l intent, to keep the community active and relevant.
The discussion highlights a framework for determining the relevance of post=
s to a local-focused subreddit. It suggests that purely local content, such=
 as running models on specific hardware and benchmarks, should be prioritiz=
ed. However, posts about non-local models or breakthroughs should be allowe=
d if they can be tied back to local implications, such as potential future =
applications or relevance to local models.
A consensus among moderators is mentioned, emphasizing the importance of al=
lowing content that is adjacent or relevant to the local ecosystem. The dis=
cussion acknowledges the difficulty in drawing strict boundaries, as the re=
levance of certain models or announcements can vary. For instance, the anno=
uncement of Minimax M2.5 ahead of its weights release poses a challenge in =
determining its local relevance.
The moderation team has debated the balance between maintaining the subredd=
it=E2=80=99s original focus and adapting to current trends. They argue that=
 strict adherence to the original intent could lead to the subreddit=E2=80=
=99s decline, as seen with the diminishing relevance of models like Llama. =
The focus is on maintaining the spirit of the subreddit rather than strict =
rules, allowing for flexibility in content relevance.
GLM thinks its Gemini [ https://substack.com/redirect/a31797f4-a15c-429e-b6=
eb-40fb6b2906d7?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7=
RTdD8x0 ] (Activity: 354): The image depicts a chat interface where a langu=
age model initially identifies itself as GLM-5 but then corrects itself to =
say it is actually Gemini, a large language model developed by Google. This=
 raises questions about the model=E2=80=99s identity and the potential use =
of Gemini in either distilling GLM or generating synthetic data. The commen=
ts highlight a common issue where users ask language models to identify the=
mselves, which they typically cannot do accurately due to context limitatio=
ns. One comment suggests that the model=E2=80=99s response might be influen=
ced by non-empty context, implying that the model=E2=80=99s identity confus=
ion could be due to prior interactions or prompts.
NoobMLDude raises a technical inquiry about the relationship between GLM an=
d Gemini, questioning whether GLM is distilled from Gemini outputs or if Ge=
mini is used in generating synthetic data. This suggests a curiosity about =
the training processes and data sources involved in developing these models=
, which could impact their performance and capabilities.
Less Technical AI Subreddit Recap
/r/Singularity, /r/Oobabooga, /r/MachineLearning, /r/OpenAI, /r/ClaudeAI, /=
r/StableDiffusion, /r/ChatGPT, /r/ChatGPTCoding, /r/aivideo, /r/aivideo
1. AI Model Launches and Performance Comparisons
Anthropic raises $30B, Elon crashes out [ https://substack.com/redirect/607=
936ac-029a-4642-af2d-9b604e308018?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34C=
eFwYb7BfAOkO-PNiz7RTdD8x0 ] (Activity: 4819): The image is a meme featuring=
 a fictional tweet from Anthropic announcing a $30 billion funding round, v=
aluing the company at $380 billion. This is a satirical take, as such a fun=
ding round and valuation are not real. The tweet humorously suggests that t=
he funds will be used for research, product innovation, and infrastructure =
expansion. Elon Musk is depicted as responding critically, accusing Anthrop=
ic=E2=80=99s AI of being biased and labeling it as =E2=80=98misanthropic an=
d evil,=E2=80=99 which is a play on words with the company=E2=80=99s name. =
This meme is likely a commentary on the competitive and sometimes contentio=
us nature of AI development and funding, as well as Musk=E2=80=99s outspoke=
n views on AI ethics and bias. The comments reflect a mix of confusion and =
humor, with one user questioning a reference to =E2=80=98Name of the Wind,=
=E2=80=99 a fantasy novel, suggesting it is unrelated to the topic. Another=
 comment suggests that Musk=E2=80=99s response is a projection of his own i=
nsecurities, while a third implies jealousy on Musk=E2=80=99s part.
Introducing Simile - The Simulation Company [ https://substack.com/redirect=
/b70ffc7a-525f-4c7c-b706-9f25ec123650?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9T=
d34CeFwYb7BfAOkO-PNiz7RTdD8x0 ] (Activity: 504): Simile has introduced an A=
I-based simulation platform designed to model societal behaviors and predic=
t human actions at scale. The company has developed a foundation model that=
 uses generative agents to simulate real people with high accuracy, allowin=
g organizations to test decisions before implementation. This approach is a=
lready being utilized by companies for applications such as earnings call r=
ehearsals and policy testing. Simile is supported by $100M in funding from =
notable investors including Index Ventures, Andrej Karpathy, and Fei-Fei Li=
=2E Commenters highlight the potenti=
al of Simile=E2=80=99s technology to revo=
lutionize decision-making processes, comparing it to Asimov=E2=80=99s conce=
pt of Psychohistory. The involvement of prominent figures like Karpathy and=
 Fei-Fei Li lends credibility to the project, suggesting it is not merely s=
peculative.
Rare-Site highlights the contrast between the rigorous testing in software =
development, such as A/B testing for UI elements, and the often intuitive d=
ecision-making in economic policies. They emphasize the potential of Simile=
 to revolutionize decision-making by simulating reality, especially with th=
e backing of prominent figures like Karpathy and Fei-Fei Li. This could rep=
resent a significant advancement in AI capabilities.
EmbarrassedRing7806 raises a concern about the competitive landscape, quest=
ioning the ability of Simile to maintain a competitive advantage or =E2=80=
=98moat=E2=80=99. They reference a similar project, Aaru, suggesting that t=
he field of simulation technology might be crowded or rapidly evolving, whi=
ch could impact Simile=E2=80=99s unique positioning.
The_Scout1255 expresses surprise at the emergence of simulation technology =
this year, indicating that the development of such advanced simulation capa=
bilities was unexpected in the current timeline. This suggests a rapid pace=
 of innovation in the field, potentially driven by recent advancements in A=
I and computational power.
Lead product + design at Google AI Studio promises =E2=80=9Csomething even =
better=E2=80=9D than Gemini 3 Pro GA this week [ https://substack.com/redir=
ect/5e12095f-48e7-4ce3-ad2b-4cf5da8c3017?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3=
G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ] (Activity: 626): The image captures a so=
cial media exchange where a lead from Google AI Studio hints at an upcoming=
 release that is expected to surpass the anticipated Gemini 3 Pro GA. This =
suggests that Google may be preparing to unveil a new product or feature th=
at could potentially include advanced capabilities, possibly related to cod=
ing agents, as speculated by users. The discussion reflects a high level of=
 anticipation and excitement within the community for Google=E2=80=99s next=
 move in AI development. One comment suggests that Google needs a product s=
imilar to Codex, as Gemini 3 Pro reportedly lacks effective agentic feature=
s. This indicates a demand for more advanced AI functionalities from Google=
=2E
Impressive-Zebra1505 highlights a critical gap in Google=E2=80=99s AI capab=
ilities, noting that =E2=80=9CGoogle needs something akin to Codex ASAP,=E2=
=80=9D as Gemini 3 Pro struggles with agentic features. This suggests a pot=
ential area for improvement or innovation in Google=E2=80=99s AI offerings,=
 particularly in enhancing the model=E2=80=99s ability to handle tasks auto=
nomously, similar to OpenAI=E2=80=99s Codex.
Hemingbird discusses a New Yorker article that provides an in-depth look at=
 Anthropic and its AI model, Claude. The article is praised for its nuanced=
 understanding of AI, particularly in differentiating next-token prediction=
 from simple autocomplete. It also explores the role of =E2=80=98AI psychon=
auts=E2=80=99 in model interpretability, highlighting the diverse and somet=
imes unconventional approaches to understanding AI behavior.
kvothe5688 speculates that the upcoming announcement from Google AI Studio =
might involve a =E2=80=9Crumoured coding agent.=E2=80=9D This aligns with t=
he broader industry trend of integrating more sophisticated coding capabili=
ties into AI models, potentially addressing the limitations noted in Gemini=
 3 Pro=E2=80=99s current functionalities.
How is this not the biggest news right now? [ https://substack.com/redirect=
/e3d3f6e2-02aa-400b-a6ec-96b2c3db6041?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9T=
d34CeFwYb7BfAOkO-PNiz7RTdD8x0 ] (Activity: 865): Google has developed a mat=
h-specialized version of its AI model, named Aletheia, which has achieved a=
 perfect score on the International Mathematical Olympiad (IMO) and signifi=
cantly outperforms other models on various benchmarks. The image shows Alet=
heia leading the leaderboard with a 91.9% score on the Advanced Proofbench =
and 100% on the IMO 2024 category, far surpassing other models like =E2=80=
=9CGPT-5.2 Thinking (high)=E2=80=9D and =E2=80=9CGemini 3 Pro.=E2=80=9D Thi=
s model is described as a generator-verifier agent, which may not directly =
compare to traditional language models, suggesting a different approach in =
its architecture and capabilities. Some commenters question the significanc=
e of this news, noting that achieving high scores on IMO with sufficient fi=
ne-tuning and resources is possible. Others highlight that Aletheia=E2=80=
=99s architecture as a generator-verifier agent makes it distinct from typi=
cal language models, suggesting that the leaderboard comparison might not b=
e entirely fair.
Alex__007 highlights that both OpenAI and Google achieved gold at the Inter=
national Mathematical Olympiad (IMO) with their models, suggesting that wit=
h sufficient fine-tuning and inference expenditure, such results are achiev=
able. The commenter questions the generalization of these models beyond spe=
cific benchmarks and inquires about the accessibility and cost of using Ale=
theia, indicating a need for more transparency in these areas.
Faintly_glowing_fish points out that the model in question is a generator-v=
erifier agent, which differs from traditional language models. This distinc=
tion implies that comparing its performance on leaderboards with standard l=
anguage models might be misleading, as they serve different purposes and op=
erate under different paradigms.
jjjjbaggg discusses the model=E2=80=99s focus and cost, suggesting it might=
 be an iteration of Gemini Deepthink with extensive scaffold engineering an=
d fine-tuning. They note that scaffold engineering can become obsolete as r=
einforcement learning (RL) techniques evolve, potentially eliminating the n=
eed for such scaffolding in future model generations.
GLM 5 is out now. [ https://substack.com/redirect/f132835e-242d-40e6-bf3e-7=
3db6896588a?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD=
8x0 ] (Activity: 312): The image is a performance evaluation chart comparin=
g several language models, including the newly released GLM-5, against othe=
rs like GLM-4.7, Claude Opus 4.5, Gemini 3 Pro, and GPT-5.2 (xhigh). The ch=
art highlights GLM-5=E2=80=99s strong performance across various benchmarks=
 such as =E2=80=9CSWE-bench Verified=E2=80=9D and =E2=80=9Ct=C2=B2-Bench,=
=E2=80=9D indicating its competitive edge in these categories. The release =
of GLM-5 is emphasized by its highlighted position in the chart, suggesting=
 improvements over its predecessor, GLM-4.7, and competitive performance ag=
ainst other leading models. One commenter criticizes the benchmarks for not=
 reflecting real-life usage, while another highlights the cost-effectivenes=
s and efficiency of models like Oppus 4.6 over GLM-5, suggesting that despi=
te GLM-5=E2=80=99s performance, it may not be as practical for certain task=
s.
SnooTangerines2270 highlights a critical performance issue with GLM 5, noti=
ng that while it may be cost-effective, it often leads to inefficient workf=
lows characterized by repetitive =E2=80=98copy-paste-fix-it=E2=80=99 cycles=
=2E They contrast this with Oppus 4.6,=20=
which they claim offers superior perfo=
rmance by understanding user intent without extensive prompting, thanks to =
its advanced swarm agent capabilities. This suggests that for users priorit=
izing efficiency and time savings, Oppus 4.6 might be a more suitable choic=
e despite its higher cost.
ianxiao criticizes the performance of GLM 5, stating that it operates at =
=E2=80=98unusable token/s=E2=80=99, implying that the model=E2=80=99s proce=
ssing speed is insufficient for practical use. This suggests that despite a=
ny potential improvements or features, the model=E2=80=99s throughput may n=
ot meet the demands of users requiring fast and efficient processing.
stiky21 expresses a preference for Opus and Codex over GLM 5, indicating a =
possible perception of superior performance or reliability in these alterna=
tives. This choice might reflect a broader sentiment among users who priori=
tize established models with proven track records over newer releases that =
may not yet have demonstrated their capabilities in real-world applications=
=2E
Deepseek V4 is coming this week. [ https://substack.com/redirect/a810ebe1-1=
298-4cd0-a77b-ad44669d2237?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7B=
fAOkO-PNiz7RTdD8x0 ] (Activity: 385): Deepseek V4 is anticipated to release=
 by February 17, coinciding with the Chinese New Year. The update reportedl=
y includes the capability to handle 1 million tokens, suggesting a signific=
ant enhancement in processing capacity. This positions Deepseek as a compet=
itive alternative to major models like Opus, Codex, and others, potentially=
 offering similar capabilities at a reduced cost. One commenter highlights =
that Deepseek=E2=80=99s advancements make it a cost-effective alternative t=
o major models, suggesting that China=E2=80=99s development in AI is compet=
itive with global leaders.
A user mentioned that Deepseek has been updated to handle 1M tokens, sugges=
ting a significant increase in its processing capabilities. This could impl=
y improvements in handling larger datasets or more complex queries, which i=
s a notable enhancement for users dealing with extensive data or requiring =
detailed analysis.
Another user reported that after the update, Deepseek provided a highly nua=
nced and original review of a complex piece of character writing. This sugg=
ests improvements in the model=E2=80=99s ability to understand and critique=
 creative content, indicating advancements in its natural language processi=
ng and comprehension abilities.
One comment highlighted a perceived increase in the =E2=80=98personality=E2=
=80=99 of Deepseek=E2=80=99s responses post-update, comparing it to ChatGPT=
=2E This suggests enhancements in th=
e model=E2=80=99s conversational abilitie=
s, potentially making interactions more engaging and human-like.
MiniMax-M2.5 Now First to Go Live on NetMind (Before the Official Launch), =
Free for a Limited Time Only [ https://substack.com/redirect/1f2df1aa-004f-=
4512-9f4e-a6f484cdc26c?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOk=
O-PNiz7RTdD8x0 ] (Activity: 14): MiniMax-M2.5 is now available on the NetMi=
nd platform with first-to-market API access, free for a limited time. This =
model is designed for agents, supporting multilingual programming, complex =
tool-calling chains, and long-horizon planning. It surpasses Claude Opus 4.=
6 on SWE-bench Pro and Verified, making it one of the top models for softwa=
re engineering. It also achieves state-of-the-art scores in Excel manipulat=
ion, deep research, and document summarization. With an output speed of app=
roximately 100 TPS, it is about 3x faster than Opus-class models, and is pr=
iced at $0.3/M input tokens and $1.2/M output tokens, making it suitable fo=
r high-volume, always-on production workloads. A comment notes that despite=
 the announcement, the service is paid, indicating potential user concerns =
about cost despite the initial free access.
2. AI in Medical Diagnosis and Healthcare
This morning ChatGPT talked me out of toughing out a strain in my calf musc=
le and to go get it looked at because it suspected a blood clot. [ https://=
substack.com/redirect/ff11a40f-73c4-4d8e-adb9-8accbb947d94?j=3DeyJ1IjoiYnBk=
bncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ] (Activity: 6516): The =
image and accompanying post highlight a real-life scenario where ChatGPT pl=
ayed a crucial role in prompting a user to seek immediate medical attention=
 for a suspected blood clot. The user initially considered ignoring a calf =
muscle strain, but ChatGPT=E2=80=99s advice led them to discover a life-thr=
eatening condition involving multiple blood clots in the lungs. This incide=
nt underscores the potential of AI tools like ChatGPT in providing timely h=
ealth advice, although it should not replace professional medical consultat=
ion. The comments further illustrate similar experiences where ChatGPT=E2=
=80=99s guidance led to the discovery of serious health issues, emphasizing=
 its utility in preliminary health assessments. Commenters shared similar e=
xperiences where ChatGPT=E2=80=99s advice led to the discovery of serious h=
ealth conditions, such as heart blockages and shingles, highlighting the AI=
=E2=80=99s potential in preliminary health diagnostics.
gpt is goated as a doctor [ https://substack.com/redirect/de676362-3991-460=
b-9d53-c56c4d248ea2?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-P=
Niz7RTdD8x0 ] (Activity: 1219): The post discusses using ChatGPT for medica=
l diagnosis by analyzing lab reports, claiming it accurately identified con=
ditions like Crohn=E2=80=99s disease, fatty liver, and a tumor, suggesting =
follow-up tests that were later confirmed by doctors. This highlights GPT=
=E2=80=99s capability in medical pattern recognition, leveraging its traini=
ng on extensive medical literature to perform sophisticated pattern matchin=
g against documented cases and clinical correlations. It excels in the diff=
erential diagnosis phase, suggesting potential diagnoses and tests, but sho=
uld be used as a diagnostic assistant rather than a replacement for doctors=
=2E Comments emphasize GPT=E2=80=99s role=20=
as a second opinion tool, enhancing=
 patient-doctor interactions by enabling informed discussions. However, cau=
tion is advised as GPT provides confident answers based on pattern matching=
, not true diagnosis. The potential for AI integration in healthcare workfl=
ows is noted, suggesting it could improve diagnostic efficiency and patient=
 outcomes.
BookPast8673 highlights the effectiveness of GPT in medical pattern recogni=
tion due to its training on extensive medical literature and case studies. =
It excels in differential diagnosis by matching symptoms and data points ag=
ainst a vast database of documented cases, which allows it to recall rare c=
onditions and drug interactions quickly. However, it is emphasized that GPT=
 should be used as a diagnostic assistant rather than a replacement, as it =
can suggest tests but cannot interpret the full clinical picture or patient=
 history.
BookPast8673 also discusses the potential for AI integration into healthcar=
e systems, suggesting that AI could act as a co-pilot for doctors by flaggi=
ng potential diagnoses and suggesting follow-up tests in real-time. This in=
tegration could reduce diagnostic delays and unnecessary testing, ultimatel=
y saving time and money while improving patient outcomes. The comment under=
scores the importance of AI as a tool to enhance, rather than replace, huma=
n medical expertise.
3. Gemini 3 Deep Think and ARC-AGI-2 Benchmarks
The new Gemini Deep Think incredible numbers on ARC-AGI-2. [ https://substa=
ck.com/redirect/c3de22e0-1785-4b8a-bdf8-80ff7b79b1b7?j=3DeyJ1IjoiYnBkbncifQ=
=2EqTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7=
RTdD8x0 ] (Activity: 1286): The image=20=
presents a bar graph illustrating the performance of various AI models on t=
he ARC-AGI-2 benchmark, with the Gemini 3 Deep Think model achieving a lead=
ing score of 84.6%. This score significantly surpasses other models like Cl=
aude Opus 4.6 (68.8%), GPT-5.2 (52.9%), and Gemini 3 Pro Preview (31.1%). T=
he Gemini 3 Deep Think=E2=80=99s performance is particularly notable as it =
approaches the threshold for effectively solving the benchmark under the AR=
C Prize criteria [ https://substack.com/redirect/d6540725-e41d-4ad2-90b8-f7=
22ce4d9680?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8=
x0 ]. Additionally, the model=E2=80=99s Codeforces Elo rating of 3455 place=
s it in the top 0.008% of human competitors, highlighting its advanced capa=
bilities in reasoning and knowledge without the use of tools. Commenters ar=
e impressed by the significant performance leap of the Gemini 3 Deep Think =
model, noting its potential breakthrough in AI capabilities. The model=E2=
=80=99s high Codeforces Elo rating is also highlighted as a remarkable achi=
evement, indicating its superior problem-solving skills.
FundusAnimae highlights the significant performance improvement of the Gemi=
ni Deep Think model on the ARC-AGI-2 benchmark, noting that it scores above=
 85%, which is considered effectively solving the benchmark according to th=
e ARC Prize criteria [ https://substack.com/redirect/d6540725-e41d-4ad2-90b=
8-f722ce4d9680?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7R=
TdD8x0 ]. The model=E2=80=99s Codeforces Elo rating of 3455 places it in th=
e top 0.008% of human competitors, which is particularly impressive given t=
hat it achieved this without any tools.
Agreeable_Bike_4764 points out the rapid progress of the ARC-AGI-2 model, n=
oting that it took less than a year to reach a performance level considered=
 as =E2=80=98saturation=E2=80=99 (85% solved) since its release. This sugge=
sts a fast-paced development and improvement cycle in AI model capabilities=
=2E
Google upgraded Gemini-3 DeepThink: Advancing science, research and enginee=
ring [ https://substack.com/redirect/1917a937-5cf7-4969-a850-783001d83e6b?j=
=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ] (Activi=
ty: 674): Google=E2=80=99s Gemini-3 DeepThink has set a new benchmark in AI=
 performance, achieving 48.4% on Humanity=E2=80=99s Last Exam without tools=
, 84.6% on ARC-AGI-2 as verified by the ARC Prize Foundation, and an Elo ra=
ting of 3455 on Codeforces. It also reached gold-medal level performance in=
 the International Math Olympiad 2025. These results highlight its advanced=
 capabilities in reasoning and problem-solving across scientific domains. F=
or more details, see the original article [ https://substack.com/redirect/6=
44fc537-b3be-4eeb-aac0-b4948719369c?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td3=
4CeFwYb7BfAOkO-PNiz7RTdD8x0 ]. A notable debate in the comments revolves ar=
ound the comparison of Gemini-3 DeepThink to GPT 5.2, with some users point=
ing out that the comparison should be made with GPT 5.2 Pro, which is a mor=
e direct competitor.
SerdarCS points out a potential issue with the comparison metrics used by G=
oogle, noting that they are comparing Gemini-3 DeepThink to GPT-5.2 Thinkin=
g instead of GPT-5.2 Pro, which would be a more direct competitor. This sug=
gests a possible bias in the benchmarking process, as the Pro version might=
 offer different performance characteristics that are more aligned with Gem=
ini-3=E2=80=99s capabilities.
brett_baty_is_him inquires about specific benchmarks related to Gemini-3 De=
epThink, particularly focusing on Software Engineering (SWE) benchmarks and=
 long context benchmarks. This indicates a need for detailed performance me=
trics to evaluate the model=E2=80=99s capabilities in handling complex engi=
neering tasks and extended context scenarios, which are critical for assess=
ing its utility in technical applications.
verysecreta expresses confusion over the naming conventions used for Gemini=
-3 DeepThink, comparing it to other models like =E2=80=9CFlash=E2=80=9D and=
 =E2=80=9CPro=E2=80=9D. The comment highlights the ambiguity in distinguish=
ing whether =E2=80=9CDeep Think=E2=80=9D is a separate model or a mode with=
in the existing Gemini framework. This reflects a broader issue in AI model=
 branding and clarity, which can impact user understanding and adoption.
Google Just Dropped Gemini 3 =E2=80=9CDeep Think=E2=80=9D : and its Insane.=
 [ https://substack.com/redirect/e55f3b87-abf4-42f2-8422-85699f4498ac?j=3De=
yJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ] (Activity: =
844): Google has released Gemini 3 =E2=80=98Deep Think=E2=80=99, an advance=
d AI model noted for its exceptional capabilities in reasoning, coding, and=
 science, comparable to Olympiad-level performance. It is already being app=
lied in practical scenarios, such as semiconductor material design at Duke =
University. The model has also achieved a new benchmark by solving PhD-leve=
l math and physics problems, showcasing its potential in academic and resea=
rch settings. Image [ https://substack.com/redirect/17cd3292-7425-43b5-99e3=
-6d7a599db07d?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RT=
dD8x0 ] Some users express concern over the high cost of accessing Gemini 3=
, which is priced at $270 per month with a limit of 10 messages per day, su=
ggesting that its use may be restricted to those who can afford such a prem=
ium service.
TechNerd10191 highlights the restrictive nature of Gemini 3=E2=80=99s prici=
ng model, which costs $270 per month and limits users to 10 messages per da=
y. This is contrasted with ChatGPT Pro, which offers 100+ messages on its 5=
=2E2 Pro version, suggesting a signific=
ant limitation for users who require e=
xtensive interaction with the model.
NervousSWE raises concerns about the practicality of using Gemini 3 for cod=
ing due to the 10 messages a day limit. They speculate on the efficiency of=
 the model, suggesting that if one message with Gemini 3 can achieve what w=
ould take 10 messages with other models, it might still be viable for power=
 users. This highlights a potential strategy for maximizing the limited int=
eractions by focusing on complex, high-value queries.
blondbother compares Gemini 3=E2=80=99s offering with ChatGPT Pro, noting t=
hat the latter provides 100+ messages per day on its 5.2 Pro version. This =
comparison underscores the limitations of Gemini 3=E2=80=99s 10 queries a d=
ay policy, which may deter users who need more frequent access, especially =
when considering the high subscription cost.
AI Discord Recap
A summary of Summaries of Summaries by gpt-5.2
1. GLM-5 Model Release & Ecosystem Momentum
GLM-5 Grabs the Gold (Twice): GLM-5 hit #1 among open models on both the Te=
xt Arena leaderboard [ https://substack.com/redirect/204c66c8-4cec-4a60-b24=
d-720ce82741e9?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7R=
TdD8x0 ] (score 1452, on par with gpt-5.1-high) and the Code Arena leaderbo=
ard [ https://substack.com/redirect/e1793d8e-cac7-43ca-9aa3-590c2e7c1b95?j=
=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ], with A=
rena also pointing to Peter Gostev=E2=80=99s review of GLM-5 and MiniMax-M2=
=2E5 [ https://substack.com/redirect/2=
a1d62fc-da7a-4487-a3ba-f7c36c8e89c6?j=
=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ].
Engineers debated whether GLM-5 tilts more agentic than =E2=80=9Cgeneral as=
sistant=E2=80=9D (similar comparisons to MiniMax), and a separate thread no=
ted chat.deepseek.com [ https://substack.com/redirect/2e8c02fb-b1b4-4fff-98=
9b-7fe80331bb7c?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7=
RTdD8x0 ] =E2=80=9Csilently=E2=80=9D feels different with no official annou=
ncement, sharpening interest in independent evals.
GGUF Goes Brrr: GLM-5 Runs Local: Unsloth shipped GLM-5 GGUFs plus a local =
llama.cpp guide via their post [ https://substack.com/redirect/2e51eaa9-424=
d-40f9-840a-d08ad48d9627?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfA=
OkO-PNiz7RTdD8x0 ] and the weights at unsloth/GLM-5-GGUF [ https://substack=
=2Ecom/redirect/0a2538fa-9caa-40b8-a1f=
0-666975a4702a?j=3DeyJ1IjoiYnBkbncifQ.q=
TvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ].
One user reported 46 t/s with 3=C3=97 Nvidia Blackwell RTX 6000 GPUs, kicki=
ng off practical discussion about real-world throughput and whether GLM-5=
=E2=80=99s tuning targets longer-horizon tool use over chat polish.
2. Agentic Coding: Speed, Long-Running Agents, and New Leaderboards
Codex Spark Lights the Fuse (1000 tok/s): OpenAI launched GPT-5.3-Codex-Spa=
rk in research preview with an official post, =E2=80=9CIntroducing GPT=E2=
=80=915.3 Codex Spark=E2=80=9D [ https://substack.com/redirect/adcc2df5-2c2=
8-41c2-bb58-fe50deac1411?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfA=
OkO-PNiz7RTdD8x0 ], plus a video demo [ https://substack.com/redirect/0da73=
b06-4762-494e-ba28-366eb8242e00?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeF=
wYb7BfAOkO-PNiz7RTdD8x0 ] and example CLI usage like codex -m gpt-5.3-codex=
-spark --yolo -c model_reasoning_effort=3D"xhigh".
Cursor users highlighted Cerebras-backed speed (=E2=80=9Dthe speed is just =
a whole new level!=E2=80=9C), while also stressing that the real shock is f=
ast deployable code changes, not just token throughput.
Cursor Lets Agents Run Wild (=E2=80=A6and Bills TBD): Cursor shipped long-r=
unning agents, and users poked around pricing/limits via dev tools on curso=
r.com/dashboard [ https://substack.com/redirect/5df67ebc-72a9-43b4-978a-fea=
75b5f3bc1?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x=
0 ] while also debating Composer 1.5 pricing (reports like $3.5 input / $17=
=2E5 output in some views).
The vibe split between excitement (=E2=80=9CHOW I LET CURSOR LONG RUNNING A=
GENT RUN FOR 1 WEEK=E2=80=9D as a meme headline) and frustration over uncle=
ar pools/limits=E2=80=94especially compared against cheaper/high-scoring al=
ternatives like GLM-5.
Windsurf Turns Eval Into a Spectator Sport: Windsurf published an Arena Mod=
e public leaderboard with an announcement and writeup: announcement [ https=
://substack.com/redirect/33907c8d-04ae-45a9-81f2-2efb5487087e?j=3DeyJ1IjoiY=
nBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ], blog analysis [ ht=
tps://substack.com/redirect/184f5a72-cd6a-4d24-98cf-26c969e2a0b3?j=3DeyJ1Ij=
oiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ], and the live le=
aderboard [ https://substack.com/redirect/b42f3cf4-d938-42f2-a609-e6f022f01=
3da?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ].
They also added GPT-5.3-Codex-Spark (preview) into Arena Mode per this upda=
te [ https://substack.com/redirect/70ef9762-5d49-4e61-8a74-cebbf0dde5b0?j=
=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ], creati=
ng a new feedback loop where users compare =E2=80=9CFrontier=E2=80=9D (e.g.=
, Opus 4.6) vs =E2=80=9CFast=E2=80=9D model behavior under battle-group con=
straints.
3. GPU/Infra Tooling + Kernel-Gen Experiments
torchao Trims Fat, Adds MXFP8 MoE Muscles: The torchao v0.16.0 release adde=
d MXFP8 MoE building blocks for training with expert parallelism and pushed=
 toward ABI stability, per release notes [ https://substack.com/redirect/e3=
22acd5-00be-400b-a32e-f78e9789a0aa?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34=
CeFwYb7BfAOkO-PNiz7RTdD8x0 ].
The same release also deprecated older configs/less-used quantization optio=
ns, reinforcing a =E2=80=9Ckeep it lean=E2=80=9D direction that kernel and =
inference folks immediately map to simpler deployment surfaces.
$30k in 5 Days: Kernel-Gen Hackathon Energy: GPU MODE organizers lined up $=
20=E2=80=9330k of compute for 4=E2=80=935 days (late February) to run rapid=
 kernel-generation experiments using models like Qwen3/GLM4.7 Flash, integr=
ating evals such as Kernelbot/Flashinferbench.
They called for collaborators and pointed at concrete baselines/datasets li=
ke kernelbook-kimi_k2_thinking-evals-unique-synthetic-prompts [ https://sub=
stack.com/redirect/d0cd1759-9d59-458f-845e-4b35c7a3d04d?j=3DeyJ1IjoiYnBkbnc=
ifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ] plus tooling progress lik=
e NCU/Compute-Sanitizer as tool calls in FlashInfer Bench docs [ https://su=
bstack.com/redirect/b4cdb7bf-6052-4ef1-8b8f-daae797cb84b?j=3DeyJ1IjoiYnBkbn=
cifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ] and a modularization PR:=
 flashinfer-bench #183 [ https://substack.com/redirect/a33896ec-0856-4023-8=
e4c-865bb05f80f2?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz=
7RTdD8x0 ].
TraceML Watches Your Ranks Like a Hawk: An engineer shared TraceML, an OSS =
tool for PyTorch DDP that shows live per-rank step time/skew with ~one line=
 of instrumentation, at traceopt-ai/traceml [ https://substack.com/redirect=
/52d9effb-bb32-4e09-88e7-c0ea1f47cb34?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9T=
d34CeFwYb7BfAOkO-PNiz7RTdD8x0 ].
The pitch resonated because it targets the boring-but-fatal failure mode: y=
ou think you=E2=80=99re scaling, but one GPU drags, and you only notice aft=
er a burned weekend.
4. Search/OCR + MCP Toolchains for Practical Agents
Google Search MCP: No Keys, No Mercy: LM Studio users shared VincentKaufman=
n/noapi-google-search-mcp [ https://substack.com/redirect/99f41a48-f1a1-49f=
1-bc7b-0bd381d962c3?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-P=
Niz7RTdD8x0 ], a Google Search MCP built on Chromium Headless that avoids A=
PI keys and supports YouTube transcription, Images/Lens, and even local OCR=
=2E
The thread framed this as a pragmatic =E2=80=9Cagent toolbelt=E2=80=9D upgr=
ade: fewer vendor dependencies, more modalities, and a clear MCP-shaped int=
erface for plugging into LLM workflows.
SigLIP2 Tags 150k Photos Without an LLM Identity Crisis: For bulk image tag=
ging, the community recommended SigLIP2 via the HF blog =E2=80=9CSigLIP2=E2=
=80=9D [ https://substack.com/redirect/2c8f13cb-9eff-46d0-9ed0-4f39427f6727=
?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ], spec=
ifically pointing to google/siglip2-large-patch16-256 [ https://substack.co=
m/redirect/a76f2497-7474-44fd-be7e-39b7e94960f7?j=3DeyJ1IjoiYnBkbncifQ.qTvo=
IDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0 ] as a small(ish) vision backbone f=
or generating tags in Python.
The underlying theme: don=E2=80=99t overpay for a chatty multimodal LLM if =
a focused vision encoder solves the pipeline cleanly.
Granite 4 + DuckDuckGo: Cheap Search Brains: LM Studio users reported Grani=
te 4 tiny/micro models work well for web search when paired with DuckDuckGo=
=E2=80=99s API, with some asking for tooling to fetch and extract text from=
 URLs.
This clustered with other =E2=80=9Cbuild-your-own search stack=E2=80=9D cha=
tter (and Perplexity frustration elsewhere), suggesting engineers are activ=
ely reconstructing search workflows with local models + scraping/tooling.
5. Observability, Introspection, and =E2=80=9CShow Your Work=E2=80=9D Gover=
nance
Anthropic=E2=80=99s =E2=80=9CIntrospection=E2=80=9D Paper Gets Side-Eyed: U=
nsloth=E2=80=99s research channel dug into Anthropic=E2=80=99s =E2=80=9CInt=
rospection=E2=80=9D paper [ https://substack.com/redirect/5be14277-6a7d-402=
9-9c91-4f92a369e9b6?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-P=
Niz7RTdD8x0 ], debating what counts as real introspection versus a redundan=
t network that detects =E2=80=9Cabnormal=E2=80=9D activations/weights.
One camp argued it=E2=80=99s basically a sensor for weight/activation fiddl=
ing (=E2=80=9Dpressure sensor on a pressure cooker=E2=80=9C), while others =
pointed out models can detect light steering, implying some usable awarenes=
s of internal state drift.
KOKKI v15.5 Makes Audits a First-Class Output: In OpenAI=E2=80=99s prompt-e=
ngineering discussions, KOKKI v15.5 proposed an explicit Draft =E2=86=92 Au=
dit output contract to make accountability user-visible, with members notin=
g the intentional tradeoff: higher token usage and latency for observabilit=
y.
The follow-on debate got concrete: if you truly want a =E2=80=9Cguarantee,=
=E2=80=9D one member said it would look like a deterministic system, not a =
transformer, so the realistic goal becomes bounded error + inspectable beha=
vior rather than binary truth.

Unsubscribe https://substack.com/redirect/2/eyJlIjoiaHR0cHM6Ly93d3cubGF0ZW5=
0LnNwYWNlL2FjdGlvbi9kaXNhYmxlX2VtYWlsP3Rva2VuPWV5SjFjMlZ5WDJsa0lqb3hPVFkxT1=
RnNE5Dd2ljRzl6ZEY5cFpDSTZNVGczT0RNeU16azNMQ0pwWVhRaU9qRTNOekE1TnpFMU1EY3NJb=
VY0Y0NJNk1UZ3dNalV3TnpVd055d2lhWE56SWpvaWNIVmlMVEV3T0RRd09Ea2lMQ0p6ZFdJaU9p=
SmthWE5oWW14bFgyVnRZV2xzSW4wLjU4a2t4N1lsV21Md2R1SjJ3MndZQjJpRW9fRElWQWhzdGd=
4bDNfdmkzQTAiLCJwIjoxODc4MzIzOTcsInMiOjEwODQwODksImYiOmZhbHNlLCJ1IjoxOTY1OT=
g4NCwiaWF0IjoxNzcwOTcxNTA3LCJleHAiOjIwODY1NDc1MDcsImlzcyI6InB1Yi0wIiwic3ViI=
joibGluay1yZWRpcmVjdCJ9.qKzRK1geY2Ei4xq9HZ7Rb_Uky73JAfsgahPOxxT3ov4?
--53a1463f4835e6c56d10f4540ea2eec91d48eb51fa39e619ffccc2456a84
Content-Type: text/html; charset="utf-8"
Content-Transfer-Encoding: quoted-printable

<html style=3D"scrollbar-width: thin;scrollbar-color: rgb(219,219,219)rgb(2=
55,255,255);"><head><meta charset=3D"utf-8"><title>[AINews] new Gemini 3 De=
ep Think, Anthropic $30B @ $380B, GPT-5.3-Codex Spark, MiniMax M2.5</title>=
<style>
@media (max-width: 1024px) {
  .typography .pullquote-align-left,
  .typography.editor .pullquote-align-left,
  .typography .pullquote-align-right,
  .typography.editor .pullquote-align-right,
  .typography .pullquote-align-wide,
  .typography.editor .pullquote-align-wide,
  .typography .pullquote-align-center,
  .typography.editor .pullquote-align-center {
    float: none;
    margin: 0 auto;
    width: 100%;
    max-width: 100%;
  }
}
@media all and (-ms-high-contrast: none), (-ms-high-contrast: active) {
  .typography .markup table.image-wrapper img,
  .typography.editor .markup table.image-wrapper img,
  .typography .markup table.kindle-wrapper img,
  .typography.editor .markup table.kindle-wrapper img {
    max-width: 550px;
  }
}
@media (min-width: 1024px) {
  .typography:not(:has(#toc)) .captioned-image-container figure:has(> a.ima=
ge2-offset-left),
  .typography.editor:not(:has(#toc)) .captioned-image-container figure:has(=
> a.image2-offset-left) {
    margin-left: var(--image-offset-margin);
  }
  .typography:not(:has(#toc)) .captioned-image-container figure:has(> a.ima=
ge2-offset-right),
  .typography.editor:not(:has(#toc)) .captioned-image-container figure:has(=
> a.image2-offset-right) {
    margin-right: var(--image-offset-margin);
  }
}
@media (min-width: 1300px) {
  .typography .captioned-image-container figure:has(> a.image2-offset-left)=
,
  .typography.editor .captioned-image-container figure:has(> a.image2-offse=
t-left) {
    margin-left: var(--image-offset-margin);
  }
  .typography .captioned-image-container figure:has(> a.image2-offset-right=
),
  .typography.editor .captioned-image-container figure:has(> a.image2-offse=
t-right) {
    margin-right: var(--image-offset-margin);
  }
}
@media (max-width: 1024px) {
  .typography,
  .typography.editor {
    /* Disable offset on mobile/tablet */
  }
  .typography .captioned-image-container figure:has(> a.image2-align-left),
  .typography.editor .captioned-image-container figure:has(> a.image2-align=
-left),
  .typography .captioned-image-container figure:has(> a.image2-align-right)=
,
  .typography.editor .captioned-image-container figure:has(> a.image2-align=
-right) {
    float: none;
    margin: 1em auto;
    max-width: 100%;
    width: auto;
    padding: 0;
  }
  .typography .captioned-image-container figure:has(> a.image2-align-left.t=
hefp),
  .typography.editor .captioned-image-container figure:has(> a.image2-align=
-left.thefp),
  .typography .captioned-image-container figure:has(> a.image2-align-right.=
thefp),
  .typography.editor .captioned-image-container figure:has(> a.image2-align=
-right.thefp) {
    margin: 1em auto;
  }
  .typography .captioned-image-container figure:has(> a.image2-offset-left)=
,
  .typography.editor .captioned-image-container figure:has(> a.image2-offse=
t-left),
  .typography .captioned-image-container figure:has(> a.image2-offset-right=
),
  .typography.editor .captioned-image-container figure:has(> a.image2-offse=
t-right) {
    margin: 1em auto;
  }
  .typography .captioned-image-container figure:has(> a.image2-align-left) =
=2Eimage2-inset,
  .typography.editor .captioned-image-container figure:has(> a.image2-align=
-left) .image2-inset,
  .typography .captioned-image-container figure:has(> a.image2-align-right)=
 .image2-inset,
  .typography.editor .captioned-image-container figure:has(> a.image2-align=
-right) .image2-inset {
    display: block;
    justify-content: initial;
  }
}
@media (max-width: 768px) {
  .typography .markup div.sponsorship-campaign-embed,
  .typography.editor .markup div.sponsorship-campaign-embed {
    margin-top: 24px;
    margin-bottom: 24px;
  }
  .typography .markup div.sponsorship-campaign-embed:first-child,
  .typography.editor .markup div.sponsorship-campaign-embed:first-child {
    margin-top: 0px;
  }
}
@media screen and (max-width: 650px) {
  .typography .markup div.youtube-overlay,
  .typography.editor .markup div.youtube-overlay,
  .typography .markup div.vimeo-overlay,
  .typography.editor .markup div.vimeo-overlay {
    display: none !important;
  }
}
@media screen and (max-width: 370px) {
  .typography .markup div.tiktok-wrap,
  .typography.editor .markup div.tiktok-wrap {
    width: calc(95vw - 32px);
    height: calc((95vw - 32px - 2px) / 0.485714);
  }
}
@media screen and (max-width: 650px) {
  .typography .markup div.embedded-publication-wrap .embedded-publication.s=
how-subscribe,
  .typography.editor .markup div.embedded-publication-wrap .embedded-public=
ation.show-subscribe {
    padding: 24px;
  }
}
@media screen and (max-width: 650px) {
  .typography .markup div.subscription-widget-wrap .subscription-widget.sho=
w-subscribe,
  .typography.editor .markup div.subscription-widget-wrap .subscription-wid=
get.show-subscribe,
  .typography .markup div.subscription-widget-wrap-editor .subscription-wid=
get.show-subscribe,
  .typography.editor .markup div.subscription-widget-wrap-editor .subscript=
ion-widget.show-subscribe,
  .typography .markup div.captioned-button-wrap .subscription-widget.show-s=
ubscribe,
  .typography.editor .markup div.captioned-button-wrap .subscription-widget=
=2Eshow-subscribe {
    padding: 0px 24px;
  }
}
@media screen and (max-width: 650px) {
  .typography .markup div.subscription-widget-wrap .subscription-widget.sho=
w-subscribe .subscription-widget-subscribe .button,
  .typography.editor .markup div.subscription-widget-wrap .subscription-wid=
get.show-subscribe .subscription-widget-subscribe .button,
  .typography .markup div.subscription-widget-wrap-editor .subscription-wid=
get.show-subscribe .subscription-widget-subscribe .button,
  .typography.editor .markup div.subscription-widget-wrap-editor .subscript=
ion-widget.show-subscribe .subscription-widget-subscribe .button,
  .typography .markup div.captioned-button-wrap .subscription-widget.show-s=
ubscribe .subscription-widget-subscribe .button,
  .typography.editor .markup div.captioned-button-wrap .subscription-widget=
=2Eshow-subscribe .subscription-widget-subscribe .button {
    padding: 10px 12px;
    min-width: 110px;
  }
}
@media (max-width: 650px) {
  .typography .markup .twitter-embed,
  .typography.editor .markup .twitter-embed,
  .typography .markup .tweet,
  .typography.editor .markup .tweet {
    padding: 12px;
  }
}
@media (max-width: 650px) {
  .typography .markup .twitter-embed .tweet-text,
  .typography.editor .markup .twitter-embed .tweet-text,
  .typography .markup .tweet .tweet-text,
  .typography.editor .markup .tweet .tweet-text {
    font-size: 14px;
    line-height: 20px;
  }
}
@media (max-width: 650px) {
  .typography .markup .twitter-embed .tweet-photos-container.two,
  .typography.editor .markup .twitter-embed .tweet-photos-container.two,
  .typography .markup .tweet .tweet-photos-container.two,
  .typography.editor .markup .tweet .tweet-photos-container.two,
  .typography .markup .twitter-embed .tweet-photos-container.three,
  .typography.editor .markup .twitter-embed .tweet-photos-container.three,
  .typography .markup .tweet .tweet-photos-container.three,
  .typography.editor .markup .tweet .tweet-photos-container.three,
  .typography .markup .twitter-embed .tweet-photos-container.four,
  .typography.editor .markup .twitter-embed .tweet-photos-container.four,
  .typography .markup .tweet .tweet-photos-container.four,
  .typography.editor .markup .tweet .tweet-photos-container.four {
    height: 200px;
  }
}
@media (max-width: 650px) {
  .typography .markup .twitter-embed a.expanded-link .expanded-link-img,
  .typography.editor .markup .twitter-embed a.expanded-link .expanded-link-=
img,
  .typography .markup .tweet a.expanded-link .expanded-link-img,
  .typography.editor .markup .tweet a.expanded-link .expanded-link-img {
    max-height: 180px;
  }
}
@media (max-width: 650px) {
  .typography .markup .twitter-embed a.expanded-link .expanded-link-descrip=
tion,
  .typography.editor .markup .twitter-embed a.expanded-link .expanded-link-=
description,
  .typography .markup .tweet a.expanded-link .expanded-link-description,
  .typography.editor .markup .tweet a.expanded-link .expanded-link-descript=
ion {
    display: none;
  }
}
@media screen and (max-width: 650px) {
  .typography .markup .apple-podcast-container,
  .typography.editor .markup .apple-podcast-container {
    width: unset;
  }
}
@media (max-width: 420px) {
  .typography .markup .install-substack-app-embed img.install-substack-app-=
embed-img,
  .typography.editor .markup .install-substack-app-embed img.install-substa=
ck-app-embed-img {
    margin: 0 auto 16px auto;
  }
}
@media (max-width: 420px) {
  .typography .markup .install-substack-app-embed .install-substack-app-emb=
ed-text,
  .typography.editor .markup .install-substack-app-embed .install-substack-=
app-embed-text {
    margin: 0 0 12px 0;
    max-width: 100%;
    width: auto;
    text-align: center;
  }
}
@media (max-width: 420px) {
  .typography .markup .install-substack-app-embed .install-substack-app-emb=
ed-link,
  .typography.editor .markup .install-substack-app-embed .install-substack-=
app-embed-link {
    display: flex;
    justify-content: center;
  }
}
@media screen and (min-width: 481px) {
  .share-button-container {
    height: 38px;
  }
}
@media screen and (min-width: 481px) {
  .share-button-container a.comment {
    height: 38px;
    line-height: 38px;
    padding-right: 10px;
  }
}
@media screen and (max-width: 480px) {
  .share-button-container .separator {
    display: block;
    margin: 0;
    height: 8px;
    border-left: none;
  }
}
@media screen and (max-width: 480px) {
  .share-button-container a.share.first img {
    padding-left: 0;
  }
}
@media screen and (min-width: 481px) {
  .share-button-container a.mobile {
    display: none !important;
  }
}
@media screen and (min-width: 541px) {
  .settings-add-pub-modal-wrapper .container .add-recommending-pub-modal-co=
ntainer {
    padding: 36px;
    height: 680px;
  }
}
@media screen and (min-width: 541px) {
  .settings-add-pub-modal-wrapper .container .add-recommending-pub-modal-co=
ntainer .footer {
    position: absolute;
    bottom: 36px;
    margin: 0px;
  }
}
@media screen and (max-width: 650px) {
  .header-anchor-parent {
    display: none;
  }
}
@media screen and (max-width: 768px) {
  .post {
    padding: 16px 0 0 0;
  }
}
@media screen and (max-width: 650px) {
  .post .post-header .post-label {
    margin-top: 8px;
  }
}
@media screen and (max-width: 650px) {
  .post .post-header .meta-author-wrap.alternative-meta .meta-right-column =
=2Epost-meta {
    margin-top: 6px;
  }
}
@media screen and (max-width: 650px) {
  .post .footer-facepile-container {
    height: 64px;
    padding: 0 16px;
    display: flex;
    align-items: center;
    justify-content: flex-start;
    width: 100%;
  }
}
@media screen and (max-width: 650px) {
  .post .post-footer.use-separators {
    justify-content: center;
  }
}
@media screen and (max-width: 650px) {
  .post .post-footer.next-prev {
    height: 64px;
    justify-content: space-between;
    box-sizing: border-box;
  }
}
@media screen and (max-width: 650px) {
  .post-contributor-footer .post-contributor-bio-table {
    display: block;
  }
  .post-contributor-footer .post-contributor-bio-table-row {
    display: flex;
    flex-direction: row;
  }
  .post-contributor-footer .post-contributor-bio-userhead-cell,
  .post-contributor-footer .post-contributor-bio-body-cell {
    display: block;
  }
  .post-contributor-footer .post-contributor-bio-body-cell {
    flex-grow: 1;
  }
  .post-contributor-footer .post-contributor-bio-body-table {
    display: block;
  }
  .post-contributor-footer .post-contributor-bio-body-table-row {
    display: block;
  }
  .post-contributor-footer .post-contributor-bio-copy-cell,
  .post-contributor-footer .post-contributor-bio-controls-cell {
    display: block;
  }
  .post-contributor-footer .post-contributor-bio-copy-cell {
    margin: 0 0 16px 0;
  }
  .post-contributor-footer .post-contributor-bio-controls-cell {
    width: auto;
  }
  .post-contributor-footer .post-contributor-bio-controls {
    margin: auto;
  }
  .post-contributor-footer .post-contributor-bio-controls .button.primary {
    width: 100%;
  }
  .post-contributor-footer .post-contributor-bio-text {
    font-size: 14px;
  }
}
@media screen and (min-width: 768px) {
  .post-silhouette {
    padding: 32px 0;
  }
}
@media screen and (max-width: 650px) {
  .post-silhouette .post-silhouette-title {
    margin-top: 10.44225025px;
    height: 120px;
  }
}
@media screen and (max-width: 650px) {
  .post-silhouette .post-silhouette-meta {
    width: 75%;
  }
}
@media screen and (max-width: 650px) {
  .post-silhouette .post-silhouette-meta.with-byline-image {
    margin: 20px 0;
  }
}
@media screen and (max-width: 650px) {
  .use-theme-bg .post-meta.alternative-meta .post-meta-item,
  .post-meta.alternative-meta .post-meta-item {
    padding-right: 16px;
  }
}
@media screen and (max-width: 370px) {
  .use-theme-bg .post-meta.alternative-meta .post-meta-item,
  .post-meta.alternative-meta .post-meta-item {
    font-size: 14px;
  }
}
@media screen and (max-width: 650px) {
  .use-theme-bg .post-meta.alternative-meta .post-meta-item.guest-author-pu=
blication,
  .post-meta.alternative-meta .post-meta-item.guest-author-publication {
    display: none;
  }
}
@media screen and (max-width: 370px) {
  .post-meta .post-meta-item .post-meta-button {
    height: 36px !important;
    /* important to override in-line height style on emails */
  }
  .post-meta .post-meta-item .post-meta-button .meta-button-label {
    display: none;
  }
  .post-meta .post-meta-item .post-meta-button > svg {
    margin-right: 0;
  }
}
@media screen and (max-width: 370px) {
  .post-meta .post-meta-item {
    font-size: 12px;
  }
}
@media screen and (max-width: 650px) {
  .post .floating-subscribe-button {
    bottom: 20px;
    right: 20px;
  }
}
@media (max-width: 1024px) {
  body .pullquote-align-left,
  body .pullquote-align-right,
  body .pullquote-align-wide,
  body .pullquote-align-center {
    float: none;
    margin: 0 auto;
    width: 100%;
    max-width: 100%;
  }
}
@media all and (-ms-high-contrast: none), (-ms-high-contrast: active) {
  body .markup table.image-wrapper img,
  body .markup table.kindle-wrapper img {
    max-width: 550px;
  }
}
@media (min-width: 1024px) {
  body:not(:has(#toc)) .captioned-image-container figure:has(> a.image2-off=
set-left) {
    margin-left: var(--image-offset-margin);
  }
  body:not(:has(#toc)) .captioned-image-container figure:has(> a.image2-off=
set-right) {
    margin-right: var(--image-offset-margin);
  }
}
@media (min-width: 1300px) {
  body .captioned-image-container figure:has(> a.image2-offset-left) {
    margin-left: var(--image-offset-margin);
  }
  body .captioned-image-container figure:has(> a.image2-offset-right) {
    margin-right: var(--image-offset-margin);
  }
}
@media (max-width: 1024px) {
  body {
    /* Disable offset on mobile/tablet */
  }
  body .captioned-image-container figure:has(> a.image2-align-left),
  body .captioned-image-container figure:has(> a.image2-align-right) {
    float: none;
    margin: 1em auto;
    max-width: 100%;
    width: auto;
    padding: 0;
  }
  body .captioned-image-container figure:has(> a.image2-align-left.thefp),
  body .captioned-image-container figure:has(> a.image2-align-right.thefp) =
{
    margin: 1em auto;
  }
  body .captioned-image-container figure:has(> a.image2-offset-left),
  body .captioned-image-container figure:has(> a.image2-offset-right) {
    margin: 1em auto;
  }
  body .captioned-image-container figure:has(> a.image2-align-left) .image2=
-inset,
  body .captioned-image-container figure:has(> a.image2-align-right) .image=
2-inset {
    display: block;
    justify-content: initial;
  }
}
@media (max-width: 768px) {
  body .markup div.sponsorship-campaign-embed {
    margin-top: 24px;
    margin-bottom: 24px;
  }
  body .markup div.sponsorship-campaign-embed:first-child {
    margin-top: 0px;
  }
}
@media screen and (max-width: 650px) {
  body .markup div.youtube-overlay,
  body .markup div.vimeo-overlay {
    display: none !important;
  }
}
@media screen and (max-width: 370px) {
  body .markup div.tiktok-wrap {
    width: calc(95vw - 32px);
    height: calc((95vw - 32px - 2px) / 0.485714);
  }
}
@media screen and (max-width: 650px) {
  body .markup div.embedded-publication-wrap .embedded-publication.show-sub=
scribe {
    padding: 24px;
  }
}
@media screen and (max-width: 650px) {
  body .markup div.subscription-widget-wrap .subscription-widget.show-subsc=
ribe,
  body .markup div.subscription-widget-wrap-editor .subscription-widget.sho=
w-subscribe,
  body .markup div.captioned-button-wrap .subscription-widget.show-subscrib=
e {
    padding: 0px 24px;
  }
}
@media screen and (max-width: 650px) {
  body .markup div.subscription-widget-wrap .subscription-widget.show-subsc=
ribe .subscription-widget-subscribe .button,
  body .markup div.subscription-widget-wrap-editor .subscription-widget.sho=
w-subscribe .subscription-widget-subscribe .button,
  body .markup div.captioned-button-wrap .subscription-widget.show-subscrib=
e .subscription-widget-subscribe .button {
    padding: 10px 12px;
    min-width: 110px;
  }
}
@media (max-width: 650px) {
  body .markup .twitter-embed,
  body .markup .tweet {
    padding: 12px;
  }
}
@media (max-width: 650px) {
  body .markup .twitter-embed .tweet-text,
  body .markup .tweet .tweet-text {
    font-size: 14px;
    line-height: 20px;
  }
}
@media (max-width: 650px) {
  body .markup .twitter-embed .tweet-photos-container.two,
  body .markup .tweet .tweet-photos-container.two,
  body .markup .twitter-embed .tweet-photos-container.three,
  body .markup .tweet .tweet-photos-container.three,
  body .markup .twitter-embed .tweet-photos-container.four,
  body .markup .tweet .tweet-photos-container.four {
    height: 200px;
  }
}
@media (max-width: 650px) {
  body .markup .twitter-embed a.expanded-link .expanded-link-img,
  body .markup .tweet a.expanded-link .expanded-link-img {
    max-height: 180px;
  }
}
@media (max-width: 650px) {
  body .markup .twitter-embed a.expanded-link .expanded-link-description,
  body .markup .tweet a.expanded-link .expanded-link-description {
    display: none;
  }
}
@media screen and (max-width: 650px) {
  body .markup .apple-podcast-container {
    width: unset;
  }
}
@media (max-width: 420px) {
  body .markup .install-substack-app-embed img.install-substack-app-embed-i=
mg {
    margin: 0 auto 16px auto;
  }
}
@media (max-width: 420px) {
  body .markup .install-substack-app-embed .install-substack-app-embed-text=
 {
    margin: 0 0 12px 0;
    max-width: 100%;
    width: auto;
    text-align: center;
  }
}
@media (max-width: 420px) {
  body .markup .install-substack-app-embed .install-substack-app-embed-link=
 {
    display: flex;
    justify-content: center;
  }
}
@media screen and (min-width: 500px) {
  body .header a.logo {
    width: 42px;
    height: 42px;
    border-radius: 12px;
  }
}
@media screen and (max-width: 420px) {
  body .subscription-receipt table:first-of-type .subscription-amount .subs=
cription-discount {
    width: 72px !important;
  }
}
@media screen and (min-width: 481px) {
  body .share-button-container {
    height: auto;
  }
}
@media screen and (max-width: 480px) {
  body .share-button-container .separator {
    display: block !important;
    margin: 0 !important;
    height: 8px !important;
    border-left: none !important;
  }
}
@media screen and (max-width: 650px) {
  .digest .item .post-meta-item.audience {
    display: none;
  }
}
@media screen and (min-width: 500px) {
  .digest-publication .logo img {
    width: 42px;
    height: 42px;
    border-radius: 8px;
  }
}
@media screen and (max-width: 650px) {
  .comments-page .container .comment-list .collapsed-reply {
    margin-left: calc(10 + 32px - 24px);
  }
}
@media screen and (max-width: 650px) {
  .comment > .comment-list {
    padding-left: 24px;
  }
}
@media screen and (max-width: 650px) {
  .finish-magic-login-modal .modal-content .container {
    padding: 24px 0;
  }
}
@media (max-width: 650px) {
  .reader2-text-b3 {
    line-height: 24px;
  }
}
@media screen and (max-width: 650px) {
  .reader2-text-h4 {
    line-height: 24px;
  }
}
@media screen and (min-width: 541px) {
  .user-profile-modal {
    padding-left: 12px;
    padding-right: 12px;
  }
}
@media screen and (max-width: 650px) {
  .subscribe-widget form.form .sideBySideWrap button.rightButton {
    padding: 10px 12px;
  }
}
@media screen and (min-width: 541px) {
  .pub-icon:hover .logo-hover,
  .feed-item-icon:hover .logo-hover {
    display: block;
  }
}
@media screen and (max-width: 650px) {
  .post-ufi.single-full-width-button .post-ufi-button-wrapper {
    width: 100%;
    padding: 16px;
  }
  .post-ufi.single-full-width-button .post-ufi-button-wrapper:empty {
    display: none;
  }
  .post-ufi.single-full-width-button .post-ufi-button {
    width: 100%;
    justify-content: center;
  }
}
@media screen and (max-width: 768px) {
  .file-embed-wrapper {
    padding: 0;
  }
}
@media screen and (max-width: 768px) {
  .file-embed-wrapper-editor {
    padding: 0;
  }
}
@media screen and (max-width: 768px) {
  .file-embed-wrapper-editor:active {
    padding: 0;
  }
}
@media only screen and (max-width: 650px) {
  .file-embed-button.wide,
  .file-embed-error-button.wide {
    display: none;
  }
}
@media only screen and (min-width: 630px) {
  .file-embed-button.narrow,
  .file-embed-error-button.narrow {
    display: none;
  }
}
@media screen and (min-width: 541px) {
  .audio-player-wrapper .audio-player {
    min-width: 500px;
  }
}
@media screen and (max-width: 650px) {
  .audio-player-wrapper .audio-player .audio-player-progress {
    border-left-width: 16px;
    border-right-width: 16px;
  }
}
@media screen and (max-width: 650px) {
  .audio-player-wrapper .audio-player .audio-player-progress .audio-player-=
progress-bar .audio-player-progress-bar-popup {
    top: -54px;
  }
}
@media screen and (max-width: 650px) {
  .audio-player-wrapper-fancy .audio-player .audio-player-progress {
    border-left-width: 16px;
    border-right-width: 16px;
  }
}
@media screen and (max-width: 650px) {
  .audio-player-wrapper-fancy .audio-player .audio-player-progress .audio-p=
layer-progress-bar .audio-player-progress-bar-popup {
    top: -54px;
  }
}
@media (min-width: 250px) {
  .audio-player-wrapper-fancy .audio-player {
    padding: 32px;
  }
  .audio-player-wrapper-fancy .audio-player .btn-group {
    display: flex;
  }
  .audio-player-wrapper-fancy .audio-player .btn-group .button:last-of-type=
 {
    display: block;
  }
}
@media (min-width: 300px) {
  .audio-player-wrapper-fancy .audio-player .btn-group {
    display: block;
  }
  .audio-player-wrapper-fancy .audio-player .btn-group .button:first-of-typ=
e {
    display: block;
  }
}
@media (min-width: 350px) {
  .audio-player-wrapper-fancy .audio-player .audio-player-substack-logo {
    display: block;
  }
  .audio-player-wrapper-fancy .audio-player .audio-player-title {
    margin-top: 16px;
  }
  .audio-player-wrapper-fancy .audio-player .audio-player-hero-image-contai=
ner {
    padding-top: 15%;
    width: 15%;
    display: block;
  }
  .audio-player-wrapper-fancy .audio-player .btn-group .button:first-of-typ=
e {
    display: block;
  }
  .audio-player-wrapper-fancy .audio-player .audio-player-substack-logo {
    display: block;
  }
}
@media (min-width: 350px) {
  .audio-player-wrapper-fancy .audio-player .audio-player-hero-image-contai=
ner {
    padding-top: 25%;
    width: 25%;
    display: block;
  }
  .audio-player-wrapper-fancy .audio-player .btn-group {
    display: flex;
  }
  .audio-player-wrapper-fancy .audio-player .btn-group .button:first-of-typ=
e {
    display: block;
  }
}
@media (min-width: 400px) {
  .audio-player-wrapper-fancy .audio-player .audio-player-hero-image-contai=
ner {
    padding-top: 40%;
    width: 40%;
  }
}
@media (max-width: 400px) {
  .audio-player-wrapper-fancy .audio-player .btn-group {
    margin-top: 12px;
  }
  .audio-player-wrapper-fancy .audio-player .btn-group .button {
    font-size: 13px;
    padding: 6px 12px;
    height: auto;
    margin-top: 10px;
  }
}
@media (min-width: 600px) {
  .audio-player-wrapper-fancy .audio-player .audio-player-hero-image-contai=
ner {
    padding-top: 55%;
    width: 55%;
  }
}
@media (max-width: 650px) {
  .poll-editor-modal {
    min-width: calc(100% - 20px);
  }
}
@media (max-width: 750px) {
  .poll-embed .poll-anchor-target .poll-anchor-copy-button {
    left: 8px;
    top: 45px;
  }
}
@media not all and (min-resolution: 0.001dpcm) {
  @supports (-webkit-appearance: none) {
    p a:not(.primary.button),
    .post p:not(.button-wrapper) a:not(.primary.button),
    .footnote a.footnote-anchor:not(.primary.button),
    .thread-head .markup p:not(.button-wrapper) a:not(.primary.button) {
      color: #9333ea;
      text-decoration: none;
    }
    p a:not(.primary.button):hover,
    .post p:not(.button-wrapper) a:not(.primary.button):hover,
    .footnote a.footnote-anchor:not(.primary.button):hover,
    .thread-head .markup p:not(.button-wrapper) a:not(.primary.button):hove=
r {
      text-decoration: underline;
    }
  }
}</style></head><body class=3D"email-body" style=3D"font-kerning: auto;--im=
age-offset-margin: -120px;"><img src=3D"https://eotrx.substackcdn.com/open?=
token=3DeyJtIjoiPDIwMjYwMjEzMDgyOTE5LjMuOTJlMGFkYWVlMjdjOWFmMUBtZzEuc3Vic3R=
hY2suY29tPiIsInUiOjE5NjU5ODg0LCJyIjoiZ2VvcmdlY2tAZ21haWwuY29tIiwiZCI6Im1nMS=
5zdWJzdGFjay5jb20iLCJwIjoxODc4MzIzOTcsInQiOiJuZXdzbGV0dGVyIiwiYSI6Im9ubHlfc=
GFpZCIsInMiOjEwODQwODksImMiOiJwb3N0IiwiZiI6ZmFsc2UsInBvc2l0aW9uIjoidG9wIiwi=
aWF0IjoxNzcwOTcxNTA3LCJleHAiOjE3NzM1NjM1MDcsImlzcyI6InB1Yi0wIiwic3ViIjoiZW8=
ifQ.o5YYjBmjLD34z71w6rzH6UY7t8AxGPB63FQL1sFbMAg" alt=3D"" width=3D"1" heigh=
t=3D"1" border=3D"0" style=3D"height:1px !important;width:1px !important;bo=
rder-width:0 !important;margin-top:0 !important;margin-bottom:0 !important;=
margin-right:0 !important;margin-left:0 !important;padding-top:0 !important=
;padding-bottom:0 !important;padding-right:0 !important;padding-left:0 !imp=
ortant;"/><div class=3D"preview" style=3D"display:none;font-size:1px;color:=
#333333;line-height:1px;max-height:0px;max-width:0px;opacity:0;overflow:hid=
den;">There's too much going on!</div><div class=3D"preview" style=3D"displ=
ay:none;font-size:1px;color:#333333;line-height:1px;max-height:0px;max-widt=
h:0px;opacity:0;overflow:hidden;">&#847; &nbsp; &#8199; &#173;&#847; &nbsp;=
 &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#84=
7; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &=
#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; =
&#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847=
; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#=
173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &=
#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847;=
 &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#1=
73;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#=
8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; =
&nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#17=
3;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8=
199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &=
nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173=
;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#81=
99; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &n=
bsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;=
&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#819=
9; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nb=
sp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&=
#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199=
; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbs=
p; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#=
847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199;=
 &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp=
; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#8=
47; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; =
&#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp;=
 &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#84=
7; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &=
#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; =
&#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847=
; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#=
173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &=
#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847;=
 &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#1=
73;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#=
8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; =
&nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#17=
3;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8=
199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &=
nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173=
;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#81=
99; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &n=
bsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;=
&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#819=
9; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nb=
sp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&=
#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199=
; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbs=
p; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#=
847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199;=
 &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp=
; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#8=
47; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; =
&#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp;=
 &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#84=
7; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &=
#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; =
&#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847=
; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#=
173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &=
#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847;=
 &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#1=
73;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#=
8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; =
&nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#17=
3;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8=
199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &=
nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173=
;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#81=
99; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &n=
bsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;=
&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#8199; &#173;&#847; &nbsp; &#819=
9; &#173;</div><table class=3D"email-body-container" role=3D"presentation" =
width=3D"100%" border=3D"0" cellspacing=3D"0" cellpadding=3D"0"><tbody><tr>=
<td></td><td class=3D"content" width=3D"550"></td><td></td></tr><tr><td></t=
d><td class=3D"content" width=3D"550" align=3D"left"><div style=3D"font-siz=
e: 16px;line-height: 26px;max-width: 550px;width: 100%;margin: 0 auto;overf=
low-wrap: break-word;"><table role=3D"presentation" width=3D"100%" border=
=3D"0" cellspacing=3D"0" cellpadding=3D"0"><tbody><tr><td align=3D"right" s=
tyle=3D"height:20px;"><table role=3D"presentation" width=3D"auto" border=3D=
"0" cellspacing=3D"0" cellpadding=3D"0"><tbody><tr><td style=3D"vertical-al=
ign:middle;"><span class=3D"pencraft pc-reset reset-IxiVJZ tw-font-body tw-=
text-ssm tw-text-substack-secondary" style=3D"font-family: SF Pro Text, -ap=
ple-system, system-ui, BlinkMacSystemFont, Inter, Segoe UI, Roboto, Helveti=
ca, Arial, sans-serif, Apple Color Emoji, Segoe UI Emoji, Segoe UI Symbol;f=
ont-size: 13px;color: unset;list-style: none;text-decoration: unset;margin:=
 0;"><a class=3D"tw-text-substack-secondary tw-underline" href=3D"https://s=
ubstack.com/redirect/2/eyJlIjoiaHR0cHM6Ly93d3cubGF0ZW50LnNwYWNlL3AvYWluZXdz=
LW5ldy1nZW1pbmktMy1kZWVwLXRoaW5rLWFudGhyb3BpYz91dG1fY2FtcGFpZ249ZW1haWwtcG9=
zdCZyPWJwZG53JnRva2VuPWV5SjFjMlZ5WDJsa0lqb3hPVFkxT1RnNE5Dd2ljRzl6ZEY5cFpDST=
ZNVGczT0RNeU16azNMQ0pwWVhRaU9qRTNOekE1TnpFMU1EY3NJbVY0Y0NJNk1UYzNNelUyTXpVd=
055d2lhWE56SWpvaWNIVmlMVEV3T0RRd09Ea2lMQ0p6ZFdJaU9pSndiM04wTFhKbFlXTjBhVzl1=
SW4wLjdjbW1NLWFjNnZNN1pFMnQ3WUR0djBHUU1zVXhWWkNhS0ZQaGpwWHpqYlkiLCJwIjoxODc=
4MzIzOTcsInMiOjEwODQwODksImYiOmZhbHNlLCJ1IjoxOTY1OTg4NCwiaWF0IjoxNzcwOTcxNT=
A3LCJleHAiOjIwODY1NDc1MDcsImlzcyI6InB1Yi0wIiwic3ViIjoibGluay1yZWRpcmVjdCJ9.=
dWkO2QDta1BLGPK1fT8luhOBKXZ-Uf1EYZecBDO5OHc?" style=3D"color: rgb(119,119,1=
19);-webkit-text-decoration-line: underline;text-decoration-line: underline=
;">View in browser</a></span></td></tr></tbody></table></td></tr></tbody></=
table><div class=3D"post typography" dir=3D"auto" style=3D"--image-offset-m=
argin: -120px;padding: 32px 0 0 0;font-size: 16px;line-height: 26px;"><div =
class=3D"post-header" role=3D"region" aria-label=3D"Post header" style=3D"f=
ont-size: 16px;line-height: 26px;"><h1 class=3D"post-title published title-=
X77sOw" dir=3D"auto" style=3D"direction: auto;text-align: start;unicode-bid=
i: isolate;color: rgb(54,55,55);font-family: 'Roboto Slab',sans-serif;font-=
weight: 700;-webkit-font-smoothing: antialiased;-moz-osx-font-smoothing: an=
tialiased;-webkit-appearance: optimizelegibility;-moz-appearance: optimizel=
egibility;appearance: optimizelegibility;margin: 0;line-height: 36px;font-s=
ize: 32px;"><a href=3D"https://substack.com/app-link/post?publication_id=3D=
1084089&post_id=3D187832397&utm_source=3Dpost-email-title&utm_campaign=3Dem=
ail-post-title&isFreemail=3Dfalse&r=3Dbpdnw&token=3DeyJ1c2VyX2lkIjoxOTY1OTg=
4NCwicG9zdF9pZCI6MTg3ODMyMzk3LCJpYXQiOjE3NzA5NzE1MDcsImV4cCI6MTc3MzU2MzUwNy=
wiaXNzIjoicHViLTEwODQwODkiLCJzdWIiOiJwb3N0LXJlYWN0aW9uIn0.7cmmM-ac6vM7ZE2t7=
YDtv0GQMsUxVZCaKFPhjpXzjbY" style=3D"color: rgb(54,55,55);text-decoration: =
none;">[AINews] new Gemini 3 Deep Think, Anthropic $30B @ $380B, GPT-5.3-Co=
dex Spark, MiniMax M2.5</a></h1><h3 class=3D"subtitle subtitle-HEEcLo" dir=
=3D"auto" style=3D"direction: auto;text-align: start;unicode-bidi: isolate;=
font-family: 'SF Pro Display',-apple-system-headline,system-ui,-apple-syste=
m,BlinkMacSystemFont,'Segoe UI',Roboto,Helvetica,Arial,sans-serif,'Apple Co=
lor Emoji','Segoe UI Emoji','Segoe UI Symbol';font-weight: normal;-webkit-f=
ont-smoothing: antialiased;-moz-osx-font-smoothing: antialiased;-webkit-app=
earance: optimizelegibility;-moz-appearance: optimizelegibility;appearance:=
 optimizelegibility;margin: 4px 0 0;color: #777777;line-height: 24px;font-s=
ize: 18px;margin-top: 12px;">There's too much going on!</h3><table class=3D=
"post-meta custom alternative-meta" cellpadding=3D"0" cellspacing=3D"0" sty=
le=3D"margin: 1em 0;height: 20px;align-items: center;"><tbody><tr style=3D"=
display: flex;align-items: center;"><td class=3D"post-meta-item audience-lo=
ck" style=3D"position: relative;padding: 0px 12px 0px 0;height: 14px;font-s=
ize: 14px;font-family: system-ui,-apple-system,BlinkMacSystemFont,'Segoe UI=
',Roboto,Helvetica,Arial,sans-serif,'Apple Color Emoji','Segoe UI Emoji','S=
egoe UI Symbol';color: #777777;text-decoration: none;font-weight: 400;paddi=
ng-top: 0;padding-bottom: 0;padding-right: 11px;display: flex;align-items: =
center;"><img src=3D"https://substackcdn.com/image/fetch/$s_!95Aw!,w_28,c_s=
cale,f_png,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack.com%2Fic=
on%2FLockFullIcon%3Fv%3D4%26height%3D28%26strokeWidth%3D3.6" width=3D"14" h=
eight=3D"14" style=3D"border: none;vertical-align: middle;margin-top: -3px;=
margin-left: 0;max-width: 14px" alt=3D""></td><td class=3D"post-meta-item p=
ost-date" title=3D"2026-02-13T08:29:19.362Z" style=3D"position: relative;pa=
dding: 0px 12px 0px 0;height: 14px;font-size: 14px;font-family: system-ui,-=
apple-system,BlinkMacSystemFont,'Segoe UI',Roboto,Helvetica,Arial,sans-seri=
f,'Apple Color Emoji','Segoe UI Emoji','Segoe UI Symbol';text-decoration: n=
one;font-weight: 400;padding-top: 2px;padding-bottom: 2px;padding-right: 0;=
margin-right: 0;overflow-y: visible;overflow-x: hidden;white-space: nowrap;=
text-overflow: ellipsis;min-width: 0;-ms-overflow-style: none;overflow: -mo=
z-scrollbars-none;scrollbar-width: none;color: #363737;display: flex;align-=
items: center;"><div class=3D"pencraft pc-reset color-secondary-ls1g8s line=
-height-20-t4M0El font-meta-MWBumP size-11-NuY2Zx weight-medium-fw81nC tran=
sform-uppercase-yKDgcq reset-IxiVJZ meta-EgzBVA" style=3D"list-style: none;=
font-size: 11px;line-height: 20px;text-decoration: unset;color: rgb(119,119=
,119);margin: 0;font-family: 'SF Compact',-apple-system,system-ui,-apple-sy=
stem,BlinkMacSystemFont,'Segoe UI',Roboto,Helvetica,Arial,sans-serif,'Apple=
 Color Emoji','Segoe UI Emoji','Segoe UI Symbol';font-weight: 500;text-tran=
sform: uppercase;letter-spacing: .2px;"><time datetime=3D"2026-02-13T08:29:=
19.362Z" style=3D"padding-top: 2px;padding-bottom: 2px;overflow-y: visible;=
overflow-x: hidden;white-space: nowrap;text-overflow: ellipsis;">Feb 13</ti=
me></div></td></tr></tbody></table><table class=3D"email-ufi-2-top" role=3D=
"presentation" width=3D"100%" border=3D"0" cellspacing=3D"0" cellpadding=3D=
"0" style=3D"border-top: 1px solid rgb(0,0,0,.1);border-bottom: 1px solid r=
gb(0,0,0,.1);min-width: 100%;"><tbody><tr height=3D"16"><td height=3D"16" s=
tyle=3D"font-size:0px;line-height:0;">&nbsp;</td></tr><tr><td><table role=
=3D"presentation" width=3D"100%" border=3D"0" cellspacing=3D"0" cellpadding=
=3D"0"><tbody><tr><td><table role=3D"presentation" width=3D"auto" border=3D=
"0" cellspacing=3D"0" cellpadding=3D"0"><tbody><tr><td style=3D"vertical-al=
ign:middle;"><table role=3D"presentation" width=3D"38" border=3D"0" cellspa=
cing=3D"0" cellpadding=3D"0"><tbody><tr><td align=3D"center"><a class=3D"em=
ail-icon-button" href=3D"https://substack.com/app-link/post?publication_id=
=3D1084089&post_id=3D187832397&utm_source=3Dsubstack&isFreemail=3Dfalse&sub=
mitLike=3Dtrue&token=3DeyJ1c2VyX2lkIjoxOTY1OTg4NCwicG9zdF9pZCI6MTg3ODMyMzk3=
LCJyZWFjdGlvbiI6IuKdpCIsImlhdCI6MTc3MDk3MTUwNywiZXhwIjoxNzczNTYzNTA3LCJpc3M=
iOiJwdWItMTA4NDA4OSIsInN1YiI6InJlYWN0aW9uIn0.YTkvzf0JRLaIwH4Env4ASqQ-VRQiud=
vsmBnk7MtR4Jg&utm_medium=3Demail&utm_campaign=3Demail-reaction&r=3Dbpdnw" s=
tyle=3D"font-family: system-ui,-apple-system,BlinkMacSystemFont,'Segoe UI',=
Roboto,Helvetica,Arial,sans-serif,'Apple Color Emoji','Segoe UI Emoji','Seg=
oe UI Symbol';display: inline-block;font-weight: 500;border: 1px solid rgb(=
0,0,0,.1);border-radius: 9999px;text-transform: uppercase;font-size: 12px;l=
ine-height: 1;padding: 9px 0;text-decoration: none;color: rgb(119,119,119);=
min-width: 38px;box-sizing: border-box;width: 38px"><img class=3D"icon" src=
=3D"https://substackcdn.com/image/fetch/$s_!PeVs!,w_36,c_scale,f_png,q_auto=
:good,fl_progressive:steep/https%3A%2F%2Fsubstack.com%2Ficon%2FLucideHeart%=
3Fv%3D4%26height%3D36%26fill%3Dnone%26stroke%3D%2523808080%26strokeWidth%3D=
2" width=3D"18" height=3D"18" style=3D"border: none;vertical-align: middle;=
max-width: 18px" alt=3D""></a></td></tr></tbody></table></td><td width=3D"8=
" style=3D"min-width:8px;"></td><td style=3D"vertical-align:middle;"><table=
 role=3D"presentation" width=3D"38" border=3D"0" cellspacing=3D"0" cellpadd=
ing=3D"0"><tbody><tr><td align=3D"center"><a class=3D"email-icon-button" hr=
ef=3D"https://substack.com/app-link/post?publication_id=3D1084089&post_id=
=3D187832397&utm_source=3Dsubstack&utm_medium=3Demail&isFreemail=3Dfalse&co=
mments=3Dtrue&token=3DeyJ1c2VyX2lkIjoxOTY1OTg4NCwicG9zdF9pZCI6MTg3ODMyMzk3L=
CJpYXQiOjE3NzA5NzE1MDcsImV4cCI6MTc3MzU2MzUwNywiaXNzIjoicHViLTEwODQwODkiLCJz=
dWIiOiJwb3N0LXJlYWN0aW9uIn0.7cmmM-ac6vM7ZE2t7YDtv0GQMsUxVZCaKFPhjpXzjbY&r=
=3Dbpdnw&utm_campaign=3Demail-half-magic-comments&action=3Dpost-comment&utm=
_source=3Dsubstack&utm_medium=3Demail" style=3D"font-family: system-ui,-app=
le-system,BlinkMacSystemFont,'Segoe UI',Roboto,Helvetica,Arial,sans-serif,'=
Apple Color Emoji','Segoe UI Emoji','Segoe UI Symbol';display: inline-block=
;font-weight: 500;border: 1px solid rgb(0,0,0,.1);border-radius: 9999px;tex=
t-transform: uppercase;font-size: 12px;line-height: 1;padding: 9px 0;text-d=
ecoration: none;color: rgb(119,119,119);min-width: 38px;box-sizing: border-=
box;width: 38px"><img class=3D"icon" src=3D"https://substackcdn.com/image/f=
etch/$s_!x1tS!,w_36,c_scale,f_png,q_auto:good,fl_progressive:steep/https%3A=
%2F%2Fsubstack.com%2Ficon%2FLucideComments%3Fv%3D4%26height%3D36%26fill%3Dn=
one%26stroke%3D%2523808080%26strokeWidth%3D2" width=3D"18" height=3D"18" st=
yle=3D"border: none;vertical-align: middle;max-width: 18px" alt=3D""></a></=
td></tr></tbody></table></td><td width=3D"8" style=3D"min-width:8px;"></td>=
<td style=3D"vertical-align:middle;"><table role=3D"presentation" width=3D"=
38" border=3D"0" cellspacing=3D"0" cellpadding=3D"0"><tbody><tr><td align=
=3D"center"><a class=3D"email-icon-button" href=3D"https://substack.com/app=
-link/post?publication_id=3D1084089&post_id=3D187832397&utm_source=3Dsubsta=
ck&utm_medium=3Demail&utm_content=3Dshare&utm_campaign=3Demail-share&action=
=3Dshare&triggerShare=3Dtrue&isFreemail=3Dfalse&r=3Dbpdnw&token=3DeyJ1c2VyX=
2lkIjoxOTY1OTg4NCwicG9zdF9pZCI6MTg3ODMyMzk3LCJpYXQiOjE3NzA5NzE1MDcsImV4cCI6=
MTc3MzU2MzUwNywiaXNzIjoicHViLTEwODQwODkiLCJzdWIiOiJwb3N0LXJlYWN0aW9uIn0.7cm=
mM-ac6vM7ZE2t7YDtv0GQMsUxVZCaKFPhjpXzjbY" style=3D"font-family: system-ui,-=
apple-system,BlinkMacSystemFont,'Segoe UI',Roboto,Helvetica,Arial,sans-seri=
f,'Apple Color Emoji','Segoe UI Emoji','Segoe UI Symbol';display: inline-bl=
ock;font-weight: 500;border: 1px solid rgb(0,0,0,.1);border-radius: 9999px;=
text-transform: uppercase;font-size: 12px;line-height: 1;padding: 9px 0;tex=
t-decoration: none;color: rgb(119,119,119);min-width: 38px;box-sizing: bord=
er-box;width: 38px"><img class=3D"icon" src=3D"https://substackcdn.com/imag=
e/fetch/$s_!_L14!,w_36,c_scale,f_png,q_auto:good,fl_progressive:steep/https=
%3A%2F%2Fsubstack.com%2Ficon%2FLucideShare2%3Fv%3D4%26height%3D36%26fill%3D=
none%26stroke%3D%2523808080%26strokeWidth%3D2" width=3D"18" height=3D"18" s=
tyle=3D"border: none;vertical-align: middle;max-width: 18px" alt=3D""></a><=
/td></tr></tbody></table></td><td width=3D"8" style=3D"min-width:8px;"></td=
><td style=3D"vertical-align:middle;"><table role=3D"presentation" width=3D=
"38" border=3D"0" cellspacing=3D"0" cellpadding=3D"0"><tbody><tr><td align=
=3D"center"><a class=3D"email-icon-button" href=3D"https://substack.com/red=
irect/2/eyJlIjoiaHR0cHM6Ly9vcGVuLnN1YnN0YWNrLmNvbS9wdWIvc3d5eC9wL2FpbmV3cy1=
uZXctZ2VtaW5pLTMtZGVlcC10aGluay1hbnRocm9waWM_dXRtX3NvdXJjZT1zdWJzdGFjayZ1dG=
1fbWVkaXVtPWVtYWlsJnV0bV9jYW1wYWlnbj1lbWFpbC1yZXN0YWNrLWNvbW1lbnQmYWN0aW9uP=
XJlc3RhY2stY29tbWVudCZyPWJwZG53JnRva2VuPWV5SjFjMlZ5WDJsa0lqb3hPVFkxT1RnNE5D=
d2ljRzl6ZEY5cFpDSTZNVGczT0RNeU16azNMQ0pwWVhRaU9qRTNOekE1TnpFMU1EY3NJbVY0Y0N=
JNk1UYzNNelUyTXpVd055d2lhWE56SWpvaWNIVmlMVEV3T0RRd09Ea2lMQ0p6ZFdJaU9pSndiM0=
4wTFhKbFlXTjBhVzl1SW4wLjdjbW1NLWFjNnZNN1pFMnQ3WUR0djBHUU1zVXhWWkNhS0ZQaGpwW=
HpqYlkiLCJwIjoxODc4MzIzOTcsInMiOjEwODQwODksImYiOmZhbHNlLCJ1IjoxOTY1OTg4NCwi=
aWF0IjoxNzcwOTcxNTA3LCJleHAiOjIwODY1NDc1MDcsImlzcyI6InB1Yi0wIiwic3ViIjoibGl=
uay1yZWRpcmVjdCJ9.mh3sqZU00zvcdJPHboKHz5mBYYsp7Ctg8B3zrbdEDVs?&utm_source=
=3Dsubstack&utm_medium=3Demail" style=3D"font-family: system-ui,-apple-syst=
em,BlinkMacSystemFont,'Segoe UI',Roboto,Helvetica,Arial,sans-serif,'Apple C=
olor Emoji','Segoe UI Emoji','Segoe UI Symbol';display: inline-block;font-w=
eight: 500;border: 1px solid rgb(0,0,0,.1);border-radius: 9999px;text-trans=
form: uppercase;font-size: 12px;line-height: 1;padding: 9px 0;text-decorati=
on: none;color: rgb(119,119,119);min-width: 38px;box-sizing: border-box;wid=
th: 38px"><img class=3D"icon" src=3D"https://substackcdn.com/image/fetch/$s=
_!5EGt!,w_36,c_scale,f_png,q_auto:good,fl_progressive:steep/https%3A%2F%2Fs=
ubstack.com%2Ficon%2FNoteForwardIcon%3Fv%3D4%26height%3D36%26fill%3Dnone%26=
stroke%3D%2523808080%26strokeWidth%3D2" width=3D"18" height=3D"18" style=3D=
"border: none;vertical-align: middle;max-width: 18px" alt=3D""></a></td></t=
r></tbody></table></td></tr></tbody></table></td><td align=3D"right"><table=
 role=3D"presentation" width=3D"auto" border=3D"0" cellspacing=3D"0" cellpa=
dding=3D"0"><tbody><tr><td style=3D"vertical-align:middle;"><table role=3D"=
presentation" width=3D"auto" border=3D"0" cellspacing=3D"0" cellpadding=3D"=
0"><tbody><tr><td align=3D"center"><a class=3D"email-button-outline" href=
=3D"https://open.substack.com/pub/swyx/p/ainews-new-gemini-3-deep-think-ant=
hropic?utm_source=3Demail&redirect=3Dapp-store&utm_campaign=3Demail-read-in=
-app" style=3D"font-family: system-ui,-apple-system,BlinkMacSystemFont,'Seg=
oe UI',Roboto,Helvetica,Arial,sans-serif,'Apple Color Emoji','Segoe UI Emoj=
i','Segoe UI Symbol';display: inline-block;font-weight: 500;border: 1px sol=
id rgb(0,0,0,.1);border-radius: 9999px;text-transform: uppercase;font-size:=
 12px;line-height: 12px;padding: 9px 14px;text-decoration: none;color: rgb(=
119,119,119);"><div class=3D"email-button-spacer" style=3D"font-size: 16px;=
line-height: 26px;display: inline-block;vertical-align: middle;max-width: 0=
;min-height: 18px;"></div><span class=3D"email-button-text" style=3D"vertic=
al-align: middle;margin-right: 4px">READ IN APP</span><img class=3D"icon te=
xt-icon" src=3D"https://substackcdn.com/image/fetch/$s_!ET-_!,w_36,c_scale,=
f_png,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack.com%2Ficon%2F=
LucideArrowUpRight%3Fv%3D4%26height%3D36%26fill%3Dnone%26stroke%3D%25238080=
80%26strokeWidth%3D2" width=3D"18" height=3D"18" style=3D"min-width: 18px;m=
in-height: 18px;border: none;vertical-align: middle;margin-right: 0;margin-=
left: 0;max-width: 18px" alt=3D""></a></td></tr></tbody></table></td></tr><=
/tbody></table></td></tr></tbody></table></td></tr><tr height=3D"16"><td he=
ight=3D"16" style=3D"font-size:0px;line-height:0;">&nbsp;</td></tr></tbody>=
</table></div></div><div class=3D"post typography" dir=3D"auto" style=3D"--=
image-offset-margin: -120px;padding: 32px 0 0 0;font-size: 16px;line-height=
: 26px;"><div class=3D"body markup" dir=3D"auto" style=3D"text-align: initi=
al;font-size: 16px;line-height: 26px;width: 100%;word-break: break-word;mar=
gin-bottom: 16px;font-family: 'SF Pro Display', -apple-system, system-ui, B=
linkMacSystemFont, 'Inter', 'Segoe UI', Roboto, Helvetica, Arial, sans-seri=
f, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol';font-weight: 40=
0;"><p style=3D"margin: 0 0 20px 0;color: rgb(54,55,55);line-height: 26px;f=
ont-size: 16px;margin-top: 0;"><span>China open model week kept going with =
</span><a href=3D"https://substack.com/redirect/66ceae9d-e0ad-4efe-8d2e-352=
891d5db52?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x=
0" rel=3D"" style=3D"color: #9333ea;text-decoration: none;">MiniMax M2.5 cl=
aiming</a><span> an Opus-matching 80.2% on SWE-Bench Verified, however, as =
often happens on Thursdays, all 3 leading US labs had updates - Anthropic <=
/span><a href=3D"https://substack.com/redirect/26e4e9b0-a1ca-4378-898e-ddb6=
bc743b34?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0=
" rel=3D"" style=3D"color: #9333ea;text-decoration: none;">closed their $38=
0B round</a><span> confirming a historic </span><a href=3D"https://substack=
=2Ecom/redirect/c53aab7c-45a1-42e3-bc0=
a-5cc057b3ef08?j=3DeyJ1IjoiYnBkbncifQ.q=
TvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333e=
a;text-decoration: none;">&gt;10xing of revenue to $14B</a><span> as of tod=
ay (remember in August Dario </span><a href=3D"https://substack.com/redirec=
t/e6a68e4b-163d-4eea-911e-48d76862cab9?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9=
Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-decor=
ation: none;">projected $10B</a><span>), with Claude Code&#8217;s ARR doubl=
ing, hitting 2.5B year to date. Not to be outdone, OpenAI rolled out their =
answer to </span><a href=3D"https://substack.com/redirect/4e06696a-c11f-4d0=
2-813a-efc50e1bfe16?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-P=
Niz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-decoration: none;">Claud=
e&#8217;s fast mode</a><span> (2.5x speedup) with </span><a href=3D"https:/=
/substack.com/redirect/adcc2df5-2c28-41c2-bb58-fe50deac1411?j=3DeyJ1IjoiYnB=
kbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"colo=
r: #9333ea;text-decoration: none;">GPT-5.3-Codex-Spark</a><span>, which del=
ivers &gt;1000 tok/s (10x speedup), an impressively fast turnaround of </sp=
an><a href=3D"https://substack.com/redirect/b9580800-d03c-41e3-862e-15bca8a=
22c13?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" r=
el=3D"" style=3D"color: #9333ea;text-decoration: none;">the Cerebras deal</=
a><span>. </span></p><p style=3D"margin: 0 0 20px 0;color: rgb(54,55,55);li=
ne-height: 26px;font-size: 16px;">All fantastic news, but we give the title=
 story to the new Gemini 3 Deep Think today, and Jeff Dean dropped by the s=
tudio to give an update on the general state of GDM:</p><a class=3D"youtube=
-wrap" href=3D"https://substack.com/redirect/515d445e-ea2a-4854-bfa0-7bd64e=
8ca5e6?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" =
target=3D"_blank" data-component-name=3D"Youtube2ToDOMStatic" style=3D"disp=
lay: block;margin: 32px 0;"><img src=3D"https://substackcdn.com/image/youtu=
be/w_728,c_limit/l_youtube_play_qyqt8q,w_120/F_1oDPWxpFQ" style=3D"border: =
none !important;vertical-align: middle;-ms-interpolation-mode: bicubic;max-=
width: 100%;height: auto;margin: 0 auto;display: block;width: 100%;"></a><p=
 style=3D"margin: 0 0 20px 0;color: rgb(54,55,55);line-height: 26px;font-si=
ze: 16px;"><span>This is the same model that scored </span><a href=3D"https=
://substack.com/redirect/3e58e186-2205-4bfb-aa46-7942f51735ac?j=3DeyJ1IjoiY=
nBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"co=
lor: #9333ea;text-decoration: none;">that IMO Gold last summer</a><span>, a=
nd is simultaneously </span><a href=3D"https://substack.com/redirect/6eb55c=
3f-94e0-413a-89e3-e4f5ac510558?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFw=
Yb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-decoration: n=
one;">the #8 best Codeforces programmer in the world</a><span> and helping =
</span><a href=3D"https://substack.com/redirect/540a1b61-9b07-42f8-9d13-550=
72401679d?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x=
0" rel=3D"" style=3D"color: #9333ea;text-decoration: none;">new semiconduct=
or research</a><span>, but perhaps most impressive is that it reaches new S=
OTA levels (eg on </span><a href=3D"https://substack.com/redirect/7e63172a-=
4bac-46f0-81e7-88d972cad408?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7=
BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-decoration: none=
;">ARC-AGI-2</a><span>) while also </span><a href=3D"https://substack.com/r=
edirect/73f4dd58-c46c-43c0-83d4-bbd45b23fbb4?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDj=
k3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text=
-decoration: none;">being very efficient</a><span> - 82% cheaper per task -=
 something Jeff was very excited about in his pod.</span></p><div class=3D"=
captioned-image-container-static" style=3D"font-size: 16px;line-height: 26p=
x;margin: 32px auto;"><figure style=3D"width: 100%;margin: 0 auto;"><table =
class=3D"image-wrapper" width=3D"100%" border=3D"0" cellspacing=3D"0" cellp=
adding=3D"0" data-component-name=3D"Image2ToDOMStatic" style=3D"mso-padding=
-alt: 1em 0 1.6em;"><tbody><tr><td style=3D"text-align: center;"></td><td c=
lass=3D"content" align=3D"left" width=3D"563" style=3D"text-align: center;"=
><a class=3D"image-link" target=3D"_blank" href=3D"https://substack.com/red=
irect/a68d8475-4493-414e-8937-322d9e80c879?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3=
U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"position: relative;fl=
ex-direction: column;align-items: center;padding: 0;width: auto;height: aut=
o;border: none;text-decoration: none;display: block;margin: 0;"><img class=
=3D"wide-image" data-attrs=3D"{&quot;src&quot;:&quot;https://substack-post-=
media.s3.amazonaws.com/public/images/b8bb2bd9-a33e-4577-bdae-5cb09076e58f_1=
176x1256.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:n=
ull,&quot;imageSize&quot;:null,&quot;height&quot;:1256,&quot;width&quot;:11=
76,&quot;resizeWidth&quot;:563,&quot;bytes&quot;:259234,&quot;alt&quot;:nul=
l,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&=
quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;i=
nternalRedirect&quot;:&quot;https://www.latent.space/i/187832397?img=3Dhttp=
s%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8bb2bd9=
-a33e-4577-bdae-5cb09076e58f_1176x1256.png&quot;,&quot;isProcessing&quot;:f=
alse,&quot;align&quot;:null,&quot;offset&quot;:false}" alt=3D"" width=3D"55=
0" height=3D"587.4149659863946" src=3D"https://substackcdn.com/image/fetch/=
$s_!XRbI!,w_1100,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2=
F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8bb2bd9-a33e-=
4577-bdae-5cb09076e58f_1176x1256.png" style=3D"border: none !important;vert=
ical-align: middle;display: block;-ms-interpolation-mode: bicubic;height: a=
uto;margin-bottom: 0;width: auto !important;max-width: 100% !important;marg=
in: 0 auto;"></a></td><td style=3D"text-align: center;"></td></tr></tbody><=
/table></figure></div><p style=3D"margin: 0 0 20px 0;color: rgb(54,55,55);l=
ine-height: 26px;font-size: 16px;"></p><div style=3D"font-size: 16px;line-h=
eight: 26px;"><hr style=3D"margin: 32px 0;padding: 0;height: 1px;background=
: rgb(0,0,0,.1);border: none;"></div><h1 class=3D"header-anchor-post" style=
=3D"position: relative;font-family: 'SF Pro Display',-apple-system-headline=
,system-ui,-apple-system,BlinkMacSystemFont,'Segoe UI',Roboto,Helvetica,Ari=
al,sans-serif,'Apple Color Emoji','Segoe UI Emoji','Segoe UI Symbol';font-w=
eight: bold;-webkit-font-smoothing: antialiased;-moz-osx-font-smoothing: an=
tialiased;-webkit-appearance: optimizelegibility;-moz-appearance: optimizel=
egibility;appearance: optimizelegibility;margin: 1em 0 0.625em 0;color: rgb=
(54,55,55);line-height: 1.16em;font-size: 2em;"><strong>AI Twitter Recap</s=
trong></h1><p style=3D"margin: 0 0 20px 0;color: rgb(54,55,55);line-height:=
 26px;font-size: 16px;"><strong>Google DeepMind&#8217;s Gemini 3 Deep Think=
 V2: benchmark jump + &#8220;science/engineering reasoning mode&#8221; ship=
ping to users</strong></p><ul style=3D"margin-top: 0;padding: 0;"><li style=
=3D"margin: 8px 0 0 32px;mso-special-format: bullet;"><p style=3D"color: rg=
b(54,55,55);line-height: 26px;margin-bottom: 0;box-sizing: border-box;paddi=
ng-left: 4px;font-size: 16px;margin: 0;"><strong>Deep Think V2 rollout + ac=
cess paths</strong><span>: Google is shipping an upgraded </span><strong>Ge=
mini 3 Deep Think</strong><span> reasoning mode to </span><strong>Google AI=
 Ultra</strong><span> subscribers in the Gemini app, and opening a </span><=
strong>Vertex AI / Gemini API early access</strong><span> program for selec=
t researchers/enterprises (</span><a href=3D"https://substack.com/redirect/=
094a7ff1-4460-4f1e-b211-5f4e50be8f42?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td=
34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-decorat=
ion: none;">GoogleDeepMind</a><span>, </span><a href=3D"https://substack.co=
m/redirect/bcecc62c-6fdf-4ec7-8dc9-5ca9d59c4b93?j=3DeyJ1IjoiYnBkbncifQ.qTvo=
IDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;t=
ext-decoration: none;">Google</a><span>, </span><a href=3D"https://substack=
=2Ecom/redirect/22b0310e-5508-4d03-909=
1-4a795c8a02ad?j=3DeyJ1IjoiYnBkbncifQ.q=
TvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333e=
a;text-decoration: none;">GeminiApp</a><span>, </span><a href=3D"https://su=
bstack.com/redirect/8b35ec2a-b2a3-4f7a-9d3e-59ed7ca73c09?j=3DeyJ1IjoiYnBkbn=
cifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: =
#9333ea;text-decoration: none;">tulseedoshi</a><span>). Multiple Googlers e=
mphasized this is meant to be a </span><em>productized</em><span> test-time=
 compute heavy mode rather than a lab-only demo (</span><a href=3D"https://=
substack.com/redirect/d57b6dce-66dd-48d0-9c31-5fd47255a059?j=3DeyJ1IjoiYnBk=
bncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color=
: #9333ea;text-decoration: none;">OriolVinyalsML</a><span>, </span><a href=
=3D"https://substack.com/redirect/b3c65e4e-08e7-4648-b0b6-7361e3097f15?j=3D=
eyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" st=
yle=3D"color: #9333ea;text-decoration: none;">JeffDean</a><span>, </span><a=
 href=3D"https://substack.com/redirect/744215ea-28f3-4395-a568-db495ce3e471=
?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D=
"" style=3D"color: #9333ea;text-decoration: none;">demishassabis</a><span>,=
 </span><a href=3D"https://substack.com/redirect/150eedc9-c9e4-4e2b-a0ad-c6=
da107534eb?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8=
x0" rel=3D"" style=3D"color: #9333ea;text-decoration: none;">sundarpichai</=
a><span>).</span></p></li><li style=3D"margin: 8px 0 0 32px;mso-special-for=
mat: bullet;"><p style=3D"margin: 0 0 20px 0;color: rgb(54,55,55);line-heig=
ht: 26px;margin-bottom: 0;box-sizing: border-box;padding-left: 4px;font-siz=
e: 16px;"><strong>Key reported numbers (and what&#8217;s notable about them=
)</strong><span>:</span></p><ul style=3D"margin-top: 0;padding: 0;"><li sty=
le=3D"margin: 8px 0 0 32px;mso-special-format: bullet;"><p style=3D"color: =
rgb(54,55,55);line-height: 26px;margin-bottom: 0;box-sizing: border-box;pad=
ding-left: 4px;font-size: 16px;margin: 0;"><strong>ARC-AGI-2: 84.6%</strong=
><span> (promoted as new SOTA; independently certified/verified by the ARC =
community) (</span><a href=3D"https://substack.com/redirect/21924c2a-f267-4=
99a-adf9-600d6b408343?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO=
-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-decoration: none;">Goo=
gle</a><span>, </span><a href=3D"https://substack.com/redirect/ed7664c6-e97=
2-4cf2-894f-9cd2e93a08f0?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfA=
OkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-decoration: none;">=
arcprize</a><span>, </span><a href=3D"https://substack.com/redirect/3cd5393=
c-8a6f-4849-b09b-96418c4659e2?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwY=
b7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-decoration: no=
ne;">fchollet</a><span>, </span><a href=3D"https://substack.com/redirect/ef=
87ab1c-e0f5-4740-86ac-f6ea2b4dac18?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34=
CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-decoratio=
n: none;">scaling01</a><span>).</span></p></li><li style=3D"margin: 8px 0 0=
 32px;mso-special-format: bullet;"><p style=3D"color: rgb(54,55,55);line-he=
ight: 26px;margin-bottom: 0;box-sizing: border-box;padding-left: 4px;font-s=
ize: 16px;margin: 0;"><strong>Humanity&#8217;s Last Exam (HLE): 48.4% witho=
ut tools</strong><span> (</span><a href=3D"https://substack.com/redirect/15=
0eedc9-c9e4-4e2b-a0ad-c6da107534eb?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34=
CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-decoratio=
n: none;">sundarpichai</a><span>, </span><a href=3D"https://substack.com/re=
direct/b8d22fa0-77dc-4baa-b914-af1011c06bd1?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk=
3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-=
decoration: none;">_philschmid</a><span>, </span><a href=3D"https://substac=
k.com/redirect/b3c65e4e-08e7-4648-b0b6-7361e3097f15?j=3DeyJ1IjoiYnBkbncifQ.=
qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333=
ea;text-decoration: none;">JeffDean</a><span>).</span></p></li><li style=3D=
"margin: 8px 0 0 32px;mso-special-format: bullet;"><p style=3D"color: rgb(5=
4,55,55);line-height: 26px;margin-bottom: 0;box-sizing: border-box;padding-=
left: 4px;font-size: 16px;margin: 0;"><strong>Codeforces Elo: 3455</strong>=
<span> (framed as &#8220;only ~7 humans&#8221; above it; discussion about &=
#8220;no tools&#8221; conditions and what that implies for evaluation) (</s=
pan><a href=3D"https://substack.com/redirect/6a42c71c-a671-4e92-8217-992511=
fce5e0?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" =
rel=3D"" style=3D"color: #9333ea;text-decoration: none;">scaling01</a><span=
>, </span><a href=3D"https://substack.com/redirect/a960b21c-1fca-4784-9319-=
2426c20075eb?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTd=
D8x0" rel=3D"" style=3D"color: #9333ea;text-decoration: none;">YouJiacheng<=
/a><span>, </span><a href=3D"https://substack.com/redirect/8cc3fc3c-5e3a-42=
10-b022-1b3c8e7301b4?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-=
PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-decoration: none;">Dery=
aTR_</a><span>).</span></p></li><li style=3D"margin: 8px 0 0 32px;mso-speci=
al-format: bullet;"><p style=3D"color: rgb(54,55,55);line-height: 26px;marg=
in-bottom: 0;box-sizing: border-box;padding-left: 4px;font-size: 16px;margi=
n: 0;"><strong>Olympiad-level written performance</strong><span> in </span>=
<strong>Physics/Chemistry</strong><span> (and references to IMO/ICPC histor=
y) (</span><a href=3D"https://substack.com/redirect/27977b47-58a6-4541-be0e=
-0361c71d5310?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RT=
dD8x0" rel=3D"" style=3D"color: #9333ea;text-decoration: none;">Google</a><=
span>, </span><a href=3D"https://substack.com/redirect/d3334c9b-f926-414e-9=
fc9-6903fb6a14bd?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz=
7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-decoration: none;">NoamShaz=
eer</a><span>, </span><a href=3D"https://substack.com/redirect/744215ea-28f=
3-4395-a568-db495ce3e471?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfA=
OkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-decoration: none;">=
demishassabis</a><span>, </span><a href=3D"https://substack.com/redirect/b8=
d22fa0-77dc-4baa-b914-af1011c06bd1?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34=
CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-decoratio=
n: none;">_philschmid</a><span>).</span></p></li><li style=3D"margin: 8px 0=
 0 32px;mso-special-format: bullet;"><p style=3D"color: rgb(54,55,55);line-=
height: 26px;margin-bottom: 0;box-sizing: border-box;padding-left: 4px;font=
-size: 16px;margin: 0;"><strong>Cost disclosures for ARC</strong><span>: AR=
C Prize posted semi-private eval pricing like </span><strong>$13.62/task</s=
trong><span> for ARC-AGI-2 and </span><strong>$7.17/task</strong><span> for=
 ARC-AGI-1 (</span><a href=3D"https://substack.com/redirect/ed7664c6-e972-4=
cf2-894f-9cd2e93a08f0?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO=
-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-decoration: none;">arc=
prize</a><span>).</span></p></li></ul></li><li style=3D"margin: 8px 0 0 32p=
x;mso-special-format: bullet;"><p style=3D"color: rgb(54,55,55);line-height=
: 26px;margin-bottom: 0;box-sizing: border-box;padding-left: 4px;font-size:=
 16px;margin: 0;"><strong>Real-world &#8220;engineering&#8221; demos and cl=
aimed impact</strong><span>: Several posts push the message that Deep Think=
&#8217;s value is in </span><em>practical</em><span> scientific/engineering=
 workflows: finding errors in math papers, modeling physical systems in cod=
e, optimizing semiconductor crystal growth, and even a </span><strong>sketc=
h &#8594; CAD/STL</strong><span> pipeline for 3D printing (e.g., laptop sta=
nd and turbine-blade-esque components) (</span><a href=3D"https://substack.=
com/redirect/93aea54d-26cf-4da0-8cec-a613997d414e?j=3DeyJ1IjoiYnBkbncifQ.qT=
voIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea=
;text-decoration: none;">Google</a><span>, </span><a href=3D"https://substa=
ck.com/redirect/bb186bc4-5b6e-423e-98b9-40c295486187?j=3DeyJ1IjoiYnBkbncifQ=
=2EqTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNi=
z7RTdD8x0" rel=3D"" style=3D"color: #933=
3ea;text-decoration: none;">Google</a><span>, </span><a href=3D"https://sub=
stack.com/redirect/04e896db-d9d6-44f7-a74e-aca548f1916d?j=3DeyJ1IjoiYnBkbnc=
ifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #=
9333ea;text-decoration: none;">Google</a><span>, </span><a href=3D"https://=
substack.com/redirect/22b0310e-5508-4d03-9091-4a795c8a02ad?j=3DeyJ1IjoiYnBk=
bncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color=
: #9333ea;text-decoration: none;">GeminiApp</a><span>, </span><a href=3D"ht=
tps://substack.com/redirect/fd5d8fee-f470-4688-abd2-5be24e6e2d26?j=3DeyJ1Ij=
oiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D=
"color: #9333ea;text-decoration: none;">joshwoodward</a><span>, </span><a h=
ref=3D"https://substack.com/redirect/2ebe7534-de44-49be-8c3e-7ce9159712bd?j=
=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D""=
 style=3D"color: #9333ea;text-decoration: none;">tulseedoshi</a><span>, </s=
pan><a href=3D"https://substack.com/redirect/15c4c866-3c7d-486d-bb3e-2f671b=
ed28f9?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" =
rel=3D"" style=3D"color: #9333ea;text-decoration: none;">OriolVinyalsML</a>=
<span>).</span></p></li><li style=3D"margin: 8px 0 0 32px;mso-special-forma=
t: bullet;"><p style=3D"color: rgb(54,55,55);line-height: 26px;margin-botto=
m: 0;box-sizing: border-box;padding-left: 4px;font-size: 16px;margin: 0;"><=
strong>ARC context / what &#8220;saturating ARC&#8221; means</strong><span>=
: Fran&#231;ois Chollet (ARC&#8217;s creator) both celebrated certification=
 and later reiterated that ARC&#8217;s purpose is to steer research toward =
</span><strong>test-time adaptation / fluid intelligence</strong><span>, no=
t to &#8220;prove AGI&#8221; (</span><a href=3D"https://substack.com/redire=
ct/3cd5393c-8a6f-4849-b09b-96418c4659e2?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G=
9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-deco=
ration: none;">fchollet</a><span>, </span><a href=3D"https://substack.com/r=
edirect/580a499c-6713-4f12-9428-d89a8a670ecf?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDj=
k3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text=
-decoration: none;">fchollet</a><span>). In a separate thread he defines &#=
8220;AGI&#8221; as </span><em>the end of the human&#8211;AI gap</em><span> =
and argues benchmarks must evolve until humans can no longer propose tasks =
where they outperform AI, with a rough expectation of </span><strong>~2030<=
/strong><span> for that state (</span><a href=3D"https://substack.com/redir=
ect/d64f66b8-8326-43cc-b887-f2ebaf4f82ee?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3=
G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-dec=
oration: none;">fchollet</a><span>, </span><a href=3D"https://substack.com/=
redirect/fd6dfd6a-29ef-4fa6-94c8-6b5cb557762f?j=3DeyJ1IjoiYnBkbncifQ.qTvoID=
jk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;tex=
t-decoration: none;">fchollet</a><span>).</span></p></li></ul><div style=3D=
"font-size: 16px;line-height: 26px;"><hr style=3D"margin: 32px 0;padding: 0=
;height: 1px;background: rgb(0,0,0,.1);border: none;"></div><p style=3D"mar=
gin: 0 0 20px 0;color: rgb(54,55,55);line-height: 26px;font-size: 16px;"><s=
trong>Open coding/agent models shipping fast: MiniMax M2.5 + Zhipu&#8217;s =
GLM-5 battle for &#8220;best open agentic coder&#8221;</strong></p><ul styl=
e=3D"margin-top: 0;padding: 0;"><li style=3D"margin: 8px 0 0 32px;mso-speci=
al-format: bullet;"><p style=3D"margin: 0 0 20px 0;color: rgb(54,55,55);lin=
e-height: 26px;margin-bottom: 0;box-sizing: border-box;padding-left: 4px;fo=
nt-size: 16px;"><strong>MiniMax M2.5: distribution + positioning</strong><s=
pan>: MiniMax&#8217;s new model is pushed as an &#8220;agent-verse / long-h=
orizon agent&#8221; model, rapidly appearing across aggregators and tools: =
OpenRouter (</span><a href=3D"https://substack.com/redirect/ee7579d0-024e-4=
1a3-b060-da4293630b0a?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO=
-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-decoration: none;">Ope=
nRouterAI</a><span>), Arena (</span><a href=3D"https://substack.com/redirec=
t/5931b9d0-7c07-495d-b3f5-73684250b6bd?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9=
Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-decor=
ation: none;">arena</a><span>), IDE/agents like </span><strong>Cline</stron=
g><span> (</span><a href=3D"https://substack.com/redirect/6b0f79e7-7bb2-46c=
4-9e88-6576625ac522?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-P=
Niz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-decoration: none;">cline=
</a><span>), </span><strong>Ollama cloud</strong><span> free promo (</span>=
<a href=3D"https://substack.com/redirect/2ab64e6e-e4a2-44db-9126-22737e6f1b=
f5?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=
=3D"" style=3D"color: #9333ea;text-decoration: none;">ollama</a><span>), Ei=
gent agent scaffolds (</span><a href=3D"https://substack.com/redirect/7b3e1=
1b4-4007-4e8d-9f07-fe8dd19656a8?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeF=
wYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-decoration: =
none;">Eigent_AI</a><span>), Qoder (</span><a href=3D"https://substack.com/=
redirect/be423a22-27e4-42bb-a270-9da88fc6e438?j=3DeyJ1IjoiYnBkbncifQ.qTvoID=
jk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;tex=
t-decoration: none;">qoder_ai_ide</a><span>), and Blackbox AI (</span><a hr=
ef=3D"https://substack.com/redirect/89f288ae-f24b-4234-9c67-a463842f4258?j=
=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D""=
 style=3D"color: #9333ea;text-decoration: none;">blackboxai</a><span>).</sp=
an></p><ul style=3D"margin-top: 0;padding: 0;"><li style=3D"margin: 8px 0 0=
 32px;mso-special-format: bullet;"><p style=3D"color: rgb(54,55,55);line-he=
ight: 26px;margin-bottom: 0;box-sizing: border-box;padding-left: 4px;font-s=
ize: 16px;margin: 0;"><strong>Benchmarks cited in the thread</strong><span>=
 include claims like </span><strong>80.2% SWE-Bench Verified</strong><span>=
 and strong performance vs closed models in coding settings; multiple tweet=
s stress </span><em>throughput + cost</em><span> as differentiators (e.g., =
</span><strong>100 tokens/s</strong><span> and </span><strong>$0.06/M blend=
ed with caching</strong><span> are cited by Cline) (</span><a href=3D"https=
://substack.com/redirect/6b0f79e7-7bb2-46c4-9e88-6576625ac522?j=3DeyJ1IjoiY=
nBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"co=
lor: #9333ea;text-decoration: none;">cline</a><span>, </span><a href=3D"htt=
ps://substack.com/redirect/8522563d-fc03-45b8-b22b-4dde87bd1f22?j=3DeyJ1Ijo=
iYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"=
color: #9333ea;text-decoration: none;">cline</a><span>, </span><a href=3D"h=
ttps://substack.com/redirect/e2a92a9e-edef-4bb6-97df-b50409525668?j=3DeyJ1I=
joiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=
=3D"color: #9333ea;text-decoration: none;">guohao_li</a><span>, </span><a h=
ref=3D"https://substack.com/redirect/f4c3a9a8-1e4c-4ebf-9312-d3d2e456c4b9?j=
=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D""=
 style=3D"color: #9333ea;text-decoration: none;">shydev69</a><span>). Commu=
nity vibe checks (e.g., Neubig) claim it&#8217;s one of the first open-ish =
coding models he&#8217;d seriously consider switching to for daily work (</=
span><a href=3D"https://substack.com/redirect/e8fdf156-d4fc-4819-99e4-39409=
633d814?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0"=
 rel=3D"" style=3D"color: #9333ea;text-decoration: none;">gneubig</a><span>=
).</span></p></li></ul></li><li style=3D"margin: 8px 0 0 32px;mso-special-f=
ormat: bullet;"><p style=3D"margin: 0 0 20px 0;color: rgb(54,55,55);line-he=
ight: 26px;margin-bottom: 0;box-sizing: border-box;padding-left: 4px;font-s=
ize: 16px;"><strong>GLM-5: model scale + infra hints + &#8220;open model le=
aderboards&#8221;</strong><span>:</span></p><ul style=3D"margin-top: 0;padd=
ing: 0;"><li style=3D"margin: 8px 0 0 32px;mso-special-format: bullet;"><p =
style=3D"color: rgb(54,55,55);line-height: 26px;margin-bottom: 0;box-sizing=
: border-box;padding-left: 4px;font-size: 16px;margin: 0;"><span>Tooling ec=
osystem reports: GLM-5 is used on YouWare with a </span><strong>200K contex=
t window</strong><span> for web projects (</span><a href=3D"https://substac=
k.com/redirect/cdd34771-39a9-40ff-bb7d-42c74ee8bdbe?j=3DeyJ1IjoiYnBkbncifQ.=
qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333=
ea;text-decoration: none;">YouWareAI</a><span>); one user reports </span><s=
trong>~14 tps on OpenRouter</strong><span> (</span><a href=3D"https://subst=
ack.com/redirect/e5ce207e-cfbd-4a4e-8dde-a909d976db58?j=3DeyJ1IjoiYnBkbncif=
Q.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #93=
33ea;text-decoration: none;">scaling01</a><span>).</span></p></li><li style=
=3D"margin: 8px 0 0 32px;mso-special-format: bullet;"><p style=3D"color: rg=
b(54,55,55);line-height: 26px;margin-bottom: 0;box-sizing: border-box;paddi=
ng-left: 4px;font-size: 16px;margin: 0;"><span>A more detailed (but still t=
hird-party) technical summary claims </span><strong>GLM-5 is 744B params wi=
th ~40B active</strong><span>, trained on </span><strong>28.5T tokens</stro=
ng><span>, integrates </span><strong>DeepSeek Sparse Attention</strong><spa=
n>, and uses &#8220;Slime&#8221; asynchronous RL infra to increase post-tra=
ining iteration speed (</span><a href=3D"https://substack.com/redirect/d4d3=
9695-81e9-4023-8130-4953ca4d9a15?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34Ce=
FwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-decoration:=
 none;">cline</a><span>). Another tweet nitpicks terminology confusion arou=
nd attention components (</span><a href=3D"https://substack.com/redirect/2f=
97be80-7ada-4864-94f9-b414b4ee1a02?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34=
CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-decoratio=
n: none;">eliebakouch</a><span>).</span></p></li><li style=3D"margin: 8px 0=
 0 32px;mso-special-format: bullet;"><p style=3D"color: rgb(54,55,55);line-=
height: 26px;margin-bottom: 0;box-sizing: border-box;padding-left: 4px;font=
-size: 16px;margin: 0;"><strong>Local inference datapoint</strong><span>: a=
wnihannun reports running GLM-5 via </span><strong>mlx-lm</strong><span> on=
 a </span><strong>512GB M3 Ultra</strong><span>, generating a small game at=
 </span><strong>~15.4 tok/s</strong><span> using </span><strong>~419GB memo=
ry</strong><span> (</span><a href=3D"https://substack.com/redirect/8e884019=
-6415-49d6-a0d6-3b3072162720?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb=
7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-decoration: non=
e;">awnihannun</a><span>).</span></p></li><li style=3D"margin: 8px 0 0 32px=
;mso-special-format: bullet;"><p style=3D"color: rgb(54,55,55);line-height:=
 26px;margin-bottom: 0;box-sizing: border-box;padding-left: 4px;font-size: =
16px;margin: 0;"><strong>Arena signal</strong><span>: the Arena account say=
s </span><strong>GLM-5 is #1 open model in Code Arena (tied with Kimi)</str=
ong><span> and overall </span><strong>#6</strong><span>, still ~100+ points=
 behind </span><strong>Claude Opus 4.6</strong><span> on &#8220;agentic web=
dev&#8221; tasks (</span><a href=3D"https://substack.com/redirect/492b8af8-=
1aef-410b-a22c-23c11c7db898?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7=
BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-decoration: none=
;">arena</a><span>).</span></p></li><li style=3D"margin: 8px 0 0 32px;mso-s=
pecial-format: bullet;"><p style=3D"color: rgb(54,55,55);line-height: 26px;=
margin-bottom: 0;box-sizing: border-box;padding-left: 4px;font-size: 16px;m=
argin: 0;"><span>A long Chinese-language-style analysis reposted via ZhihuF=
rontier argues GLM-5 improves hallucination control and programming fundame=
ntals but is more verbose/&#8220;overthinks,&#8221; suggesting compute cons=
traints (concurrency limits) show through (</span><a href=3D"https://substa=
ck.com/redirect/20e5efa2-0607-4d60-ae14-57aea80f5b57?j=3DeyJ1IjoiYnBkbncifQ=
=2EqTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNi=
z7RTdD8x0" rel=3D"" style=3D"color: #933=
3ea;text-decoration: none;">ZhihuFrontier</a><span>).</span></p></li></ul><=
/li></ul><div style=3D"font-size: 16px;line-height: 26px;"><hr style=3D"mar=
gin: 32px 0;padding: 0;height: 1px;background: rgb(0,0,0,.1);border: none;"=
></div><p style=3D"margin: 0 0 20px 0;color: rgb(54,55,55);line-height: 26p=
x;font-size: 16px;"><strong>OpenAI&#8217;s GPT-5.3-Codex-Spark: ultra-low-l=
atency coding via Cerebras (and why UX becomes the bottleneck)</strong></p>=
<ul style=3D"margin-top: 0;padding: 0;"><li style=3D"margin: 8px 0 0 32px;m=
so-special-format: bullet;"><p style=3D"color: rgb(54,55,55);line-height: 2=
6px;margin-bottom: 0;box-sizing: border-box;padding-left: 4px;font-size: 16=
px;margin: 0;"><strong>Product announcement</strong><span>: OpenAI released=
 </span><strong>GPT-5.3-Codex-Spark</strong><span> as a &#8220;research pre=
view&#8221; for </span><strong>ChatGPT Pro users</strong><span> in the Code=
x app/CLI/IDE extension (</span><a href=3D"https://substack.com/redirect/81=
549586-2231-4d26-b03d-c3bf9368f408?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34=
CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-decoratio=
n: none;">OpenAI</a><span>, </span><a href=3D"https://substack.com/redirect=
/761f86ff-29bf-42bb-9c60-25adcc14a7f6?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9T=
d34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-decora=
tion: none;">OpenAIDevs</a><span>). It&#8217;s explicitly framed as the fir=
st milestone in a partnership with </span><strong>Cerebras</strong><span> (=
also touted by Cerebras) (</span><a href=3D"https://substack.com/redirect/4=
f9ae689-09f9-4599-bb4b-f32356709780?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td3=
4CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-decorati=
on: none;">cerebras</a><span>).</span></p></li><li style=3D"margin: 8px 0 0=
 32px;mso-special-format: bullet;"><p style=3D"margin: 0 0 20px 0;color: rg=
b(54,55,55);line-height: 26px;margin-bottom: 0;box-sizing: border-box;paddi=
ng-left: 4px;font-size: 16px;"><strong>Performance envelope</strong><span>:=
</span></p><ul style=3D"margin-top: 0;padding: 0;"><li style=3D"margin: 8px=
 0 0 32px;mso-special-format: bullet;"><p style=3D"color: rgb(54,55,55);lin=
e-height: 26px;margin-bottom: 0;box-sizing: border-box;padding-left: 4px;fo=
nt-size: 16px;margin: 0;"><span>The headline is </span><strong>&#8220;1000+=
 tokens per second&#8221;</strong><span> and &#8220;near-instant&#8221; int=
eraction (</span><a href=3D"https://substack.com/redirect/761f86ff-29bf-42b=
b-9c60-25adcc14a7f6?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-P=
Niz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-decoration: none;">OpenA=
IDevs</a><span>, </span><a href=3D"https://substack.com/redirect/4e530c8e-7=
f73-48aa-bdc3-647b1796aae5?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7B=
fAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-decoration: none;=
">sama</a><span>, </span><a href=3D"https://substack.com/redirect/d3e7da2b-=
bc0e-462d-8bdd-ab985e0a4e92?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7=
BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-decoration: none=
;">kevinweil</a><span>, </span><a href=3D"https://substack.com/redirect/31c=
9ff56-338b-4737-a2b6-b7fff094e6de?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34C=
eFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-decoration=
: none;">gdb</a><span>).</span></p></li><li style=3D"margin: 8px 0 0 32px;m=
so-special-format: bullet;"><p style=3D"color: rgb(54,55,55);line-height: 2=
6px;margin-bottom: 0;box-sizing: border-box;padding-left: 4px;font-size: 16=
px;margin: 0;"><span>Initial capability details: </span><strong>text-only</=
strong><span>, </span><strong>128k context</strong><span>, with plans for l=
arger/longer/multimodal as infra capacity expands (</span><a href=3D"https:=
//substack.com/redirect/796c20ec-9341-42c5-9f50-eb281a1b641f?j=3DeyJ1IjoiYn=
BkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"col=
or: #9333ea;text-decoration: none;">OpenAIDevs</a><span>).</span></p></li><=
li style=3D"margin: 8px 0 0 32px;mso-special-format: bullet;"><p style=3D"c=
olor: rgb(54,55,55);line-height: 26px;margin-bottom: 0;box-sizing: border-b=
ox;padding-left: 4px;font-size: 16px;margin: 0;"><span>Anecdotal reviews hi=
ghlight a new bottleneck: humans can&#8217;t </span><em>read/validate/steer=
</em><span> as fast as the model can produce code, implying tooling/UX must=
 evolve (better diffs, task decomposition, guardrails, &#8220;agent inboxes=
,&#8221; etc.) (</span><a href=3D"https://substack.com/redirect/37b87397-af=
fb-4422-aff9-0012ae499db4?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7Bf=
AOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-decoration: none;"=
>danshipper</a><span>, </span><a href=3D"https://substack.com/redirect/da2e=
5c3b-aea9-4878-8242-1c6d5ae05c15?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34Ce=
FwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-decoration:=
 none;">skirano</a><span>).</span></p></li></ul></li><li style=3D"margin: 8=
px 0 0 32px;mso-special-format: bullet;"><p style=3D"color: rgb(54,55,55);l=
ine-height: 26px;margin-bottom: 0;box-sizing: border-box;padding-left: 4px;=
font-size: 16px;margin: 0;"><strong>Model size speculation</strong><span>: =
There are community attempts to back-calculate size from throughput vs othe=
r MoEs; one estimate suggests </span><strong>~30B active</strong><span> and=
 perhaps </span><strong>300B&#8211;700B total</strong><span> parameters (</=
span><a href=3D"https://substack.com/redirect/005faeac-2b1f-46c2-ab99-fc230=
7e9adf3?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0"=
 rel=3D"" style=3D"color: #9333ea;text-decoration: none;">scaling01</a><spa=
n>). Treat this as informed speculation, not an official disclosure.</span>=
</p></li><li style=3D"margin: 8px 0 0 32px;mso-special-format: bullet;"><p =
style=3D"color: rgb(54,55,55);line-height: 26px;margin-bottom: 0;box-sizing=
: border-box;padding-left: 4px;font-size: 16px;margin: 0;"><strong>Adoption=
/availability</strong><span>: Sam Altman later says Spark is rolling to Pro=
; OpenAI DevRel notes limited API early access for a small group (</span><a=
 href=3D"https://substack.com/redirect/4e530c8e-7f73-48aa-bdc3-647b1796aae5=
?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D=
"" style=3D"color: #9333ea;text-decoration: none;">sama</a><span>, </span><=
a href=3D"https://substack.com/redirect/1947d476-b771-40aa-9fae-42269bf9485=
b?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=
=3D"" style=3D"color: #9333ea;text-decoration: none;">OpenAIDevs</a><span>)=
=2E There are also &#8220;Spark now wit=
h 100% of pro users&#8221; type rollou=
t notes with infra instability caveats (</span><a href=3D"https://substack.=
com/redirect/b20f5030-1e11-46bf-941f-cee142c509b3?j=3DeyJ1IjoiYnBkbncifQ.qT=
voIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea=
;text-decoration: none;">thsottiaux</a><span>).</span></p></li></ul><div st=
yle=3D"font-size: 16px;line-height: 26px;"><hr style=3D"margin: 32px 0;padd=
ing: 0;height: 1px;background: rgb(0,0,0,.1);border: none;"></div><p style=
=3D"margin: 0 0 20px 0;color: rgb(54,55,55);line-height: 26px;font-size: 16=
px;"><strong>Agent frameworks &amp; infra: long-running agents, protocol st=
andardization, and KV-cache as the new scaling wall</strong></p><ul style=
=3D"margin-top: 0;padding: 0;"><li style=3D"margin: 8px 0 0 32px;mso-specia=
l-format: bullet;"><p style=3D"color: rgb(54,55,55);line-height: 26px;margi=
n-bottom: 0;box-sizing: border-box;padding-left: 4px;font-size: 16px;margin=
: 0;"><strong>A2A protocol as &#8220;agent interoperability layer&#8221;</s=
trong><span>: Andrew Ng promoted a new DeepLearning.AI course on </span><st=
rong>Agent2Agent (A2A)</strong><span>, positioning it as a standard for dis=
covery/communication across agent frameworks, mentioning IBM&#8217;s ACP jo=
ining forces with A2A and integration patterns across </span><strong>Google=
 ADK, LangGraph, MCP</strong><span>, and deployment via IBM&#8217;s Agent S=
tack (</span><a href=3D"https://substack.com/redirect/ddaf2c2c-a9e4-4a84-87=
45-1a4004f10eb4?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7=
RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-decoration: none;">AndrewYNg=
</a><span>).</span></p></li><li style=3D"margin: 8px 0 0 32px;mso-special-f=
ormat: bullet;"><p style=3D"margin: 0 0 20px 0;color: rgb(54,55,55);line-he=
ight: 26px;margin-bottom: 0;box-sizing: border-box;padding-left: 4px;font-s=
ize: 16px;"><strong>Long-running agent harnesses are becoming product featu=
res</strong><span>:</span></p><ul style=3D"margin-top: 0;padding: 0;"><li s=
tyle=3D"margin: 8px 0 0 32px;mso-special-format: bullet;"><p style=3D"color=
: rgb(54,55,55);line-height: 26px;margin-bottom: 0;box-sizing: border-box;p=
adding-left: 4px;font-size: 16px;margin: 0;"><span>Cursor launched </span><=
strong>long-running agents</strong><span> and explicitly ties it to a &#822=
0;new harness&#8221; that can complete larger tasks (</span><a href=3D"http=
s://substack.com/redirect/21a43324-6704-4f71-9cf8-90444f8006c4?j=3DeyJ1Ijoi=
YnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"c=
olor: #9333ea;text-decoration: none;">cursor_ai</a><span>).</span></p></li>=
<li style=3D"margin: 8px 0 0 32px;mso-special-format: bullet;"><p style=3D"=
color: rgb(54,55,55);line-height: 26px;margin-bottom: 0;box-sizing: border-=
box;padding-left: 4px;font-size: 16px;margin: 0;"><span>LangChain folks dis=
cuss &#8220;harness engineering&#8221; research: forcing </span><strong>sel=
f-verification/iteration</strong><span>, automated context prefetch, and re=
flection over traces as levers that change outcomes materially (</span><a h=
ref=3D"https://substack.com/redirect/3c3e5cb5-7581-4823-b23f-de43028f8b04?j=
=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D""=
 style=3D"color: #9333ea;text-decoration: none;">Vtrivedy10</a><span>).</sp=
an></p></li><li style=3D"margin: 8px 0 0 32px;mso-special-format: bullet;">=
<p style=3D"color: rgb(54,55,55);line-height: 26px;margin-bottom: 0;box-siz=
ing: border-box;padding-left: 4px;font-size: 16px;margin: 0;"><span>Deepage=
nts added bring-your-own sandboxes (Modal/Daytona/Runloop) for safe code ex=
ecution contexts (</span><a href=3D"https://substack.com/redirect/55b1755f-=
1c36-4742-846a-943177ada6b7?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7=
BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-decoration: none=
;">sydneyrunkle</a><span>).</span></p></li></ul></li><li style=3D"margin: 8=
px 0 0 32px;mso-special-format: bullet;"><p style=3D"margin: 0 0 20px 0;col=
or: rgb(54,55,55);line-height: 26px;margin-bottom: 0;box-sizing: border-box=
;padding-left: 4px;font-size: 16px;"><strong>Serving bottlenecks: KV cache =
&amp; disaggregation</strong><span>:</span></p><ul style=3D"margin-top: 0;p=
adding: 0;"><li style=3D"margin: 8px 0 0 32px;mso-special-format: bullet;">=
<p style=3D"color: rgb(54,55,55);line-height: 26px;margin-bottom: 0;box-siz=
ing: border-box;padding-left: 4px;font-size: 16px;margin: 0;"><span>PyTorch=
 welcomed </span><strong>Mooncake</strong><span> into the ecosystem, descri=
bing it as targeting the &#8220;</span><strong>memory wall</strong><span>&#=
8221; in LLM serving with KVCache transfer/storage, enabling </span><strong=
>prefill/decode disaggregation</strong><span>, global cache reuse, elastic =
expert parallelism, and serving as a fault-tolerant distributed backend com=
patible with </span><strong>SGLang, vLLM, TensorRT-LLM</strong><span> (</sp=
an><a href=3D"https://substack.com/redirect/95ab5022-3d2a-490b-8bca-51dbc2a=
05a5d?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" r=
el=3D"" style=3D"color: #9333ea;text-decoration: none;">PyTorch</a><span>).=
</span></p></li><li style=3D"margin: 8px 0 0 32px;mso-special-format: bulle=
t;"><p style=3D"color: rgb(54,55,55);line-height: 26px;margin-bottom: 0;box=
-sizing: border-box;padding-left: 4px;font-size: 16px;margin: 0;"><span>Moo=
nshot/Kimi highlighted Mooncake&#8217;s origins (Kimi + Tsinghua) and open-=
source trajectory (</span><a href=3D"https://substack.com/redirect/5c208cb8=
-0efa-4c9a-be57-b8b0a164aa4f?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb=
7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-decoration: non=
e;">Kimi_Moonshot</a><span>).</span></p></li></ul></li><li style=3D"margin:=
 8px 0 0 32px;mso-special-format: bullet;"><p style=3D"color: rgb(54,55,55)=
;line-height: 26px;margin-bottom: 0;box-sizing: border-box;padding-left: 4p=
x;font-size: 16px;margin: 0;"><strong>A surprisingly common theme: &#8220;f=
iles as queues&#8221;</strong><span>: A viral thread describes a reliable d=
istributed job queue using </span><strong>object storage + a queue.json</st=
rong><span> (FIFO, at-least-once) as a minimalist primitive (</span><a href=
=3D"https://substack.com/redirect/98e38228-35c5-4188-b422-83473a4d2042?j=3D=
eyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" st=
yle=3D"color: #9333ea;text-decoration: none;">turbopuffer</a><span>). Anoth=
er tweet claims Claude Code &#8220;agent teams&#8221; communicate by writin=
g JSON files on disk, emphasizing &#8220;no Redis required&#8221; CLI ergon=
omics (</span><a href=3D"https://substack.com/redirect/9e37b11d-6be6-4d41-a=
7be-0a352540a59b?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz=
7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-decoration: none;">peter675=
9</a><span>).</span></p></li></ul><div style=3D"font-size: 16px;line-height=
: 26px;"><hr style=3D"margin: 32px 0;padding: 0;height: 1px;background: rgb=
(0,0,0,.1);border: none;"></div><p style=3D"margin: 0 0 20px 0;color: rgb(5=
4,55,55);line-height: 26px;font-size: 16px;"><strong>Research notes: small =
theorem provers + label-free vision training + RL algorithms for verifiable=
 reasoning</strong></p><ul style=3D"margin-top: 0;padding: 0;"><li style=3D=
"margin: 8px 0 0 32px;mso-special-format: bullet;"><p style=3D"color: rgb(5=
4,55,55);line-height: 26px;margin-bottom: 0;box-sizing: border-box;padding-=
left: 4px;font-size: 16px;margin: 0;"><strong>QED-Nano: 4B theorem proving =
with heavy test-time compute</strong><span>: A set of tweets introduces </s=
pan><strong>QED-Nano</strong><span>, a </span><strong>4B</strong><span> nat=
ural-language theorem-proving model that matches larger systems on </span><=
strong>IMO-ProofBench</strong><span> and uses an </span><strong>agent scaff=
old scaling to &gt;1M tokens per proof</strong><span>, with RL post-trainin=
g &#8220;rubrics as rewards.&#8221; They promise open-source weights and tr=
aining artifacts soon (</span><a href=3D"https://substack.com/redirect/ad8e=
4d27-8b5a-4135-8582-d3dcc7fec2d1?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34Ce=
FwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-decoration:=
 none;"> _lewtun</a><span>, </span><a href=3D"https://substack.com/redirect=
/14ccc588-3c86-4311-9327-8619d9b8df66?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9T=
d34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-decora=
tion: none;">_lewtun</a><span>, </span><a href=3D"https://substack.com/redi=
rect/5a26fe31-6d14-42fe-94c9-e87f78dedef6?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U=
3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-de=
coration: none;">setlur_amrith</a><span>, </span><a href=3D"https://substac=
k.com/redirect/a887dee1-5e74-48b3-9768-e5e685a3a9ca?j=3DeyJ1IjoiYnBkbncifQ.=
qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333=
ea;text-decoration: none;">aviral_kumar2</a><span>).</span></p></li><li sty=
le=3D"margin: 8px 0 0 32px;mso-special-format: bullet;"><p style=3D"color: =
rgb(54,55,55);line-height: 26px;margin-bottom: 0;box-sizing: border-box;pad=
ding-left: 4px;font-size: 16px;margin: 0;"><strong>LeJEPA: simplifying self=
-supervised vision</strong><span>: NYU Data Science highlights LeJEPA (Yann=
 LeCun + collaborators) as a simpler label-free training method that drops =
many tricks but scales well and performs competitively on ImageNet (</span>=
<a href=3D"https://substack.com/redirect/528905b8-ab24-4f3b-8eb1-2d99c76418=
d9?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=
=3D"" style=3D"color: #9333ea;text-decoration: none;">NYUDataScience</a><sp=
an>).</span></p></li><li style=3D"margin: 8px 0 0 32px;mso-special-format: =
bullet;"><p style=3D"color: rgb(54,55,55);line-height: 26px;margin-bottom: =
0;box-sizing: border-box;padding-left: 4px;font-size: 16px;margin: 0;"><str=
ong>Recursive/agentic evaluation discourse</strong><span>: Multiple tweets =
debate </span><strong>recursive language models (RLMs)</strong><span> and s=
tateful REPL loops as a way to manage long-horizon tasks outside the contex=
t window (</span><a href=3D"https://substack.com/redirect/d114d27d-6972-42e=
e-94c6-4e4b0b122119?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-P=
Niz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-decoration: none;">latei=
nteraction</a><span>, </span><a href=3D"https://substack.com/redirect/7f444=
708-42a0-427c-a97a-3de8112ef9d9?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeF=
wYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-decoration: =
none;">deepfates</a><span>, </span><a href=3D"https://substack.com/redirect=
/2789b609-af00-4316-b0e4-ac02cb262199?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9T=
d34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-decora=
tion: none;">lateinteraction</a><span>).</span></p></li></ul><div style=3D"=
font-size: 16px;line-height: 26px;"><hr style=3D"margin: 32px 0;padding: 0;=
height: 1px;background: rgb(0,0,0,.1);border: none;"></div><p style=3D"marg=
in: 0 0 20px 0;color: rgb(54,55,55);line-height: 26px;font-size: 16px;"><st=
rong>Top tweets (by engagement)</strong></p><ul style=3D"margin-top: 0;padd=
ing: 0;"><li style=3D"margin: 8px 0 0 32px;mso-special-format: bullet;"><p =
style=3D"color: rgb(54,55,55);line-height: 26px;margin-bottom: 0;box-sizing=
: border-box;padding-left: 4px;font-size: 16px;margin: 0;"><strong>Gemini 3=
 Deep Think upgrade + sketch&#8594;STL demo</strong><span>: </span><a href=
=3D"https://substack.com/redirect/22b0310e-5508-4d03-9091-4a795c8a02ad?j=3D=
eyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" st=
yle=3D"color: #9333ea;text-decoration: none;">@GeminiApp</a></p></li><li st=
yle=3D"margin: 8px 0 0 32px;mso-special-format: bullet;"><p style=3D"color:=
 rgb(54,55,55);line-height: 26px;margin-bottom: 0;box-sizing: border-box;pa=
dding-left: 4px;font-size: 16px;margin: 0;"><strong>OpenAI Codex-Spark anno=
uncement</strong><span>: </span><a href=3D"https://substack.com/redirect/81=
549586-2231-4d26-b03d-c3bf9368f408?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34=
CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-decoratio=
n: none;">@OpenAI</a><span>, </span><a href=3D"https://substack.com/redirec=
t/761f86ff-29bf-42bb-9c60-25adcc14a7f6?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9=
Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-decor=
ation: none;">@OpenAIDevs</a><span>, </span><a href=3D"https://substack.com=
/redirect/4e530c8e-7f73-48aa-bdc3-647b1796aae5?j=3DeyJ1IjoiYnBkbncifQ.qTvoI=
Djk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;te=
xt-decoration: none;">@sama</a></p></li><li style=3D"margin: 8px 0 0 32px;m=
so-special-format: bullet;"><p style=3D"color: rgb(54,55,55);line-height: 2=
6px;margin-bottom: 0;box-sizing: border-box;padding-left: 4px;font-size: 16=
px;margin: 0;"><strong>Anthropic funding/valuation</strong><span>: </span><=
a href=3D"https://substack.com/redirect/4ec93e36-d831-4187-9ded-899a74a246f=
1?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=
=3D"" style=3D"color: #9333ea;text-decoration: none;">@AnthropicAI</a></p><=
/li><li style=3D"margin: 8px 0 0 32px;mso-special-format: bullet;"><p style=
=3D"color: rgb(54,55,55);line-height: 26px;margin-bottom: 0;box-sizing: bor=
der-box;padding-left: 4px;font-size: 16px;margin: 0;"><strong>Gemini Deep T=
hink &#8220;unprecedented 84.6% ARC-AGI-2&#8221;</strong><span>: </span><a =
href=3D"https://substack.com/redirect/150eedc9-c9e4-4e2b-a0ad-c6da107534eb?=
j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"=
" style=3D"color: #9333ea;text-decoration: none;">@sundarpichai</a></p></li=
><li style=3D"margin: 8px 0 0 32px;mso-special-format: bullet;"><p style=3D=
"color: rgb(54,55,55);line-height: 26px;margin-bottom: 0;box-sizing: border=
-box;padding-left: 4px;font-size: 16px;margin: 0;"><strong>Simile launch + =
$100M raise; simulation framing</strong><span>: </span><a href=3D"https://s=
ubstack.com/redirect/fcf7270e-251d-4c45-9f0e-dddd42082f28?j=3DeyJ1IjoiYnBkb=
ncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color:=
 #9333ea;text-decoration: none;">@joon_s_pk</a><span>, </span><a href=3D"ht=
tps://substack.com/redirect/82bdbf26-dbd6-4eeb-a07b-999e417b2618?j=3DeyJ1Ij=
oiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D=
"color: #9333ea;text-decoration: none;">@karpathy</a></p></li></ul><p style=
=3D"margin: 0 0 20px 0;color: rgb(54,55,55);line-height: 26px;font-size: 16=
px;"></p><div class=3D"paywall-jump" data-component-name=3D"PaywallToDOM" s=
tyle=3D"font-size: 16px;line-height: 26px;display: none;"></div><div style=
=3D"font-size: 16px;line-height: 26px;"><hr style=3D"margin: 32px 0;padding=
: 0;height: 1px;background: rgb(0,0,0,.1);border: none;"></div><h1 class=3D=
"header-anchor-post" style=3D"position: relative;font-family: 'SF Pro Displ=
ay',-apple-system-headline,system-ui,-apple-system,BlinkMacSystemFont,'Sego=
e UI',Roboto,Helvetica,Arial,sans-serif,'Apple Color Emoji','Segoe UI Emoji=
','Segoe UI Symbol';font-weight: bold;-webkit-font-smoothing: antialiased;-=
moz-osx-font-smoothing: antialiased;-webkit-appearance: optimizelegibility;=
-moz-appearance: optimizelegibility;appearance: optimizelegibility;margin: =
1em 0 0.625em 0;color: rgb(54,55,55);line-height: 1.16em;font-size: 2em;"><=
strong>AI Reddit Recap</strong></h1><h2 class=3D"header-anchor-post" style=
=3D"position: relative;font-family: 'SF Pro Display',-apple-system-headline=
,system-ui,-apple-system,BlinkMacSystemFont,'Segoe UI',Roboto,Helvetica,Ari=
al,sans-serif,'Apple Color Emoji','Segoe UI Emoji','Segoe UI Symbol';font-w=
eight: bold;-webkit-font-smoothing: antialiased;-moz-osx-font-smoothing: an=
tialiased;-webkit-appearance: optimizelegibility;-moz-appearance: optimizel=
egibility;appearance: optimizelegibility;margin: 1em 0 0.625em 0;color: rgb=
(54,55,55);line-height: 1.16em;font-size: 1.625em;"><strong>/r/LocalLlama +=
 /r/localLLM Recap</strong></h2><h3 class=3D"header-anchor-post" style=3D"p=
osition: relative;font-family: 'SF Pro Display',-apple-system-headline,syst=
em-ui,-apple-system,BlinkMacSystemFont,'Segoe UI',Roboto,Helvetica,Arial,sa=
ns-serif,'Apple Color Emoji','Segoe UI Emoji','Segoe UI Symbol';font-weight=
: bold;-webkit-font-smoothing: antialiased;-moz-osx-font-smoothing: antiali=
ased;-webkit-appearance: optimizelegibility;-moz-appearance: optimizelegibi=
lity;appearance: optimizelegibility;margin: 1em 0 0.625em 0;color: rgb(54,5=
5,55);line-height: 1.16em;font-size: 1.375em;"><strong>1. GLM-5 Model Launc=
h and Benchmarks</strong></h3><ul style=3D"margin-top: 0;padding: 0;"><li s=
tyle=3D"margin: 8px 0 0 32px;mso-special-format: bullet;"><p style=3D"margi=
n: 0 0 20px 0;color: rgb(54,55,55);line-height: 26px;margin-bottom: 0;box-s=
izing: border-box;padding-left: 4px;font-size: 16px;"><strong><a href=3D"ht=
tps://substack.com/redirect/e67b72b4-ac0e-4f07-b325-799a940d177f?j=3DeyJ1Ij=
oiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D=
"color: #9333ea;text-decoration: none;">Unsloth just unleashed Glm 5! GGUF =
NOW!</a></strong><span> (Activity: 446): </span><strong>The image presents =
a benchmark comparison table for various AI models, highlighting the perfor=
mance of GLM-5 against other models like GLM-4.7, DeepSeek-V3.2, Kimi K2.5,=
 Claude Opus 4.5, Gemini 3.0 Pro, and GPT-5.2. The table categorizes perfor=
mance into areas such as Reasoning, Coding, and General Agent, with GLM-5 s=
howing particularly strong results in the Reasoning category. Additionally,=
 the table provides a cost comparison, suggesting that GLM-5 offers competi=
tive performance at a potentially lower cost.</strong><span> One comment hu=
morously suggests the need for a data center to run these models, indicatin=
g the high computational requirements. Another comment questions the feasib=
ility of running the model on a low-end GPU like the GT 710, highlighting c=
oncerns about accessibility and hardware demands.</span></p><ul style=3D"ma=
rgin-top: 0;padding: 0;"><li style=3D"margin: 8px 0 0 32px;mso-special-form=
at: bullet;"><p style=3D"color: rgb(54,55,55);line-height: 26px;margin-bott=
om: 0;box-sizing: border-box;padding-left: 4px;font-size: 16px;margin: 0;">=
<span>A user inquired whether the new Glm 5 model requires any implementati=
on changes in </span><code>llama.cpp</code><span>, suggesting that the mode=
l might be compatible without additional modifications. This could imply ea=
se of integration for developers already using </span><code>llama.cpp</code=
><span> for other models.</span></p></li><li style=3D"margin: 8px 0 0 32px;=
mso-special-format: bullet;"><p style=3D"color: rgb(54,55,55);line-height: =
26px;margin-bottom: 0;box-sizing: border-box;padding-left: 4px;font-size: 1=
6px;margin: 0;"><span>Another user humorously questioned if the Glm 5 model=
 could run on a </span><code>GT 710</code><span> graphics card, which is kn=
own for its limited computational power. This highlights the potential hard=
ware requirements and limitations for running such advanced models, suggest=
ing that more powerful GPUs might be necessary.</span></p></li><li style=3D=
"margin: 8px 0 0 32px;mso-special-format: bullet;"><p style=3D"color: rgb(5=
4,55,55);line-height: 26px;margin-bottom: 0;box-sizing: border-box;padding-=
left: 4px;font-size: 16px;margin: 0;"><span>The release of Glm 5 in </span>=
<code>GGUF</code><span> format suggests a focus on optimized performance an=
d compatibility. GGUF, being a format designed for efficient model storage =
and execution, indicates that Glm 5 might offer improved performance metric=
s or reduced resource consumption compared to previous versions.</span></p>=
</li></ul></li><li style=3D"margin: 8px 0 0 32px;mso-special-format: bullet=
;"><p style=3D"margin: 0 0 20px 0;color: rgb(54,55,55);line-height: 26px;ma=
rgin-bottom: 0;box-sizing: border-box;padding-left: 4px;font-size: 16px;"><=
strong><a href=3D"https://substack.com/redirect/7b235842-d99f-4411-9c41-df1=
4cf888d26?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x=
0" rel=3D"" style=3D"color: #9333ea;text-decoration: none;">GLM-5 scores 50=
 on the Intelligence Index and is the new open weights leader!</a></strong>=
<span> (Activity: 892): </span><strong>The image highlights the performance=
 of GLM-5, which scores </strong><code>50</code><strong> on the Intelligenc=
e Index, positioning it as the leading model among open weights. This is si=
gnificant as it surpasses other models like Opus 4.5 and GPT-5.2-xhigh, ind=
icating a strong performance in AI evaluations. Notably, GLM-5 also has the=
 lowest hallucination rate on the AA-Omniscience benchmark, showcasing its =
accuracy and reliability in generating outputs. The discussion suggests tha=
t open-source models are closing the gap with proprietary ones, with upcomi=
ng models like Deepseek-V4 expected to use similar architectures but on a l=
arger scale.</strong><span> Commenters note the narrowing performance gap b=
etween open-source and closed-source models, with some anticipating further=
 advancements in open-source AI capabilities.</span></p><ul style=3D"margin=
-top: 0;padding: 0;"><li style=3D"margin: 8px 0 0 32px;mso-special-format: =
bullet;"><p style=3D"color: rgb(54,55,55);line-height: 26px;margin-bottom: =
0;box-sizing: border-box;padding-left: 4px;font-size: 16px;margin: 0;">GLM-=
5 is noted for having the lowest hallucination rate on the AA-Omniscience b=
enchmark, which is a significant achievement in reducing errors in AI-gener=
ated content. This positions GLM-5 as a leader in accuracy among open-weigh=
t models, surpassing models like Opus 4.5 and GPT-5.2-xhigh.</p></li><li st=
yle=3D"margin: 8px 0 0 32px;mso-special-format: bullet;"><p style=3D"color:=
 rgb(54,55,55);line-height: 26px;margin-bottom: 0;box-sizing: border-box;pa=
dding-left: 4px;font-size: 16px;margin: 0;">The open-source AI community is=
 rapidly closing the gap with closed-source models, now trailing by only ab=
out three months. This is evidenced by the upcoming release of DeepSeek v4,=
 which will utilize the same DSA architecture as GLM-5 but on a larger scal=
e, indicating a trend towards more powerful open-source models.</p></li><li=
 style=3D"margin: 8px 0 0 32px;mso-special-format: bullet;"><p style=3D"col=
or: rgb(54,55,55);line-height: 26px;margin-bottom: 0;box-sizing: border-box=
;padding-left: 4px;font-size: 16px;margin: 0;">There is a desire within the=
 community for transparency regarding the hardware requirements of these ad=
vanced models, as expressed by users who wish for detailed specifications, =
such as memory requirements, to be published alongside model announcements.=
</p></li></ul></li></ul><h3 class=3D"header-anchor-post" style=3D"position:=
 relative;font-family: 'SF Pro Display',-apple-system-headline,system-ui,-a=
pple-system,BlinkMacSystemFont,'Segoe UI',Roboto,Helvetica,Arial,sans-serif=
,'Apple Color Emoji','Segoe UI Emoji','Segoe UI Symbol';font-weight: bold;-=
webkit-font-smoothing: antialiased;-moz-osx-font-smoothing: antialiased;-we=
bkit-appearance: optimizelegibility;-moz-appearance: optimizelegibility;app=
earance: optimizelegibility;margin: 1em 0 0.625em 0;color: rgb(54,55,55);li=
ne-height: 1.16em;font-size: 1.375em;"><strong>2. MiniMax M2.5 Release and =
Discussion</strong></h3><ul style=3D"margin-top: 0;padding: 0;"><li style=
=3D"margin: 8px 0 0 32px;mso-special-format: bullet;"><p style=3D"margin: 0=
 0 20px 0;color: rgb(54,55,55);line-height: 26px;margin-bottom: 0;box-sizin=
g: border-box;padding-left: 4px;font-size: 16px;"><strong><a href=3D"https:=
//substack.com/redirect/6ce05a26-18af-434a-9fc9-3c303b504a67?j=3DeyJ1IjoiYn=
BkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"col=
or: #9333ea;text-decoration: none;">MiniMaxAI MiniMax-M2.5 has 230b paramet=
ers and 10b active parameters</a></strong><span> (Activity: 436): </span><s=
trong>OpenHands has announced the MiniMax-M2.5 model, which features </stro=
ng><code>230 billion parameters</code><strong> with </strong><code>10 billi=
on active parameters</code><strong>. This model is noted for its competitiv=
e performance, ranking fourth in the OpenHands Index, and is significantly =
cost-effective, being </strong><code>13 times cheaper</code><strong> than C=
laude Opus. It excels in software engineering tasks, particularly in app de=
velopment and issue resolution, but has room for improvement in generalizat=
ion tasks. The model is accessible for free on the OpenHands Cloud for a li=
mited time, enhancing its accessibility for developers.</strong><span> Comm=
enters are optimistic about the potential of the MiniMax-M2.5 model, with s=
uggestions to integrate it with </span><strong>Cerebras</strong><span> tech=
nology for enhanced performance and efficiency, particularly for users with=
 </span><code>128GB</code><span> machines.</span></p><ul style=3D"margin-to=
p: 0;padding: 0;"><li style=3D"margin: 8px 0 0 32px;mso-special-format: bul=
let;"><p style=3D"color: rgb(54,55,55);line-height: 26px;margin-bottom: 0;b=
ox-sizing: border-box;padding-left: 4px;font-size: 16px;margin: 0;"><span>L=
ook_0ver_There discusses the potential for a hybrid model using the MiniMax=
-M2.5&#8217;s architecture, suggesting that a </span><code>~160B</code><spa=
n> REAP/REAM hybrid could be developed with minimal performance loss. They =
propose that such a model could be quantized to run efficiently on </span><=
code>128GB</code><span> machines, allowing for deep-context tool use, which=
 would be beneficial for users with limited hardware resources.</span></p><=
/li><li style=3D"margin: 8px 0 0 32px;mso-special-format: bullet;"><p style=
=3D"color: rgb(54,55,55);line-height: 26px;margin-bottom: 0;box-sizing: bor=
der-box;padding-left: 4px;font-size: 16px;margin: 0;"><span>Rascazzione hig=
hlights the achievement of the MiniMax-M2.5 model, noting its efficiency co=
mpared to other models like GLM, which required doubling its parameters to =
evolve, and Kimi, which has </span><code>1T</code><span> parameters. They e=
mphasize that if the quality and size of MiniMax-M2.5 are confirmed, it rep=
resents a significant advancement in AI model development.</span></p></li><=
li style=3D"margin: 8px 0 0 32px;mso-special-format: bullet;"><p style=3D"c=
olor: rgb(54,55,55);line-height: 26px;margin-bottom: 0;box-sizing: border-b=
ox;padding-left: 4px;font-size: 16px;margin: 0;"><span>eviloni points out t=
hat with only </span><code>10b</code><span> active parameters, the MiniMax-=
M2.5 should achieve decent speed even on non-high-end GPUs. They suggest th=
at this performance could improve further with quantized versions, making t=
he model more accessible to users without cutting-edge hardware.</span></p>=
</li></ul></li><li style=3D"margin: 8px 0 0 32px;mso-special-format: bullet=
;"><p style=3D"margin: 0 0 20px 0;color: rgb(54,55,55);line-height: 26px;ma=
rgin-bottom: 0;box-sizing: border-box;padding-left: 4px;font-size: 16px;"><=
strong><a href=3D"https://substack.com/redirect/5a19e178-e650-4b7d-acb8-498=
90907152b?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x=
0" rel=3D"" style=3D"color: #9333ea;text-decoration: none;">Minimax M2.5 Of=
ficially Out</a></strong><span> (Activity: 664): </span><strong>Minimax M2.=
5 has been officially released, showcasing impressive benchmark results: </=
strong><code>SWE-Bench Verified</code><strong> at </strong><code>80.2%</cod=
e><strong>, </strong><code>Multi-SWE-Bench</code><strong> at </strong><code=
>51.3%</code><strong>, and </strong><code>BrowseComp</code><strong> at </st=
rong><code>76.3%</code><strong>. The model is noted for its cost efficiency=
, with operational costs significantly lower than competitors like Opus, Ge=
mini 3 Pro, and GPT-5. At </strong><code>100 output tokens per second</code=
><strong>, the cost is </strong><code>$1 per hour</code><strong>, and at </=
strong><code>50 TPS</code><strong>, it drops to </strong><code>$0.3</code><=
strong>, allowing for four instances to run continuously for a year at </st=
rong><code>$10,000</code><strong><span>. More details can be found on the <=
/span><a href=3D"https://substack.com/redirect/dfab3953-9d07-417d-808e-e437=
f231876a?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0=
" rel=3D"" style=3D"color: #9333ea;text-decoration: none;">official Minimax=
 page</a><span>.</span></strong><span> Commenters highlight the potential g=
ame-changing nature of Minimax M2.5 due to its cost efficiency compared to =
other models, and there is anticipation for the release of open weights on =
platforms like Hugging Face.</span></p><ul style=3D"margin-top: 0;padding: =
0;"><li style=3D"margin: 8px 0 0 32px;mso-special-format: bullet;"><p style=
=3D"color: rgb(54,55,55);line-height: 26px;margin-bottom: 0;box-sizing: bor=
der-box;padding-left: 4px;font-size: 16px;margin: 0;">The Minimax M2.5 is h=
ighlighted for its cost-effectiveness, with operational costs significantly=
 lower than competitors like Opus, Gemini 3 Pro, and GPT-5. Specifically, r=
unning M2.5 at 100 tokens per second costs $1 per hour, and at 50 tokens pe=
r second, it costs $0.3 per hour. This translates to a yearly cost of $10,0=
00 for four instances running continuously, which is a substantial reductio=
n compared to other models.</p></li><li style=3D"margin: 8px 0 0 32px;mso-s=
pecial-format: bullet;"><p style=3D"color: rgb(54,55,55);line-height: 26px;=
margin-bottom: 0;box-sizing: border-box;padding-left: 4px;font-size: 16px;m=
argin: 0;">There is anticipation for the release of open weights on Hugging=
 Face, which would allow for broader experimentation and integration into v=
arious applications. This is a common expectation in the AI community for n=
ew models to facilitate transparency and reproducibility.</p></li><li style=
=3D"margin: 8px 0 0 32px;mso-special-format: bullet;"><p style=3D"color: rg=
b(54,55,55);line-height: 26px;margin-bottom: 0;box-sizing: border-box;paddi=
ng-left: 4px;font-size: 16px;margin: 0;">The potential impact of Minimax M2=
=2E5 on existing models like GLM 5.0 an=
d Kimi 2.5 is discussed, with some use=
rs suggesting that if the benchmarks are accurate, M2.5 could surpass these=
 models in popularity due to its ease of use and cost advantages. This coul=
d shift the landscape of preferred local models, as users currently favor m=
odels like Kimi 2.5 and DeepSeekv3.2.</p></li></ul></li><li style=3D"margin=
: 8px 0 0 32px;mso-special-format: bullet;"><p style=3D"color: rgb(54,55,55=
);line-height: 26px;margin-bottom: 0;box-sizing: border-box;padding-left: 4=
px;font-size: 16px;margin: 0;"><strong><a href=3D"https://substack.com/redi=
rect/60a6b7fe-9ddb-4dc9-b7cc-ffe31da9ba59?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U=
3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-de=
coration: none;">GLM 5.0 &amp; MiniMax 2.5 Just Dropped, Are We Entering Ch=
ina&#8217;s Agent War Era?</a></strong><span> (Activity: 465): </span><stro=
ng>GLM 5.0 and MiniMax 2.5 have been released, marking a shift towards agen=
t-style workflows in AI development. GLM 5.0 focuses on enhanced reasoning =
and coding capabilities, while MiniMax 2.5 is designed for task decompositi=
on and extended execution times. This evolution suggests a competitive land=
scape moving from generating better responses to completing complex tasks. =
Testing plans include API benchmarks, multi-agent orchestration with Verden=
t, IDE workflows similar to Cursor, and infrastructure routing with ZenMux =
to evaluate their performance on long-duration tasks and repository-level c=
hanges.</strong><span> The comments highlight a broader context of AI devel=
opment in China, mentioning other recent releases like Seedance 2.0 and Qwe=
n-image 2.0, suggesting a vibrant and competitive AI ecosystem. There&#8217=
;s also a sentiment that this competition benefits end-users by driving inn=
ovation.</span></p></li></ul><h3 class=3D"header-anchor-post" style=3D"posi=
tion: relative;font-family: 'SF Pro Display',-apple-system-headline,system-=
ui,-apple-system,BlinkMacSystemFont,'Segoe UI',Roboto,Helvetica,Arial,sans-=
serif,'Apple Color Emoji','Segoe UI Emoji','Segoe UI Symbol';font-weight: b=
old;-webkit-font-smoothing: antialiased;-moz-osx-font-smoothing: antialiase=
d;-webkit-appearance: optimizelegibility;-moz-appearance: optimizelegibilit=
y;appearance: optimizelegibility;margin: 1em 0 0.625em 0;color: rgb(54,55,5=
5);line-height: 1.16em;font-size: 1.375em;"><strong>3. AI Model Identity an=
d Community Concerns</strong></h3><ul style=3D"margin-top: 0;padding: 0;"><=
li style=3D"margin: 8px 0 0 32px;mso-special-format: bullet;"><p style=3D"m=
argin: 0 0 20px 0;color: rgb(54,55,55);line-height: 26px;margin-bottom: 0;b=
ox-sizing: border-box;padding-left: 4px;font-size: 16px;"><strong><a href=
=3D"https://substack.com/redirect/4753aa3b-18b1-4a0a-b436-0fde132b09bc?j=3D=
eyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" st=
yle=3D"color: #9333ea;text-decoration: none;">Why do we allow &#8220;un-loc=
al&#8221; content</a></strong><span> (Activity: 466): </span><strong>The po=
st discusses the concern of &#8216;un-local&#8217; content in a subreddit f=
ocused on local AI models, suggesting that posts linking to API resources s=
hould also include links to downloadable model weights, such as those on Hu=
gging Face. The author argues that this would prevent the subreddit from be=
coming a platform for marketing rather than technical discussion. The debat=
e centers on whether posts about models without released weights should be =
allowed, with some agreeing that such posts should be tied back to local re=
levance, even if the models are not immediately available for local use. Th=
e discussion highlights a need for a balance between maintaining the subred=
dit&#8217;s focus on local models and allowing discussions on potentially r=
elevant advancements.</strong><span> Commenters generally agree with the ne=
ed for a framework to prioritize &#8216;local&#8217; content, but acknowled=
ge the difficulty in drawing strict boundaries. Some suggest that posts abo=
ut models with pending weight releases should be allowed if they are likely=
 to become relevant to local use. The moderation team emphasizes the import=
ance of staying true to the sub&#8217;s spirit rather than strictly adherin=
g to its original intent, to keep the community active and relevant.</span>=
</p><ul style=3D"margin-top: 0;padding: 0;"><li style=3D"margin: 8px 0 0 32=
px;mso-special-format: bullet;"><p style=3D"color: rgb(54,55,55);line-heigh=
t: 26px;margin-bottom: 0;box-sizing: border-box;padding-left: 4px;font-size=
: 16px;margin: 0;">The discussion highlights a framework for determining th=
e relevance of posts to a local-focused subreddit. It suggests that purely =
local content, such as running models on specific hardware and benchmarks, =
should be prioritized. However, posts about non-local models or breakthroug=
hs should be allowed if they can be tied back to local implications, such a=
s potential future applications or relevance to local models.</p></li><li s=
tyle=3D"margin: 8px 0 0 32px;mso-special-format: bullet;"><p style=3D"color=
: rgb(54,55,55);line-height: 26px;margin-bottom: 0;box-sizing: border-box;p=
adding-left: 4px;font-size: 16px;margin: 0;">A consensus among moderators i=
s mentioned, emphasizing the importance of allowing content that is adjacen=
t or relevant to the local ecosystem. The discussion acknowledges the diffi=
culty in drawing strict boundaries, as the relevance of certain models or a=
nnouncements can vary. For instance, the announcement of Minimax M2.5 ahead=
 of its weights release poses a challenge in determining its local relevanc=
e.</p></li><li style=3D"margin: 8px 0 0 32px;mso-special-format: bullet;"><=
p style=3D"color: rgb(54,55,55);line-height: 26px;margin-bottom: 0;box-sizi=
ng: border-box;padding-left: 4px;font-size: 16px;margin: 0;">The moderation=
 team has debated the balance between maintaining the subreddit&#8217;s ori=
ginal focus and adapting to current trends. They argue that strict adherenc=
e to the original intent could lead to the subreddit&#8217;s decline, as se=
en with the diminishing relevance of models like Llama. The focus is on mai=
ntaining the spirit of the subreddit rather than strict rules, allowing for=
 flexibility in content relevance.</p></li></ul></li><li style=3D"margin: 8=
px 0 0 32px;mso-special-format: bullet;"><p style=3D"margin: 0 0 20px 0;col=
or: rgb(54,55,55);line-height: 26px;margin-bottom: 0;box-sizing: border-box=
;padding-left: 4px;font-size: 16px;"><strong><a href=3D"https://substack.co=
m/redirect/a31797f4-a15c-429e-b6eb-40fb6b2906d7?j=3DeyJ1IjoiYnBkbncifQ.qTvo=
IDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;t=
ext-decoration: none;">GLM thinks its Gemini</a></strong><span> (Activity: =
354): </span><strong>The image depicts a chat interface where a language mo=
del initially identifies itself as GLM-5 but then corrects itself to say it=
 is actually Gemini, a large language model developed by Google. This raise=
s questions about the model&#8217;s identity and the potential use of Gemin=
i in either distilling GLM or generating synthetic data. The comments highl=
ight a common issue where users ask language models to identify themselves,=
 which they typically cannot do accurately due to context limitations.</str=
ong><span> One comment suggests that the model&#8217;s response might be in=
fluenced by non-empty context, implying that the model&#8217;s identity con=
fusion could be due to prior interactions or prompts.</span></p><ul style=
=3D"margin-top: 0;padding: 0;"><li style=3D"margin: 8px 0 0 32px;mso-specia=
l-format: bullet;"><p style=3D"color: rgb(54,55,55);line-height: 26px;margi=
n-bottom: 0;box-sizing: border-box;padding-left: 4px;font-size: 16px;margin=
: 0;">NoobMLDude raises a technical inquiry about the relationship between =
GLM and Gemini, questioning whether GLM is distilled from Gemini outputs or=
 if Gemini is used in generating synthetic data. This suggests a curiosity =
about the training processes and data sources involved in developing these =
models, which could impact their performance and capabilities.</p></li></ul=
></li></ul><h2 class=3D"header-anchor-post" style=3D"position: relative;fon=
t-family: 'SF Pro Display',-apple-system-headline,system-ui,-apple-system,B=
linkMacSystemFont,'Segoe UI',Roboto,Helvetica,Arial,sans-serif,'Apple Color=
 Emoji','Segoe UI Emoji','Segoe UI Symbol';font-weight: bold;-webkit-font-s=
moothing: antialiased;-moz-osx-font-smoothing: antialiased;-webkit-appearan=
ce: optimizelegibility;-moz-appearance: optimizelegibility;appearance: opti=
mizelegibility;margin: 1em 0 0.625em 0;color: rgb(54,55,55);line-height: 1.=
16em;font-size: 1.625em;"><strong>Less Technical AI Subreddit Recap</strong=
></h2><blockquote style=3D"border-left: 4px solid #9333ea;margin: 20px 0;pa=
dding: 0;"><p style=3D"margin: 0 0 20px 0;color: rgb(54,55,55);margin-left:=
 20px;line-height: 26px;font-size: 16px;">/r/Singularity, /r/Oobabooga, /r/=
MachineLearning, /r/OpenAI, /r/ClaudeAI, /r/StableDiffusion, /r/ChatGPT, /r=
/ChatGPTCoding, /r/aivideo, /r/aivideo</p></blockquote><h3 class=3D"header-=
anchor-post" style=3D"position: relative;font-family: 'SF Pro Display',-app=
le-system-headline,system-ui,-apple-system,BlinkMacSystemFont,'Segoe UI',Ro=
boto,Helvetica,Arial,sans-serif,'Apple Color Emoji','Segoe UI Emoji','Segoe=
 UI Symbol';font-weight: bold;-webkit-font-smoothing: antialiased;-moz-osx-=
font-smoothing: antialiased;-webkit-appearance: optimizelegibility;-moz-app=
earance: optimizelegibility;appearance: optimizelegibility;margin: 1em 0 0.=
625em 0;color: rgb(54,55,55);line-height: 1.16em;font-size: 1.375em;"><stro=
ng>1. AI Model Launches and Performance Comparisons</strong></h3><ul style=
=3D"margin-top: 0;padding: 0;"><li style=3D"margin: 8px 0 0 32px;mso-specia=
l-format: bullet;"><p style=3D"color: rgb(54,55,55);line-height: 26px;margi=
n-bottom: 0;box-sizing: border-box;padding-left: 4px;font-size: 16px;margin=
: 0;"><strong><a href=3D"https://substack.com/redirect/607936ac-029a-4642-a=
f2d-9b604e308018?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz=
7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-decoration: none;">Anthropi=
c raises $30B, Elon crashes out</a></strong><span> (Activity: 4819): </span=
><strong>The image is a meme featuring a fictional tweet from Anthropic ann=
ouncing a $30 billion funding round, valuing the company at $380 billion. T=
his is a satirical take, as such a funding round and valuation are not real=
=2E The tweet humorously suggests that=20=
the funds will be used for research, p=
roduct innovation, and infrastructure expansion. Elon Musk is depicted as r=
esponding critically, accusing Anthropic&#8217;s AI of being biased and lab=
eling it as &#8216;misanthropic and evil,&#8217; which is a play on words w=
ith the company&#8217;s name. This meme is likely a commentary on the compe=
titive and sometimes contentious nature of AI development and funding, as w=
ell as Musk&#8217;s outspoken views on AI ethics and bias.</strong><span> T=
he comments reflect a mix of confusion and humor, with one user questioning=
 a reference to &#8216;Name of the Wind,&#8217; a fantasy novel, suggesting=
 it is unrelated to the topic. Another comment suggests that Musk&#8217;s r=
esponse is a projection of his own insecurities, while a third implies jeal=
ousy on Musk&#8217;s part.</span></p></li><li style=3D"margin: 8px 0 0 32px=
;mso-special-format: bullet;"><p style=3D"margin: 0 0 20px 0;color: rgb(54,=
55,55);line-height: 26px;margin-bottom: 0;box-sizing: border-box;padding-le=
ft: 4px;font-size: 16px;"><strong><a href=3D"https://substack.com/redirect/=
b70ffc7a-525f-4c7c-b706-9f25ec123650?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td=
34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-decorat=
ion: none;">Introducing Simile - The Simulation Company</a></strong><span> =
(Activity: 504): </span><strong>Simile has introduced an AI-based simulatio=
n platform designed to model societal behaviors and predict human actions a=
t scale. The company has developed a foundation model that uses generative =
agents to simulate real people with high accuracy, allowing organizations t=
o test decisions before implementation. This approach is already being util=
ized by companies for applications such as earnings call rehearsals and pol=
icy testing. Simile is supported by $100M in funding from notable investors=
 including Index Ventures, Andrej Karpathy, and Fei-Fei Li.</strong><span> =
Commenters highlight the potential of Simile&#8217;s technology to revoluti=
onize decision-making processes, comparing it to Asimov&#8217;s concept of =
Psychohistory. The involvement of prominent figures like Karpathy and Fei-F=
ei Li lends credibility to the project, suggesting it is not merely specula=
tive.</span></p><ul style=3D"margin-top: 0;padding: 0;"><li style=3D"margin=
: 8px 0 0 32px;mso-special-format: bullet;"><p style=3D"color: rgb(54,55,55=
);line-height: 26px;margin-bottom: 0;box-sizing: border-box;padding-left: 4=
px;font-size: 16px;margin: 0;"><span>Rare-Site highlights the contrast betw=
een the rigorous testing in software development, such as A/B testing for U=
I elements, and the often intuitive decision-making in economic policies. T=
hey emphasize the potential of Simile to revolutionize decision-making by s=
imulating reality, especially with the backing of prominent figures like </=
span><strong>Karpathy</strong><span> and </span><strong>Fei-Fei Li</strong>=
<span>. This could represent a significant advancement in AI capabilities.<=
/span></p></li><li style=3D"margin: 8px 0 0 32px;mso-special-format: bullet=
;"><p style=3D"color: rgb(54,55,55);line-height: 26px;margin-bottom: 0;box-=
sizing: border-box;padding-left: 4px;font-size: 16px;margin: 0;">Embarrasse=
dRing7806 raises a concern about the competitive landscape, questioning the=
 ability of Simile to maintain a competitive advantage or &#8216;moat&#8217=
;. They reference a similar project, Aaru, suggesting that the field of sim=
ulation technology might be crowded or rapidly evolving, which could impact=
 Simile&#8217;s unique positioning.</p></li><li style=3D"margin: 8px 0 0 32=
px;mso-special-format: bullet;"><p style=3D"color: rgb(54,55,55);line-heigh=
t: 26px;margin-bottom: 0;box-sizing: border-box;padding-left: 4px;font-size=
: 16px;margin: 0;">The_Scout1255 expresses surprise at the emergence of sim=
ulation technology this year, indicating that the development of such advan=
ced simulation capabilities was unexpected in the current timeline. This su=
ggests a rapid pace of innovation in the field, potentially driven by recen=
t advancements in AI and computational power.</p></li></ul></li><li style=
=3D"margin: 8px 0 0 32px;mso-special-format: bullet;"><p style=3D"margin: 0=
 0 20px 0;color: rgb(54,55,55);line-height: 26px;margin-bottom: 0;box-sizin=
g: border-box;padding-left: 4px;font-size: 16px;"><strong><a href=3D"https:=
//substack.com/redirect/5e12095f-48e7-4ce3-ad2b-4cf5da8c3017?j=3DeyJ1IjoiYn=
BkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"col=
or: #9333ea;text-decoration: none;">Lead product + design at Google AI Stud=
io promises &#8220;something even better&#8221; than Gemini 3 Pro GA this w=
eek</a></strong><span> (Activity: 626): </span><strong>The image captures a=
 social media exchange where a lead from Google AI Studio hints at an upcom=
ing release that is expected to surpass the anticipated Gemini 3 Pro GA. Th=
is suggests that Google may be preparing to unveil a new product or feature=
 that could potentially include advanced capabilities, possibly related to =
coding agents, as speculated by users. The discussion reflects a high level=
 of anticipation and excitement within the community for Google&#8217;s nex=
t move in AI development.</strong><span> One comment suggests that Google n=
eeds a product similar to Codex, as Gemini 3 Pro reportedly lacks effective=
 agentic features. This indicates a demand for more advanced AI functionali=
ties from Google.</span></p><ul style=3D"margin-top: 0;padding: 0;"><li sty=
le=3D"margin: 8px 0 0 32px;mso-special-format: bullet;"><p style=3D"color: =
rgb(54,55,55);line-height: 26px;margin-bottom: 0;box-sizing: border-box;pad=
ding-left: 4px;font-size: 16px;margin: 0;">Impressive-Zebra1505 highlights =
a critical gap in Google&#8217;s AI capabilities, noting that &#8220;Google=
 needs something akin to Codex ASAP,&#8221; as Gemini 3 Pro struggles with =
agentic features. This suggests a potential area for improvement or innovat=
ion in Google&#8217;s AI offerings, particularly in enhancing the model&#82=
17;s ability to handle tasks autonomously, similar to OpenAI&#8217;s Codex.=
</p></li><li style=3D"margin: 8px 0 0 32px;mso-special-format: bullet;"><p =
style=3D"color: rgb(54,55,55);line-height: 26px;margin-bottom: 0;box-sizing=
: border-box;padding-left: 4px;font-size: 16px;margin: 0;"><span>Hemingbird=
 discusses a </span><em>New Yorker</em><span> article that provides an in-d=
epth look at Anthropic and its AI model, Claude. The article is praised for=
 its nuanced understanding of AI, particularly in differentiating next-toke=
n prediction from simple autocomplete. It also explores the role of &#8216;=
AI psychonauts&#8217; in model interpretability, highlighting the diverse a=
nd sometimes unconventional approaches to understanding AI behavior.</span>=
</p></li><li style=3D"margin: 8px 0 0 32px;mso-special-format: bullet;"><p =
style=3D"color: rgb(54,55,55);line-height: 26px;margin-bottom: 0;box-sizing=
: border-box;padding-left: 4px;font-size: 16px;margin: 0;">kvothe5688 specu=
lates that the upcoming announcement from Google AI Studio might involve a =
&#8220;rumoured coding agent.&#8221; This aligns with the broader industry =
trend of integrating more sophisticated coding capabilities into AI models,=
 potentially addressing the limitations noted in Gemini 3 Pro&#8217;s curre=
nt functionalities.</p></li></ul></li><li style=3D"margin: 8px 0 0 32px;mso=
-special-format: bullet;"><p style=3D"margin: 0 0 20px 0;color: rgb(54,55,5=
5);line-height: 26px;margin-bottom: 0;box-sizing: border-box;padding-left: =
4px;font-size: 16px;"><strong><a href=3D"https://substack.com/redirect/e3d3=
f6e2-02aa-400b-a6ec-96b2c3db6041?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34Ce=
FwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-decoration:=
 none;">How is this not the biggest news right now?</a></strong><span> (Act=
ivity: 865): </span><strong>Google has developed a math-specialized version=
 of its AI model, named Aletheia, which has achieved a perfect score on the=
 International Mathematical Olympiad (IMO) and significantly outperforms ot=
her models on various benchmarks. The image shows Aletheia leading the lead=
erboard with a </strong><code>91.9%</code><strong> score on the Advanced Pr=
oofbench and </strong><code>100%</code><strong> on the IMO 2024 category, f=
ar surpassing other models like &#8220;GPT-5.2 Thinking (high)&#8221; and &=
#8220;Gemini 3 Pro.&#8221; This model is described as a generator-verifier =
agent, which may not directly compare to traditional language models, sugge=
sting a different approach in its architecture and capabilities.</strong><s=
pan> Some commenters question the significance of this news, noting that ac=
hieving high scores on IMO with sufficient fine-tuning and resources is pos=
sible. Others highlight that Aletheia&#8217;s architecture as a generator-v=
erifier agent makes it distinct from typical language models, suggesting th=
at the leaderboard comparison might not be entirely fair.</span></p><ul sty=
le=3D"margin-top: 0;padding: 0;"><li style=3D"margin: 8px 0 0 32px;mso-spec=
ial-format: bullet;"><p style=3D"color: rgb(54,55,55);line-height: 26px;mar=
gin-bottom: 0;box-sizing: border-box;padding-left: 4px;font-size: 16px;marg=
in: 0;">Alex__007 highlights that both OpenAI and Google achieved gold at t=
he International Mathematical Olympiad (IMO) with their models, suggesting =
that with sufficient fine-tuning and inference expenditure, such results ar=
e achievable. The commenter questions the generalization of these models be=
yond specific benchmarks and inquires about the accessibility and cost of u=
sing Aletheia, indicating a need for more transparency in these areas.</p><=
/li><li style=3D"margin: 8px 0 0 32px;mso-special-format: bullet;"><p style=
=3D"color: rgb(54,55,55);line-height: 26px;margin-bottom: 0;box-sizing: bor=
der-box;padding-left: 4px;font-size: 16px;margin: 0;">Faintly_glowing_fish =
points out that the model in question is a generator-verifier agent, which =
differs from traditional language models. This distinction implies that com=
paring its performance on leaderboards with standard language models might =
be misleading, as they serve different purposes and operate under different=
 paradigms.</p></li><li style=3D"margin: 8px 0 0 32px;mso-special-format: b=
ullet;"><p style=3D"color: rgb(54,55,55);line-height: 26px;margin-bottom: 0=
;box-sizing: border-box;padding-left: 4px;font-size: 16px;margin: 0;">jjjjb=
aggg discusses the model&#8217;s focus and cost, suggesting it might be an =
iteration of Gemini Deepthink with extensive scaffold engineering and fine-=
tuning. They note that scaffold engineering can become obsolete as reinforc=
ement learning (RL) techniques evolve, potentially eliminating the need for=
 such scaffolding in future model generations.</p></li></ul></li><li style=
=3D"margin: 8px 0 0 32px;mso-special-format: bullet;"><p style=3D"margin: 0=
 0 20px 0;color: rgb(54,55,55);line-height: 26px;margin-bottom: 0;box-sizin=
g: border-box;padding-left: 4px;font-size: 16px;"><strong><a href=3D"https:=
//substack.com/redirect/f132835e-242d-40e6-bf3e-73db6896588a?j=3DeyJ1IjoiYn=
BkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"col=
or: #9333ea;text-decoration: none;">GLM 5 is out now.</a></strong><span> (A=
ctivity: 312): </span><strong>The image is a performance evaluation chart c=
omparing several language models, including the newly released GLM-5, again=
st others like GLM-4.7, Claude Opus 4.5, Gemini 3 Pro, and GPT-5.2 (xhigh).=
 The chart highlights GLM-5&#8217;s strong performance across various bench=
marks such as &#8220;SWE-bench Verified&#8221; and &#8220;t&#178;-Bench,&#8=
221; indicating its competitive edge in these categories. The release of GL=
M-5 is emphasized by its highlighted position in the chart, suggesting impr=
ovements over its predecessor, GLM-4.7, and competitive performance against=
 other leading models.</strong><span> One commenter criticizes the benchmar=
ks for not reflecting real-life usage, while another highlights the cost-ef=
fectiveness and efficiency of models like Oppus 4.6 over GLM-5, suggesting =
that despite GLM-5&#8217;s performance, it may not be as practical for cert=
ain tasks.</span></p><ul style=3D"margin-top: 0;padding: 0;"><li style=3D"m=
argin: 8px 0 0 32px;mso-special-format: bullet;"><p style=3D"color: rgb(54,=
55,55);line-height: 26px;margin-bottom: 0;box-sizing: border-box;padding-le=
ft: 4px;font-size: 16px;margin: 0;">SnooTangerines2270 highlights a critica=
l performance issue with GLM 5, noting that while it may be cost-effective,=
 it often leads to inefficient workflows characterized by repetitive &#8216=
;copy-paste-fix-it&#8217; cycles. They contrast this with Oppus 4.6, which =
they claim offers superior performance by understanding user intent without=
 extensive prompting, thanks to its advanced swarm agent capabilities. This=
 suggests that for users prioritizing efficiency and time savings, Oppus 4.=
6 might be a more suitable choice despite its higher cost.</p></li><li styl=
e=3D"margin: 8px 0 0 32px;mso-special-format: bullet;"><p style=3D"color: r=
gb(54,55,55);line-height: 26px;margin-bottom: 0;box-sizing: border-box;padd=
ing-left: 4px;font-size: 16px;margin: 0;">ianxiao criticizes the performanc=
e of GLM 5, stating that it operates at &#8216;unusable token/s&#8217;, imp=
lying that the model&#8217;s processing speed is insufficient for practical=
 use. This suggests that despite any potential improvements or features, th=
e model&#8217;s throughput may not meet the demands of users requiring fast=
 and efficient processing.</p></li><li style=3D"margin: 8px 0 0 32px;mso-sp=
ecial-format: bullet;"><p style=3D"color: rgb(54,55,55);line-height: 26px;m=
argin-bottom: 0;box-sizing: border-box;padding-left: 4px;font-size: 16px;ma=
rgin: 0;">stiky21 expresses a preference for Opus and Codex over GLM 5, ind=
icating a possible perception of superior performance or reliability in the=
se alternatives. This choice might reflect a broader sentiment among users =
who prioritize established models with proven track records over newer rele=
ases that may not yet have demonstrated their capabilities in real-world ap=
plications.</p></li></ul></li><li style=3D"margin: 8px 0 0 32px;mso-special=
-format: bullet;"><p style=3D"margin: 0 0 20px 0;color: rgb(54,55,55);line-=
height: 26px;margin-bottom: 0;box-sizing: border-box;padding-left: 4px;font=
-size: 16px;"><strong><a href=3D"https://substack.com/redirect/a810ebe1-129=
8-4cd0-a77b-ad44669d2237?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfA=
OkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-decoration: none;">=
Deepseek V4 is coming this week.</a></strong><span> (Activity: 385): </span=
><strong>Deepseek V4 is anticipated to release by February 17, coinciding w=
ith the Chinese New Year. The update reportedly includes the capability to =
handle </strong><code>1 million tokens</code><strong>, suggesting a signifi=
cant enhancement in processing capacity. This positions Deepseek as a compe=
titive alternative to major models like Opus, Codex, and others, potentiall=
y offering similar capabilities at a reduced cost.</strong><span> One comme=
nter highlights that Deepseek&#8217;s advancements make it a cost-effective=
 alternative to major models, suggesting that China&#8217;s development in =
AI is competitive with global leaders.</span></p><ul style=3D"margin-top: 0=
;padding: 0;"><li style=3D"margin: 8px 0 0 32px;mso-special-format: bullet;=
"><p style=3D"color: rgb(54,55,55);line-height: 26px;margin-bottom: 0;box-s=
izing: border-box;padding-left: 4px;font-size: 16px;margin: 0;"><span>A use=
r mentioned that Deepseek has been updated to handle </span><code>1M tokens=
</code><span>, suggesting a significant increase in its processing capabili=
ties. This could imply improvements in handling larger datasets or more com=
plex queries, which is a notable enhancement for users dealing with extensi=
ve data or requiring detailed analysis.</span></p></li><li style=3D"margin:=
 8px 0 0 32px;mso-special-format: bullet;"><p style=3D"color: rgb(54,55,55)=
;line-height: 26px;margin-bottom: 0;box-sizing: border-box;padding-left: 4p=
x;font-size: 16px;margin: 0;">Another user reported that after the update, =
Deepseek provided a highly nuanced and original review of a complex piece o=
f character writing. This suggests improvements in the model&#8217;s abilit=
y to understand and critique creative content, indicating advancements in i=
ts natural language processing and comprehension abilities.</p></li><li sty=
le=3D"margin: 8px 0 0 32px;mso-special-format: bullet;"><p style=3D"color: =
rgb(54,55,55);line-height: 26px;margin-bottom: 0;box-sizing: border-box;pad=
ding-left: 4px;font-size: 16px;margin: 0;">One comment highlighted a percei=
ved increase in the &#8216;personality&#8217; of Deepseek&#8217;s responses=
 post-update, comparing it to ChatGPT. This suggests enhancements in the mo=
del&#8217;s conversational abilities, potentially making interactions more =
engaging and human-like.</p></li></ul></li><li style=3D"margin: 8px 0 0 32p=
x;mso-special-format: bullet;"><p style=3D"color: rgb(54,55,55);line-height=
: 26px;margin-bottom: 0;box-sizing: border-box;padding-left: 4px;font-size:=
 16px;margin: 0;"><strong><a href=3D"https://substack.com/redirect/1f2df1aa=
-004f-4512-9f4e-a6f484cdc26c?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb=
7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-decoration: non=
e;">MiniMax-M2.5 Now First to Go Live on NetMind (Before the Official Launc=
h), Free for a Limited Time Only</a></strong><span> (Activity: 14): </span>=
<strong>MiniMax-M2.5 is now available on the NetMind platform with first-to=
-market API access, free for a limited time. This model is designed for age=
nts, supporting multilingual programming, complex tool-calling chains, and =
long-horizon planning. It surpasses Claude Opus 4.6 on SWE-bench Pro and Ve=
rified, making it one of the top models for software engineering. It also a=
chieves state-of-the-art scores in Excel manipulation, deep research, and d=
ocument summarization. With an output speed of approximately </strong><code=
>100 TPS</code><strong>, it is about </strong><code>3x faster</code><strong=
> than Opus-class models, and is priced at </strong><code>$0.3/M</code><str=
ong> input tokens and </strong><code>$1.2/M</code><strong> output tokens, m=
aking it suitable for high-volume, always-on production workloads.</strong>=
<span> A comment notes that despite the announcement, the service is paid, =
indicating potential user concerns about cost despite the initial free acce=
ss.</span></p></li></ul><h3 class=3D"header-anchor-post" style=3D"position:=
 relative;font-family: 'SF Pro Display',-apple-system-headline,system-ui,-a=
pple-system,BlinkMacSystemFont,'Segoe UI',Roboto,Helvetica,Arial,sans-serif=
,'Apple Color Emoji','Segoe UI Emoji','Segoe UI Symbol';font-weight: bold;-=
webkit-font-smoothing: antialiased;-moz-osx-font-smoothing: antialiased;-we=
bkit-appearance: optimizelegibility;-moz-appearance: optimizelegibility;app=
earance: optimizelegibility;margin: 1em 0 0.625em 0;color: rgb(54,55,55);li=
ne-height: 1.16em;font-size: 1.375em;"><strong>2. AI in Medical Diagnosis a=
nd Healthcare</strong></h3><ul style=3D"margin-top: 0;padding: 0;"><li styl=
e=3D"margin: 8px 0 0 32px;mso-special-format: bullet;"><p style=3D"color: r=
gb(54,55,55);line-height: 26px;margin-bottom: 0;box-sizing: border-box;padd=
ing-left: 4px;font-size: 16px;margin: 0;"><strong><a href=3D"https://substa=
ck.com/redirect/ff11a40f-73c4-4d8e-adb9-8accbb947d94?j=3DeyJ1IjoiYnBkbncifQ=
=2EqTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNi=
z7RTdD8x0" rel=3D"" style=3D"color: #933=
3ea;text-decoration: none;">This morning ChatGPT talked me out of toughing =
out a strain in my calf muscle and to go get it looked at because it suspec=
ted a blood clot.</a></strong><span> (Activity: 6516): </span><strong>The i=
mage and accompanying post highlight a real-life scenario where ChatGPT pla=
yed a crucial role in prompting a user to seek immediate medical attention =
for a suspected blood clot. The user initially considered ignoring a calf m=
uscle strain, but ChatGPT&#8217;s advice led them to discover a life-threat=
ening condition involving multiple blood clots in the lungs. This incident =
underscores the potential of AI tools like ChatGPT in providing timely heal=
th advice, although it should not replace professional medical consultation=
=2E The comments further illustrate sim=
ilar experiences where ChatGPT&#8217;s=
 guidance led to the discovery of serious health issues, emphasizing its ut=
ility in preliminary health assessments.</strong><span> Commenters shared s=
imilar experiences where ChatGPT&#8217;s advice led to the discovery of ser=
ious health conditions, such as heart blockages and shingles, highlighting =
the AI&#8217;s potential in preliminary health diagnostics.</span></p></li>=
<li style=3D"margin: 8px 0 0 32px;mso-special-format: bullet;"><p style=3D"=
margin: 0 0 20px 0;color: rgb(54,55,55);line-height: 26px;margin-bottom: 0;=
box-sizing: border-box;padding-left: 4px;font-size: 16px;"><strong><a href=
=3D"https://substack.com/redirect/de676362-3991-460b-9d53-c56c4d248ea2?j=3D=
eyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" st=
yle=3D"color: #9333ea;text-decoration: none;">gpt is goated as a doctor</a>=
</strong><span> (Activity: 1219): </span><strong>The post discusses using C=
hatGPT for medical diagnosis by analyzing lab reports, claiming it accurate=
ly identified conditions like Crohn&#8217;s disease, fatty liver, and a tum=
or, suggesting follow-up tests that were later confirmed by doctors. This h=
ighlights GPT&#8217;s capability in medical pattern recognition, leveraging=
 its training on extensive medical literature to perform sophisticated patt=
ern matching against documented cases and clinical correlations. It excels =
in the differential diagnosis phase, suggesting potential diagnoses and tes=
ts, but should be used as a diagnostic assistant rather than a replacement =
for doctors.</strong><span> Comments emphasize GPT&#8217;s role as a second=
 opinion tool, enhancing patient-doctor interactions by enabling informed d=
iscussions. However, caution is advised as GPT provides confident answers b=
ased on pattern matching, not true diagnosis. The potential for AI integrat=
ion in healthcare workflows is noted, suggesting it could improve diagnosti=
c efficiency and patient outcomes.</span></p><ul style=3D"margin-top: 0;pad=
ding: 0;"><li style=3D"margin: 8px 0 0 32px;mso-special-format: bullet;"><p=
 style=3D"color: rgb(54,55,55);line-height: 26px;margin-bottom: 0;box-sizin=
g: border-box;padding-left: 4px;font-size: 16px;margin: 0;"><strong>BookPas=
t8673</strong><span> highlights the effectiveness of GPT in medical pattern=
 recognition due to its training on extensive medical literature and case s=
tudies. It excels in differential diagnosis by matching symptoms and data p=
oints against a vast database of documented cases, which allows it to recal=
l rare conditions and drug interactions quickly. However, it is emphasized =
that GPT should be used as a diagnostic assistant rather than a replacement=
, as it can suggest tests but cannot interpret the full clinical picture or=
 patient history.</span></p></li><li style=3D"margin: 8px 0 0 32px;mso-spec=
ial-format: bullet;"><p style=3D"color: rgb(54,55,55);line-height: 26px;mar=
gin-bottom: 0;box-sizing: border-box;padding-left: 4px;font-size: 16px;marg=
in: 0;"><strong>BookPast8673</strong><span> also discusses the potential fo=
r AI integration into healthcare systems, suggesting that AI could act as a=
 co-pilot for doctors by flagging potential diagnoses and suggesting follow=
-up tests in real-time. This integration could reduce diagnostic delays and=
 unnecessary testing, ultimately saving time and money while improving pati=
ent outcomes. The comment underscores the importance of AI as a tool to enh=
ance, rather than replace, human medical expertise.</span></p></li></ul></l=
i></ul><h3 class=3D"header-anchor-post" style=3D"position: relative;font-fa=
mily: 'SF Pro Display',-apple-system-headline,system-ui,-apple-system,Blink=
MacSystemFont,'Segoe UI',Roboto,Helvetica,Arial,sans-serif,'Apple Color Emo=
ji','Segoe UI Emoji','Segoe UI Symbol';font-weight: bold;-webkit-font-smoot=
hing: antialiased;-moz-osx-font-smoothing: antialiased;-webkit-appearance: =
optimizelegibility;-moz-appearance: optimizelegibility;appearance: optimize=
legibility;margin: 1em 0 0.625em 0;color: rgb(54,55,55);line-height: 1.16em=
;font-size: 1.375em;"><strong>3. Gemini 3 Deep Think and ARC-AGI-2 Benchmar=
ks</strong></h3><ul style=3D"margin-top: 0;padding: 0;"><li style=3D"margin=
: 8px 0 0 32px;mso-special-format: bullet;"><p style=3D"margin: 0 0 20px 0;=
color: rgb(54,55,55);line-height: 26px;margin-bottom: 0;box-sizing: border-=
box;padding-left: 4px;font-size: 16px;"><strong><a href=3D"https://substack=
=2Ecom/redirect/c3de22e0-1785-4b8a-bdf=
8-80ff7b79b1b7?j=3DeyJ1IjoiYnBkbncifQ.q=
TvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333e=
a;text-decoration: none;">The new Gemini Deep Think incredible numbers on A=
RC-AGI-2.</a></strong><span> (Activity: 1286): </span><strong>The image pre=
sents a bar graph illustrating the performance of various AI models on the =
ARC-AGI-2 benchmark, with the Gemini 3 Deep Think model achieving a leading=
 score of </strong><code>84.6%</code><strong>. This score significantly sur=
passes other models like Claude Opus 4.6 (</strong><code>68.8%</code><stron=
g>), GPT-5.2 (</strong><code>52.9%</code><strong>), and Gemini 3 Pro Previe=
w (</strong><code>31.1%</code><strong><span>). The Gemini 3 Deep Think&#821=
7;s performance is particularly notable as it approaches the threshold for =
effectively solving the benchmark under the </span><a href=3D"https://subst=
ack.com/redirect/d6540725-e41d-4ad2-90b8-f722ce4d9680?j=3DeyJ1IjoiYnBkbncif=
Q.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #93=
33ea;text-decoration: none;">ARC Prize criteria</a><span>. Additionally, th=
e model&#8217;s Codeforces Elo rating of </span></strong><code>3455</code><=
strong> places it in the top </strong><code>0.008%</code><strong> of human =
competitors, highlighting its advanced capabilities in reasoning and knowle=
dge without the use of tools.</strong><span> Commenters are impressed by th=
e significant performance leap of the Gemini 3 Deep Think model, noting its=
 potential breakthrough in AI capabilities. The model&#8217;s high Codeforc=
es Elo rating is also highlighted as a remarkable achievement, indicating i=
ts superior problem-solving skills.</span></p><ul style=3D"margin-top: 0;pa=
dding: 0;"><li style=3D"margin: 8px 0 0 32px;mso-special-format: bullet;"><=
p style=3D"color: rgb(54,55,55);line-height: 26px;margin-bottom: 0;box-sizi=
ng: border-box;padding-left: 4px;font-size: 16px;margin: 0;"><span>FundusAn=
imae highlights the significant performance improvement of the Gemini Deep =
Think model on the ARC-AGI-2 benchmark, noting that it scores above 85%, wh=
ich is considered effectively solving the benchmark according to the </span=
><a href=3D"https://substack.com/redirect/d6540725-e41d-4ad2-90b8-f722ce4d9=
680?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=
=3D"" style=3D"color: #9333ea;text-decoration: none;">ARC Prize criteria</a=
><span>. The model&#8217;s Codeforces Elo rating of 3455 places it in the t=
op 0.008% of human competitors, which is particularly impressive given that=
 it achieved this without any tools.</span></p></li><li style=3D"margin: 8p=
x 0 0 32px;mso-special-format: bullet;"><p style=3D"color: rgb(54,55,55);li=
ne-height: 26px;margin-bottom: 0;box-sizing: border-box;padding-left: 4px;f=
ont-size: 16px;margin: 0;">Agreeable_Bike_4764 points out the rapid progres=
s of the ARC-AGI-2 model, noting that it took less than a year to reach a p=
erformance level considered as &#8216;saturation&#8217; (85% solved) since =
its release. This suggests a fast-paced development and improvement cycle i=
n AI model capabilities.</p></li></ul></li><li style=3D"margin: 8px 0 0 32p=
x;mso-special-format: bullet;"><p style=3D"margin: 0 0 20px 0;color: rgb(54=
,55,55);line-height: 26px;margin-bottom: 0;box-sizing: border-box;padding-l=
eft: 4px;font-size: 16px;"><strong><a href=3D"https://substack.com/redirect=
/1917a937-5cf7-4969-a850-783001d83e6b?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9T=
d34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-decora=
tion: none;">Google upgraded Gemini-3 DeepThink: Advancing science, researc=
h and engineering</a></strong><span> (Activity: 674): </span><strong>Google=
&#8217;s Gemini-3 DeepThink has set a new benchmark in AI performance, achi=
eving </strong><code>48.4%</code><strong> on Humanity&#8217;s Last Exam wit=
hout tools, </strong><code>84.6%</code><strong> on ARC-AGI-2 as verified by=
 the ARC Prize Foundation, and an Elo rating of </strong><code>3455</code><=
strong><span> on Codeforces. It also reached gold-medal level performance i=
n the International Math Olympiad 2025. These results highlight its advance=
d capabilities in reasoning and problem-solving across scientific domains. =
For more details, see the </span><a href=3D"https://substack.com/redirect/6=
44fc537-b3be-4eeb-aac0-b4948719369c?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td3=
4CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-decorati=
on: none;">original article</a><span>.</span></strong><span> A notable deba=
te in the comments revolves around the comparison of Gemini-3 DeepThink to =
GPT 5.2, with some users pointing out that the comparison should be made wi=
th GPT 5.2 Pro, which is a more direct competitor.</span></p><ul style=3D"m=
argin-top: 0;padding: 0;"><li style=3D"margin: 8px 0 0 32px;mso-special-for=
mat: bullet;"><p style=3D"color: rgb(54,55,55);line-height: 26px;margin-bot=
tom: 0;box-sizing: border-box;padding-left: 4px;font-size: 16px;margin: 0;"=
>SerdarCS points out a potential issue with the comparison metrics used by =
Google, noting that they are comparing Gemini-3 DeepThink to GPT-5.2 Thinki=
ng instead of GPT-5.2 Pro, which would be a more direct competitor. This su=
ggests a possible bias in the benchmarking process, as the Pro version migh=
t offer different performance characteristics that are more aligned with Ge=
mini-3&#8217;s capabilities.</p></li><li style=3D"margin: 8px 0 0 32px;mso-=
special-format: bullet;"><p style=3D"color: rgb(54,55,55);line-height: 26px=
;margin-bottom: 0;box-sizing: border-box;padding-left: 4px;font-size: 16px;=
margin: 0;">brett_baty_is_him inquires about specific benchmarks related to=
 Gemini-3 DeepThink, particularly focusing on Software Engineering (SWE) be=
nchmarks and long context benchmarks. This indicates a need for detailed pe=
rformance metrics to evaluate the model&#8217;s capabilities in handling co=
mplex engineering tasks and extended context scenarios, which are critical =
for assessing its utility in technical applications.</p></li><li style=3D"m=
argin: 8px 0 0 32px;mso-special-format: bullet;"><p style=3D"color: rgb(54,=
55,55);line-height: 26px;margin-bottom: 0;box-sizing: border-box;padding-le=
ft: 4px;font-size: 16px;margin: 0;">verysecreta expresses confusion over th=
e naming conventions used for Gemini-3 DeepThink, comparing it to other mod=
els like &#8220;Flash&#8221; and &#8220;Pro&#8221;. The comment highlights =
the ambiguity in distinguishing whether &#8220;Deep Think&#8221; is a separ=
ate model or a mode within the existing Gemini framework. This reflects a b=
roader issue in AI model branding and clarity, which can impact user unders=
tanding and adoption.</p></li></ul></li><li style=3D"margin: 8px 0 0 32px;m=
so-special-format: bullet;"><p style=3D"margin: 0 0 20px 0;color: rgb(54,55=
,55);line-height: 26px;margin-bottom: 0;box-sizing: border-box;padding-left=
: 4px;font-size: 16px;"><strong><a href=3D"https://substack.com/redirect/e5=
5f3b87-abf4-42f2-8422-85699f4498ac?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34=
CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-decoratio=
n: none;">Google Just Dropped Gemini 3 &#8220;Deep Think&#8221; : and its I=
nsane.</a></strong><span> (Activity: 844): </span><strong><span>Google has =
released Gemini 3 &#8216;Deep Think&#8217;, an advanced AI model noted for =
its exceptional capabilities in reasoning, coding, and science, comparable =
to Olympiad-level performance. It is already being applied in practical sce=
narios, such as semiconductor material design at Duke University. The model=
 has also achieved a new benchmark by solving PhD-level math and physics pr=
oblems, showcasing its potential in academic and research settings. </span>=
<a href=3D"https://substack.com/redirect/17cd3292-7425-43b5-99e3-6d7a599db0=
7d?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=
=3D"" style=3D"color: #9333ea;text-decoration: none;">Image</a></strong><sp=
an> Some users express concern over the high cost of accessing Gemini 3, wh=
ich is priced at </span><code>$270</code><span> per month with a limit of <=
/span><code>10 messages</code><span> per day, suggesting that its use may b=
e restricted to those who can afford such a premium service.</span></p><ul =
style=3D"margin-top: 0;padding: 0;"><li style=3D"margin: 8px 0 0 32px;mso-s=
pecial-format: bullet;"><p style=3D"color: rgb(54,55,55);line-height: 26px;=
margin-bottom: 0;box-sizing: border-box;padding-left: 4px;font-size: 16px;m=
argin: 0;"><span>TechNerd10191 highlights the restrictive nature of Gemini =
3&#8217;s pricing model, which costs </span><code>$270</code><span> per mon=
th and limits users to </span><code>10 messages per day</code><span>. This =
is contrasted with ChatGPT Pro, which offers </span><code>100+</code><span>=
 messages on its </span><code>5.2 Pro</code><span> version, suggesting a si=
gnificant limitation for users who require extensive interaction with the m=
odel.</span></p></li><li style=3D"margin: 8px 0 0 32px;mso-special-format: =
bullet;"><p style=3D"color: rgb(54,55,55);line-height: 26px;margin-bottom: =
0;box-sizing: border-box;padding-left: 4px;font-size: 16px;margin: 0;"><spa=
n>NervousSWE raises concerns about the practicality of using Gemini 3 for c=
oding due to the </span><code>10 messages a day</code><span> limit. They sp=
eculate on the efficiency of the model, suggesting that if one message with=
 Gemini 3 can achieve what would take </span><code>10 messages</code><span>=
 with other models, it might still be viable for power users. This highligh=
ts a potential strategy for maximizing the limited interactions by focusing=
 on complex, high-value queries.</span></p></li><li style=3D"margin: 8px 0 =
0 32px;mso-special-format: bullet;"><p style=3D"color: rgb(54,55,55);line-h=
eight: 26px;margin-bottom: 0;box-sizing: border-box;padding-left: 4px;font-=
size: 16px;margin: 0;"><span>blondbother compares Gemini 3&#8217;s offering=
 with ChatGPT Pro, noting that the latter provides </span><code>100+</code>=
<span> messages per day on its </span><code>5.2 Pro</code><span> version. T=
his comparison underscores the limitations of Gemini 3&#8217;s </span><code=
>10 queries a day</code><span> policy, which may deter users who need more =
frequent access, especially when considering the high subscription cost.</s=
pan></p></li></ul></li></ul><div style=3D"font-size: 16px;line-height: 26px=
;"><hr style=3D"margin: 32px 0;padding: 0;height: 1px;background: rgb(0,0,0=
,.1);border: none;"></div><h1 class=3D"header-anchor-post" style=3D"positio=
n: relative;font-family: 'SF Pro Display',-apple-system-headline,system-ui,=
-apple-system,BlinkMacSystemFont,'Segoe UI',Roboto,Helvetica,Arial,sans-ser=
if,'Apple Color Emoji','Segoe UI Emoji','Segoe UI Symbol';font-weight: bold=
;-webkit-font-smoothing: antialiased;-moz-osx-font-smoothing: antialiased;-=
webkit-appearance: optimizelegibility;-moz-appearance: optimizelegibility;a=
ppearance: optimizelegibility;margin: 1em 0 0.625em 0;color: rgb(54,55,55);=
line-height: 1.16em;font-size: 2em;"><strong>AI Discord Recap</strong></h1>=
<blockquote style=3D"border-left: 4px solid #9333ea;margin: 20px 0;padding:=
 0;"><p style=3D"margin: 0 0 20px 0;color: rgb(54,55,55);margin-left: 20px;=
line-height: 26px;font-size: 16px;">A summary of Summaries of Summaries by =
gpt-5.2</p></blockquote><p style=3D"margin: 0 0 20px 0;color: rgb(54,55,55)=
;line-height: 26px;font-size: 16px;"><strong>1. GLM-5 Model Release &amp; E=
cosystem Momentum</strong></p><ul style=3D"margin-top: 0;padding: 0;"><li s=
tyle=3D"margin: 8px 0 0 32px;mso-special-format: bullet;"><p style=3D"margi=
n: 0 0 20px 0;color: rgb(54,55,55);line-height: 26px;margin-bottom: 0;box-s=
izing: border-box;padding-left: 4px;font-size: 16px;"><strong>GLM-5 Grabs t=
he Gold (Twice)</strong><span>: </span><code>GLM-5</code><span> hit </span>=
<strong>#1 among open models</strong><span> on both the </span><a href=3D"h=
ttps://substack.com/redirect/204c66c8-4cec-4a60-b24d-720ce82741e9?j=3DeyJ1I=
joiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=
=3D"color: #9333ea;text-decoration: none;">Text Arena leaderboard</a><span>=
 (score </span><strong>1452</strong><span>, on par with </span><strong>gpt-=
5.1-high</strong><span>) and the </span><a href=3D"https://substack.com/red=
irect/e1793d8e-cac7-43ca-9aa3-590c2e7c1b95?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3=
U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-d=
ecoration: none;">Code Arena leaderboard</a><span>, with Arena also pointin=
g to </span><a href=3D"https://substack.com/redirect/2a1d62fc-da7a-4487-a3b=
a-f7c36c8e89c6?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7R=
TdD8x0" rel=3D"" style=3D"color: #9333ea;text-decoration: none;">Peter Gost=
ev&#8217;s review of GLM-5 and MiniMax-M2.5</a><span>.</span></p><ul style=
=3D"margin-top: 0;padding: 0;"><li style=3D"margin: 8px 0 0 32px;mso-specia=
l-format: bullet;"><p style=3D"color: rgb(54,55,55);line-height: 26px;margi=
n-bottom: 0;box-sizing: border-box;padding-left: 4px;font-size: 16px;margin=
: 0;"><span>Engineers debated whether </span><strong>GLM-5</strong><span> t=
ilts more </span><strong>agentic</strong><span> than &#8220;general assista=
nt&#8221; (similar comparisons to MiniMax), and a separate thread noted </s=
pan><a href=3D"https://substack.com/redirect/2e8c02fb-b1b4-4fff-989b-7fe803=
31bb7c?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" =
rel=3D"" style=3D"color: #9333ea;text-decoration: none;">chat.deepseek.com<=
/a><span> &#8220;silently&#8221; feels different with no official announcem=
ent, sharpening interest in independent evals.</span></p></li></ul></li><li=
 style=3D"margin: 8px 0 0 32px;mso-special-format: bullet;"><p style=3D"mar=
gin: 0 0 20px 0;color: rgb(54,55,55);line-height: 26px;margin-bottom: 0;box=
-sizing: border-box;padding-left: 4px;font-size: 16px;"><strong>GGUF Goes B=
rrr: GLM-5 Runs Local</strong><span>: Unsloth shipped </span><strong>GLM-5 =
GGUFs</strong><span> plus a local </span><code>llama.cpp</code><span> guide=
 via </span><a href=3D"https://substack.com/redirect/2e51eaa9-424d-40f9-840=
a-d08ad48d9627?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7R=
TdD8x0" rel=3D"" style=3D"color: #9333ea;text-decoration: none;">their post=
</a><span> and the weights at </span><a href=3D"https://substack.com/redire=
ct/0a2538fa-9caa-40b8-a1f0-666975a4702a?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G=
9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-deco=
ration: none;">unsloth/GLM-5-GGUF</a><span>.</span></p><ul style=3D"margin-=
top: 0;padding: 0;"><li style=3D"margin: 8px 0 0 32px;mso-special-format: b=
ullet;"><p style=3D"color: rgb(54,55,55);line-height: 26px;margin-bottom: 0=
;box-sizing: border-box;padding-left: 4px;font-size: 16px;margin: 0;"><span=
>One user reported </span><strong>46 t/s</strong><span> with </span><strong=
>3&#215; Nvidia Blackwell RTX 6000 GPUs</strong><span>, kicking off practic=
al discussion about real-world throughput and whether GLM-5&#8217;s tuning =
targets longer-horizon tool use over chat polish.</span></p></li></ul></li>=
</ul><p style=3D"margin: 0 0 20px 0;color: rgb(54,55,55);line-height: 26px;=
font-size: 16px;"><strong>2. Agentic Coding: Speed, Long-Running Agents, an=
d New Leaderboards</strong></p><ul style=3D"margin-top: 0;padding: 0;"><li =
style=3D"margin: 8px 0 0 32px;mso-special-format: bullet;"><p style=3D"marg=
in: 0 0 20px 0;color: rgb(54,55,55);line-height: 26px;margin-bottom: 0;box-=
sizing: border-box;padding-left: 4px;font-size: 16px;"><strong>Codex Spark =
Lights the Fuse (1000 tok/s)</strong><span>: OpenAI launched </span><strong=
>GPT-5.3-Codex-Spark</strong><span> in research preview with an official po=
st, </span><a href=3D"https://substack.com/redirect/adcc2df5-2c28-41c2-bb58=
-fe50deac1411?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RT=
dD8x0" rel=3D"" style=3D"color: #9333ea;text-decoration: none;">&#8220;Intr=
oducing GPT&#8209;5.3 Codex Spark&#8221;</a><span>, plus a </span><a href=
=3D"https://substack.com/redirect/0da73b06-4762-494e-ba28-366eb8242e00?j=3D=
eyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" st=
yle=3D"color: #9333ea;text-decoration: none;">video demo</a><span> and exam=
ple CLI usage like </span><code>codex -m gpt-5.3-codex-spark --yolo -c mode=
l_reasoning_effort=3D"xhigh"</code><span>.</span></p><ul style=3D"margin-to=
p: 0;padding: 0;"><li style=3D"margin: 8px 0 0 32px;mso-special-format: bul=
let;"><p style=3D"color: rgb(54,55,55);line-height: 26px;margin-bottom: 0;b=
ox-sizing: border-box;padding-left: 4px;font-size: 16px;margin: 0;"><span>C=
ursor users highlighted </span><strong>Cerebras-backed speed</strong><span>=
 (&#8221;</span><em>the speed is just a whole new level!</em><span>&#8220;)=
, while also stressing that the real shock is fast </span><em>deployable</e=
m><span> code changes, not just token throughput.</span></p></li></ul></li>=
<li style=3D"margin: 8px 0 0 32px;mso-special-format: bullet;"><p style=3D"=
margin: 0 0 20px 0;color: rgb(54,55,55);line-height: 26px;margin-bottom: 0;=
box-sizing: border-box;padding-left: 4px;font-size: 16px;"><strong>Cursor L=
ets Agents Run Wild (&#8230;and Bills TBD)</strong><span>: Cursor shipped <=
/span><strong>long-running agents</strong><span>, and users poked around pr=
icing/limits via dev tools on </span><a href=3D"https://substack.com/redire=
ct/5df67ebc-72a9-43b4-978a-fea75b5f3bc1?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G=
9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-deco=
ration: none;">cursor.com/dashboard</a><span> while also debating </span><s=
trong>Composer 1.5</strong><span> pricing (reports like </span><strong>$3.5=
 input / $17.5 output</strong><span> in some views).</span></p><ul style=3D=
"margin-top: 0;padding: 0;"><li style=3D"margin: 8px 0 0 32px;mso-special-f=
ormat: bullet;"><p style=3D"color: rgb(54,55,55);line-height: 26px;margin-b=
ottom: 0;box-sizing: border-box;padding-left: 4px;font-size: 16px;margin: 0=
;"><span>The vibe split between excitement (</span><em>&#8220;HOW I LET CUR=
SOR LONG RUNNING AGENT RUN FOR 1 WEEK&#8221;</em><span> as a meme headline)=
 and frustration over unclear pools/limits&#8212;especially compared agains=
t cheaper/high-scoring alternatives like </span><strong>GLM-5</strong><span=
>.</span></p></li></ul></li><li style=3D"margin: 8px 0 0 32px;mso-special-f=
ormat: bullet;"><p style=3D"margin: 0 0 20px 0;color: rgb(54,55,55);line-he=
ight: 26px;margin-bottom: 0;box-sizing: border-box;padding-left: 4px;font-s=
ize: 16px;"><strong>Windsurf Turns Eval Into a Spectator Sport</strong><spa=
n>: Windsurf published an </span><strong>Arena Mode public leaderboard</str=
ong><span> with an announcement and writeup: </span><a href=3D"https://subs=
tack.com/redirect/33907c8d-04ae-45a9-81f2-2efb5487087e?j=3DeyJ1IjoiYnBkbnci=
fQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9=
333ea;text-decoration: none;">announcement</a><span>, </span><a href=3D"htt=
ps://substack.com/redirect/184f5a72-cd6a-4d24-98cf-26c969e2a0b3?j=3DeyJ1Ijo=
iYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"=
color: #9333ea;text-decoration: none;">blog analysis</a><span>, and the liv=
e </span><a href=3D"https://substack.com/redirect/b42f3cf4-d938-42f2-a609-e=
6f022f013da?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD=
8x0" rel=3D"" style=3D"color: #9333ea;text-decoration: none;">leaderboard</=
a><span>.</span></p><ul style=3D"margin-top: 0;padding: 0;"><li style=3D"ma=
rgin: 8px 0 0 32px;mso-special-format: bullet;"><p style=3D"color: rgb(54,5=
5,55);line-height: 26px;margin-bottom: 0;box-sizing: border-box;padding-lef=
t: 4px;font-size: 16px;margin: 0;"><span>They also added </span><strong>GPT=
-5.3-Codex-Spark (preview)</strong><span> into Arena Mode per </span><a hre=
f=3D"https://substack.com/redirect/70ef9762-5d49-4e61-8a74-cebbf0dde5b0?j=
=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D""=
 style=3D"color: #9333ea;text-decoration: none;">this update</a><span>, cre=
ating a new feedback loop where users compare &#8220;</span><strong>Frontie=
r</strong><span>&#8221; (e.g., </span><strong>Opus 4.6</strong><span>) vs &=
#8220;</span><strong>Fast</strong><span>&#8221; model behavior under battle=
-group constraints.</span></p></li></ul></li></ul><p style=3D"margin: 0 0 2=
0px 0;color: rgb(54,55,55);line-height: 26px;font-size: 16px;"><strong>3. G=
PU/Infra Tooling + Kernel-Gen Experiments</strong></p><ul style=3D"margin-t=
op: 0;padding: 0;"><li style=3D"margin: 8px 0 0 32px;mso-special-format: bu=
llet;"><p style=3D"margin: 0 0 20px 0;color: rgb(54,55,55);line-height: 26p=
x;margin-bottom: 0;box-sizing: border-box;padding-left: 4px;font-size: 16px=
;"><strong>torchao Trims Fat, Adds MXFP8 MoE Muscles</strong><span>: The </=
span><strong>torchao v0.16.0</strong><span> release added </span><strong>MX=
FP8 MoE building blocks</strong><span> for training with expert parallelism=
 and pushed toward </span><strong>ABI stability</strong><span>, per </span>=
<a href=3D"https://substack.com/redirect/e322acd5-00be-400b-a32e-f78e9789a0=
aa?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=
=3D"" style=3D"color: #9333ea;text-decoration: none;">release notes</a><spa=
n>.</span></p><ul style=3D"margin-top: 0;padding: 0;"><li style=3D"margin: =
8px 0 0 32px;mso-special-format: bullet;"><p style=3D"color: rgb(54,55,55);=
line-height: 26px;margin-bottom: 0;box-sizing: border-box;padding-left: 4px=
;font-size: 16px;margin: 0;"><span>The same release also </span><strong>dep=
recated older configs/less-used quantization options</strong><span>, reinfo=
rcing a &#8220;keep it lean&#8221; direction that kernel and inference folk=
s immediately map to simpler deployment surfaces.</span></p></li></ul></li>=
<li style=3D"margin: 8px 0 0 32px;mso-special-format: bullet;"><p style=3D"=
margin: 0 0 20px 0;color: rgb(54,55,55);line-height: 26px;margin-bottom: 0;=
box-sizing: border-box;padding-left: 4px;font-size: 16px;"><strong>$30k in =
5 Days: Kernel-Gen Hackathon Energy</strong><span>: GPU MODE organizers lin=
ed up </span><strong>$20&#8211;30k</strong><span> of compute for </span><st=
rong>4&#8211;5 days</strong><span> (late February) to run rapid kernel-gene=
ration experiments using models like </span><strong>Qwen3/GLM4.7 Flash</str=
ong><span>, integrating evals such as </span><strong>Kernelbot/Flashinferbe=
nch</strong><span>.</span></p><ul style=3D"margin-top: 0;padding: 0;"><li s=
tyle=3D"margin: 8px 0 0 32px;mso-special-format: bullet;"><p style=3D"color=
: rgb(54,55,55);line-height: 26px;margin-bottom: 0;box-sizing: border-box;p=
adding-left: 4px;font-size: 16px;margin: 0;"><span>They called for collabor=
ators and pointed at concrete baselines/datasets like </span><a href=3D"htt=
ps://substack.com/redirect/d0cd1759-9d59-458f-845e-4b35c7a3d04d?j=3DeyJ1Ijo=
iYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"=
color: #9333ea;text-decoration: none;">kernelbook-kimi_k2_thinking-evals-un=
ique-synthetic-prompts</a><span> plus tooling progress like </span><strong>=
NCU/Compute-Sanitizer as tool calls</strong><span> in </span><a href=3D"htt=
ps://substack.com/redirect/b4cdb7bf-6052-4ef1-8b8f-daae797cb84b?j=3DeyJ1Ijo=
iYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"=
color: #9333ea;text-decoration: none;">FlashInfer Bench docs</a><span> and =
a modularization PR: </span><a href=3D"https://substack.com/redirect/a33896=
ec-0856-4023-8e4c-865bb05f80f2?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFw=
Yb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-decoration: n=
one;">flashinfer-bench #183</a><span>.</span></p></li></ul></li><li style=
=3D"margin: 8px 0 0 32px;mso-special-format: bullet;"><p style=3D"margin: 0=
 0 20px 0;color: rgb(54,55,55);line-height: 26px;margin-bottom: 0;box-sizin=
g: border-box;padding-left: 4px;font-size: 16px;"><strong>TraceML Watches Y=
our Ranks Like a Hawk</strong><span>: An engineer shared </span><strong>Tra=
ceML</strong><span>, an OSS tool for </span><strong>PyTorch DDP</strong><sp=
an> that shows live per-rank step time/skew with ~one line of instrumentati=
on, at </span><a href=3D"https://substack.com/redirect/52d9effb-bb32-4e09-8=
8e7-c0ea1f47cb34?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz=
7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-decoration: none;">traceopt=
-ai/traceml</a><span>.</span></p><ul style=3D"margin-top: 0;padding: 0;"><l=
i style=3D"margin: 8px 0 0 32px;mso-special-format: bullet;"><p style=3D"co=
lor: rgb(54,55,55);line-height: 26px;margin-bottom: 0;box-sizing: border-bo=
x;padding-left: 4px;font-size: 16px;margin: 0;"><span>The pitch resonated b=
ecause it targets the boring-but-fatal failure mode: you </span><em>think</=
em><span> you&#8217;re scaling, but one GPU drags, and you only notice afte=
r a burned weekend.</span></p></li></ul></li></ul><p style=3D"margin: 0 0 2=
0px 0;color: rgb(54,55,55);line-height: 26px;font-size: 16px;"><strong>4. S=
earch/OCR + MCP Toolchains for Practical Agents</strong></p><ul style=3D"ma=
rgin-top: 0;padding: 0;"><li style=3D"margin: 8px 0 0 32px;mso-special-form=
at: bullet;"><p style=3D"margin: 0 0 20px 0;color: rgb(54,55,55);line-heigh=
t: 26px;margin-bottom: 0;box-sizing: border-box;padding-left: 4px;font-size=
: 16px;"><strong>Google Search MCP: No Keys, No Mercy</strong><span>: LM St=
udio users shared </span><a href=3D"https://substack.com/redirect/99f41a48-=
f1a1-49f1-bc7b-0bd381d962c3?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7=
BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-decoration: none=
;">VincentKaufmann/noapi-google-search-mcp</a><span>, a </span><strong>Goog=
le Search MCP</strong><span> built on </span><strong>Chromium Headless</str=
ong><span> that avoids API keys and supports </span><strong>YouTube transcr=
iption</strong><span>, </span><strong>Images/Lens</strong><span>, and even =
</span><strong>local OCR</strong><span>.</span></p><ul style=3D"margin-top:=
 0;padding: 0;"><li style=3D"margin: 8px 0 0 32px;mso-special-format: bulle=
t;"><p style=3D"color: rgb(54,55,55);line-height: 26px;margin-bottom: 0;box=
-sizing: border-box;padding-left: 4px;font-size: 16px;margin: 0;">The threa=
d framed this as a pragmatic &#8220;agent toolbelt&#8221; upgrade: fewer ve=
ndor dependencies, more modalities, and a clear MCP-shaped interface for pl=
ugging into LLM workflows.</p></li></ul></li><li style=3D"margin: 8px 0 0 3=
2px;mso-special-format: bullet;"><p style=3D"margin: 0 0 20px 0;color: rgb(=
54,55,55);line-height: 26px;margin-bottom: 0;box-sizing: border-box;padding=
-left: 4px;font-size: 16px;"><strong>SigLIP2 Tags 150k Photos Without an LL=
M Identity Crisis</strong><span>: For bulk image tagging, the community rec=
ommended </span><strong>SigLIP2</strong><span> via the HF blog </span><a hr=
ef=3D"https://substack.com/redirect/2c8f13cb-9eff-46d0-9ed0-4f39427f6727?j=
=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D""=
 style=3D"color: #9333ea;text-decoration: none;">&#8220;SigLIP2&#8221;</a><=
span>, specifically pointing to </span><a href=3D"https://substack.com/redi=
rect/a76f2497-7474-44fd-be7e-39b7e94960f7?j=3DeyJ1IjoiYnBkbncifQ.qTvoIDjk3U=
3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" style=3D"color: #9333ea;text-de=
coration: none;">google/siglip2-large-patch16-256</a><span> as a small(ish)=
 vision backbone for generating tags in Python.</span></p><ul style=3D"marg=
in-top: 0;padding: 0;"><li style=3D"margin: 8px 0 0 32px;mso-special-format=
: bullet;"><p style=3D"color: rgb(54,55,55);line-height: 26px;margin-bottom=
: 0;box-sizing: border-box;padding-left: 4px;font-size: 16px;margin: 0;"><s=
pan>The underlying theme: don&#8217;t overpay for a chatty multimodal LLM i=
f a focused </span><strong>vision encoder</strong><span> solves the pipelin=
e cleanly.</span></p></li></ul></li><li style=3D"margin: 8px 0 0 32px;mso-s=
pecial-format: bullet;"><p style=3D"margin: 0 0 20px 0;color: rgb(54,55,55)=
;line-height: 26px;margin-bottom: 0;box-sizing: border-box;padding-left: 4p=
x;font-size: 16px;"><strong>Granite 4 + DuckDuckGo: Cheap Search Brains</st=
rong><span>: LM Studio users reported </span><strong>Granite 4 tiny/micro</=
strong><span> models work well for web search when paired with </span><stro=
ng>DuckDuckGo&#8217;s API</strong><span>, with some asking for tooling to f=
etch and extract text from URLs.</span></p><ul style=3D"margin-top: 0;paddi=
ng: 0;"><li style=3D"margin: 8px 0 0 32px;mso-special-format: bullet;"><p s=
tyle=3D"color: rgb(54,55,55);line-height: 26px;margin-bottom: 0;box-sizing:=
 border-box;padding-left: 4px;font-size: 16px;margin: 0;">This clustered wi=
th other &#8220;build-your-own search stack&#8221; chatter (and Perplexity =
frustration elsewhere), suggesting engineers are actively reconstructing se=
arch workflows with local models + scraping/tooling.</p></li></ul></li></ul=
><p style=3D"margin: 0 0 20px 0;color: rgb(54,55,55);line-height: 26px;font=
-size: 16px;"><strong>5. Observability, Introspection, and &#8220;Show Your=
 Work&#8221; Governance</strong></p><ul style=3D"margin-top: 0;padding: 0;m=
argin-bottom: 0;"><li style=3D"margin: 8px 0 0 32px;mso-special-format: bul=
let;"><p style=3D"margin: 0 0 20px 0;color: rgb(54,55,55);line-height: 26px=
;margin-bottom: 0;box-sizing: border-box;padding-left: 4px;font-size: 16px;=
"><strong>Anthropic&#8217;s &#8220;Introspection&#8221; Paper Gets Side-Eye=
d</strong><span>: Unsloth&#8217;s research channel dug into </span><a href=
=3D"https://substack.com/redirect/5be14277-6a7d-4029-9c91-4f92a369e9b6?j=3D=
eyJ1IjoiYnBkbncifQ.qTvoIDjk3U3G9Td34CeFwYb7BfAOkO-PNiz7RTdD8x0" rel=3D"" st=
yle=3D"color: #9333ea;text-decoration: none;">Anthropic&#8217;s &#8220;Intr=
ospection&#8221; paper</a><span>, debating what counts as real </span><stro=
ng>introspection</strong><span> versus a </span><strong>redundant network</=
strong><span> that detects &#8220;abnormal&#8221; activations/weights.</spa=
n></p><ul style=3D"margin-top: 0;padding: 0;"><li style=3D"margin: 8px 0 0 =
32px;mso-special-format: bullet;"><p style=3D"color: rgb(54,55,55);line-hei=
ght: 26px;margin-bottom: 0;box-sizing: border-box;padding-left: 4px;font-si=
ze: 16px;margin: 0;"><span>One camp argued it&#8217;s basically a sensor fo=
r </span><em>weight/activation fiddling</em><span> (&#8221;</span><em>press=
ure sensor on a pressure cooker</em><span>&#8220;), while others pointed ou=
t models can detect light steering, implying some usable awareness of inter=
nal state drift.</span></p></li></ul></li><li style=3D"margin: 8px 0 0 32px=
;mso-special-format: bullet;"><p style=3D"margin: 0 0 20px 0;color: rgb(54,=
55,55);line-height: 26px;margin-bottom: 0;box-sizing: border-box;padding-le=
ft: 4px;font-size: 16px;"><strong>KOKKI v15.5 Makes Audits a First-Class Ou=
tput</strong><span>: In OpenAI&#8217;s prompt-engineering discussions, </sp=
an><strong>KOKKI v15.5</strong><span> proposed an explicit </span><strong>D=
raft &#8594; Audit</strong><span> output contract to make accountability us=
er-visible, with members noting the intentional tradeoff: higher </span><st=
rong>token usage and latency</strong><span> for </span><strong>observabilit=
y</strong><span>.</span></p><ul style=3D"margin-top: 0;padding: 0;"><li sty=
le=3D"margin: 8px 0 0 32px;mso-special-format: bullet;"><p style=3D"color: =
rgb(54,55,55);line-height: 26px;margin-bottom: 0;box-sizing: border-box;pad=
ding-left: 4px;font-size: 16px;margin: 0;"><span>The follow-on debate got c=
oncrete: if you truly want a &#8220;guarantee,&#8221; one member said it wo=
uld look like </span><em>a deterministic system, not a transformer</em><spa=
n>, so the realistic goal becomes bounded error + inspectable behavior rath=
er than binary truth.</span></p></li></ul></li></ul></div></div><div class=
=3D"container-border" style=3D"margin: 32px 0 0;width: 100%;box-sizing: bor=
der-box;border-top: 1px solid #e6e6e6;font-size: 16px;line-height: 26px;"><=
/div><div class=3D"post-cta typography markup" style=3D"--image-offset-marg=
in: -120px;font-family: 'SF Pro Display', -apple-system, system-ui, BlinkMa=
cSystemFont, 'Inter', 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Ap=
ple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol';font-weight: 400;text=
-align: initial;word-break: break-word;margin-bottom: 32px;margin: 32px 0;f=
ont-size: 16px;line-height: 26px;"><p class=3D"referrals-cta-text" style=3D=
"color: rgb(54,55,55);text-align: center;width: 90%;line-height: 26px;font-=
size: 16px;margin-top: 0;max-width: 384px;margin: auto"></p><h4 style=3D"fo=
nt-family: 'SF Pro Display',-apple-system-headline,system-ui,-apple-system,=
BlinkMacSystemFont,'Segoe UI',Roboto,Helvetica,Arial,sans-serif,'Apple Colo=
r Emoji','Segoe UI Emoji','Segoe UI Symbol';font-weight: bold;-webkit-font-=
smoothing: antialiased;-moz-osx-font-smoothing: antialiased;-webkit-appeara=
nce: optimizelegibility;-moz-appearance: optimizelegibility;appearance: opt=
imizelegibility;margin: 1em 0 0.625em 0;color: rgb(54,55,55);line-height: 1=
=2E16em;font-size: 1.125em;text-align:=20=
center">Invite your friends and earn r=
ewards</h4><div style=3D"line-height: 26px;text-align: center;font-size: 14=
px">If you enjoy Latent.Space, share it with your friends and earn rewards =
when they subscribe.</div><p style=3D"color: rgb(54,55,55);margin: 0 auto 2=
0px;text-align: center;width: 90%;line-height: 26px;font-size: 16px;"></p><=
p class=3D"cta-box" style=3D"color: rgb(54,55,55);margin: 0 auto 20px;width=
: 90%;line-height: 26px;font-size: 16px;margin-bottom: 0;text-align: center=
;margin-left: auto;margin-right: auto;"><a class=3D"button primary" role=3D=
"button" href=3D"https://substack.com/redirect/2/eyJlIjoiaHR0cHM6Ly93d3cubG=
F0ZW50LnNwYWNlL2xlYWRlcmJvYXJkP3JlZmVycmVyX3Rva2VuPWJwZG53JnI9YnBkbncmdXRtX=
2NhbXBhaWduPWVtYWlsLWxlYWRlcmJvYXJkIiwicCI6MTg3ODMyMzk3LCJzIjoxMDg0MDg5LCJm=
IjpmYWxzZSwidSI6MTk2NTk4ODQsImlhdCI6MTc3MDk3MTUwNywiZXhwIjoyMDg2NTQ3NTA3LCJ=
pc3MiOiJwdWItMCIsInN1YiI6ImxpbmstcmVkaXJlY3QifQ.Bx9E6AjZ6mFhotPi-_VEgOVpQjC=
BjoVIlDaxTzXDBaM?&utm_source=3Dsubstack&utm_medium=3Demail&utm_content=3Dpo=
stcta" style=3D"font-family: system-ui,-apple-system,BlinkMacSystemFont,'Se=
goe UI',Roboto,Helvetica,Arial,sans-serif,'Apple Color Emoji','Segoe UI Emo=
ji','Segoe UI Symbol';display: inline-block;box-sizing: border-box;cursor: =
pointer;border: none;height: 40px;border-radius: 8px;font-size: 14px;line-h=
eight: 20px;font-weight: 600;text-align: center;padding: 10px 20px;margin: =
0;opacity: 1;outline: none;white-space: nowrap;color: #ffffff !important;te=
xt-decoration: none !important;background-color: #9333ea;">Invite Friends</=
a></p></div><table class=3D"email-ufi-2-bottom" role=3D"presentation" width=
=3D"100%" border=3D"0" cellspacing=3D"0" cellpadding=3D"0" style=3D"border-=
top: 1px solid rgb(0,0,0,.1);border-bottom: 1px solid rgb(0,0,0,.1);min-wid=
th: 100%;"><tbody><tr height=3D"16"><td height=3D"16" style=3D"font-size:0p=
x;line-height:0;">&nbsp;</td></tr><tr><td><table role=3D"presentation" widt=
h=3D"100%" border=3D"0" cellspacing=3D"0" cellpadding=3D"0"><tbody><tr><td>=
<table role=3D"presentation" width=3D"auto" border=3D"0" cellspacing=3D"0" =
cellpadding=3D"0" style=3D"margin:0 auto;"><tbody><tr><td style=3D"vertical=
-align:middle;"><table role=3D"presentation" width=3D"auto" border=3D"0" ce=
llspacing=3D"0" cellpadding=3D"0"><tbody><tr><td align=3D"center"><a class=
=3D"email-button-outline" href=3D"https://substack.com/app-link/post?public=
ation_id=3D1084089&post_id=3D187832397&utm_source=3Dsubstack&isFreemail=3Df=
alse&submitLike=3Dtrue&token=3DeyJ1c2VyX2lkIjoxOTY1OTg4NCwicG9zdF9pZCI6MTg3=
ODMyMzk3LCJyZWFjdGlvbiI6IuKdpCIsImlhdCI6MTc3MDk3MTUwNywiZXhwIjoxNzczNTYzNTA=
3LCJpc3MiOiJwdWItMTA4NDA4OSIsInN1YiI6InJlYWN0aW9uIn0.YTkvzf0JRLaIwH4Env4ASq=
Q-VRQiudvsmBnk7MtR4Jg&utm_medium=3Demail&utm_campaign=3Demail-reaction&r=3D=
bpdnw" style=3D"font-family: system-ui,-apple-system,BlinkMacSystemFont,'Se=
goe UI',Roboto,Helvetica,Arial,sans-serif,'Apple Color Emoji','Segoe UI Emo=
ji','Segoe UI Symbol';display: inline-block;font-weight: 500;border: 1px so=
lid rgb(0,0,0,.1);border-radius: 9999px;text-transform: uppercase;font-size=
: 12px;line-height: 12px;padding: 9px 14px;text-decoration: none;color: rgb=
(119,119,119);"><img class=3D"icon" src=3D"https://substackcdn.com/image/fe=
tch/$s_!PeVs!,w_36,c_scale,f_png,q_auto:good,fl_progressive:steep/https%3A%=
2F%2Fsubstack.com%2Ficon%2FLucideHeart%3Fv%3D4%26height%3D36%26fill%3Dnone%=
26stroke%3D%2523808080%26strokeWidth%3D2" width=3D"18" height=3D"18" style=
=3D"margin-right: 8px;min-width: 18px;min-height: 18px;border: none;vertica=
l-align: middle;max-width: 18px" alt=3D""><span class=3D"email-button-text"=
 style=3D"vertical-align: middle;">Like</span></a></td></tr></tbody></table=
></td><td width=3D"8" style=3D"min-width:8px;"></td><td style=3D"vertical-a=
lign:middle;"><table role=3D"presentation" width=3D"auto" border=3D"0" cell=
spacing=3D"0" cellpadding=3D"0"><tbody><tr><td align=3D"center"><a class=3D=
"email-button-outline" href=3D"https://substack.com/app-link/post?publicati=
on_id=3D1084089&post_id=3D187832397&utm_source=3Dsubstack&utm_medium=3Demai=
l&isFreemail=3Dfalse&comments=3Dtrue&token=3DeyJ1c2VyX2lkIjoxOTY1OTg4NCwicG=
9zdF9pZCI6MTg3ODMyMzk3LCJpYXQiOjE3NzA5NzE1MDcsImV4cCI6MTc3MzU2MzUwNywiaXNzI=
joicHViLTEwODQwODkiLCJzdWIiOiJwb3N0LXJlYWN0aW9uIn0.7cmmM-ac6vM7ZE2t7YDtv0GQ=
MsUxVZCaKFPhjpXzjbY&r=3Dbpdnw&utm_campaign=3Demail-half-magic-comments&acti=
on=3Dpost-comment&utm_source=3Dsubstack&utm_medium=3Demail" style=3D"font-f=
amily: system-ui,-apple-system,BlinkMacSystemFont,'Segoe UI',Roboto,Helveti=
ca,Arial,sans-serif,'Apple Color Emoji','Segoe UI Emoji','Segoe UI Symbol';=
display: inline-block;font-weight: 500;border: 1px solid rgb(0,0,0,.1);bord=
er-radius: 9999px;text-transform: uppercase;font-size: 12px;line-height: 12=
px;padding: 9px 14px;text-decoration: none;color: rgb(119,119,119);"><img c=
lass=3D"icon" src=3D"https://substackcdn.com/image/fetch/$s_!x1tS!,w_36,c_s=
cale,f_png,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack.com%2Fic=
on%2FLucideComments%3Fv%3D4%26height%3D36%26fill%3Dnone%26stroke%3D%2523808=
080%26strokeWidth%3D2" width=3D"18" height=3D"18" style=3D"margin-right: 8p=
x;min-width: 18px;min-height: 18px;border: none;vertical-align: middle;max-=
width: 18px" alt=3D""><span class=3D"email-button-text" style=3D"vertical-a=
lign: middle;">Comment</span></a></td></tr></tbody></table></td><td width=
=3D"8" style=3D"min-width:8px;"></td><td style=3D"vertical-align:middle;"><=
table role=3D"presentation" width=3D"auto" border=3D"0" cellspacing=3D"0" c=
ellpadding=3D"0"><tbody><tr><td align=3D"center"><a class=3D"email-button-o=
utline" href=3D"https://substack.com/redirect/2/eyJlIjoiaHR0cHM6Ly9vcGVuLnN=
1YnN0YWNrLmNvbS9wdWIvc3d5eC9wL2FpbmV3cy1uZXctZ2VtaW5pLTMtZGVlcC10aGluay1hbn=
Rocm9waWM_dXRtX3NvdXJjZT1zdWJzdGFjayZ1dG1fbWVkaXVtPWVtYWlsJnV0bV9jYW1wYWlnb=
j1lbWFpbC1yZXN0YWNrLWNvbW1lbnQmYWN0aW9uPXJlc3RhY2stY29tbWVudCZyPWJwZG53JnRv=
a2VuPWV5SjFjMlZ5WDJsa0lqb3hPVFkxT1RnNE5Dd2ljRzl6ZEY5cFpDSTZNVGczT0RNeU16azN=
MQ0pwWVhRaU9qRTNOekE1TnpFMU1EY3NJbVY0Y0NJNk1UYzNNelUyTXpVd055d2lhWE56SWpvaW=
NIVmlMVEV3T0RRd09Ea2lMQ0p6ZFdJaU9pSndiM04wTFhKbFlXTjBhVzl1SW4wLjdjbW1NLWFjN=
nZNN1pFMnQ3WUR0djBHUU1zVXhWWkNhS0ZQaGpwWHpqYlkiLCJwIjoxODc4MzIzOTcsInMiOjEw=
ODQwODksImYiOmZhbHNlLCJ1IjoxOTY1OTg4NCwiaWF0IjoxNzcwOTcxNTA3LCJleHAiOjIwODY=
1NDc1MDcsImlzcyI6InB1Yi0wIiwic3ViIjoibGluay1yZWRpcmVjdCJ9.mh3sqZU00zvcdJPHb=
oKHz5mBYYsp7Ctg8B3zrbdEDVs?&utm_source=3Dsubstack&utm_medium=3Demail" style=
=3D"font-family: system-ui,-apple-system,BlinkMacSystemFont,'Segoe UI',Robo=
to,Helvetica,Arial,sans-serif,'Apple Color Emoji','Segoe UI Emoji','Segoe U=
I Symbol';display: inline-block;font-weight: 500;border: 1px solid rgb(0,0,=
0,.1);border-radius: 9999px;text-transform: uppercase;font-size: 12px;line-=
height: 12px;padding: 9px 14px;text-decoration: none;color: rgb(119,119,119=
);"><img class=3D"icon" src=3D"https://substackcdn.com/image/fetch/$s_!5EGt=
!,w_36,c_scale,f_png,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstac=
k.com%2Ficon%2FNoteForwardIcon%3Fv%3D4%26height%3D36%26fill%3Dnone%26stroke=
%3D%2523808080%26strokeWidth%3D2" width=3D"18" height=3D"18" style=3D"margi=
n-right: 8px;min-width: 18px;min-height: 18px;border: none;vertical-align: =
middle;max-width: 18px" alt=3D""><span class=3D"email-button-text" style=3D=
"vertical-align: middle;">Restack</span></a></td></tr></tbody></table></td>=
</tr></tbody></table></td><td align=3D"right"><table role=3D"presentation" =
width=3D"auto" border=3D"0" cellspacing=3D"0" cellpadding=3D"0"><tbody><tr>=
</tr></tbody></table></td></tr></tbody></table></td></tr><tr height=3D"16">=
<td height=3D"16" style=3D"font-size:0px;line-height:0;">&nbsp;</td></tr></=
tbody></table><div class=3D"footer footer-ZM59BM" style=3D"color: rgb(119,1=
19,119);text-align: center;font-size: 16px;line-height: 26px;padding: 24px0=
;"><div style=3D"font-size: 16px;line-height: 26px;padding-bottom: 24px"><p=
 class=3D"pencraft pc-reset color-secondary-ls1g8s size-12-mmZ61m reset-Ixi=
VJZ small meta-B2bqa5" style=3D"list-style: none;font-family: system-ui,-ap=
ple-system,BlinkMacSystemFont,'Segoe UI',Roboto,Helvetica,Arial,sans-serif,=
'Apple Color Emoji','Segoe UI Emoji','Segoe UI Symbol';padding-bottom: 0;fo=
nt-size: 12px;line-height: 16px;margin: 0;color: rgb(119,119,119);text-deco=
ration: unset;">&#169; 2026 <span>Latent.Space</span><br>548 Market Street =
PMB 72296, San Francisco, CA 94104 <br><a href=3D"https://substack.com/redi=
rect/2/eyJlIjoiaHR0cHM6Ly93d3cubGF0ZW50LnNwYWNlL2FjdGlvbi9kaXNhYmxlX2VtYWls=
P3Rva2VuPWV5SjFjMlZ5WDJsa0lqb3hPVFkxT1RnNE5Dd2ljRzl6ZEY5cFpDSTZNVGczT0RNeU1=
6azNMQ0pwWVhRaU9qRTNOekE1TnpFMU1EY3NJbVY0Y0NJNk1UZ3dNalV3TnpVd055d2lhWE56SW=
pvaWNIVmlMVEV3T0RRd09Ea2lMQ0p6ZFdJaU9pSmthWE5oWW14bFgyVnRZV2xzSW4wLjU4a2t4N=
1lsV21Md2R1SjJ3MndZQjJpRW9fRElWQWhzdGd4bDNfdmkzQTAiLCJwIjoxODc4MzIzOTcsInMi=
OjEwODQwODksImYiOmZhbHNlLCJ1IjoxOTY1OTg4NCwiaWF0IjoxNzcwOTcxNTA3LCJleHAiOjI=
wODY1NDc1MDcsImlzcyI6InB1Yi0wIiwic3ViIjoibGluay1yZWRpcmVjdCJ9.qKzRK1geY2Ei4=
xq9HZ7Rb_Uky73JAfsgahPOxxT3ov4?" style=3D"color: #9333ea;text-decoration: n=
one;"><span style=3D"color: rgb(119,119,119);text-decoration: underline;">U=
nsubscribe</span></a></p></div><p class=3D"footerSection-EHR0jG small power=
ed-by-substack" style=3D"padding: 0 24px;font-size: 12px;line-height: 20px;=
margin: 0;color: rgb(119,119,119);font-family: system-ui,-apple-system,Blin=
kMacSystemFont,'Segoe UI',Roboto,Helvetica,Arial,sans-serif,'Apple Color Em=
oji','Segoe UI Emoji','Segoe UI Symbol';padding-bottom: 0;margin-top: 0;"><=
a href=3D"https://substack.com/redirect/2/eyJlIjoiaHR0cHM6Ly9zdWJzdGFjay5jb=
20vc2lnbnVwP3V0bV9zb3VyY2U9c3Vic3RhY2smdXRtX21lZGl1bT1lbWFpbCZ1dG1fY29udGVu=
dD1mb290ZXImdXRtX2NhbXBhaWduPWF1dG9maWxsZWQtZm9vdGVyJmZyZWVTaWdudXBFbWFpbD1=
nZW9yZ2Vja0BnbWFpbC5jb20mcj1icGRudyIsInAiOjE4NzgzMjM5NywicyI6MTA4NDA4OSwiZi=
I6ZmFsc2UsInUiOjE5NjU5ODg0LCJpYXQiOjE3NzA5NzE1MDcsImV4cCI6MjA4NjU0NzUwNywia=
XNzIjoicHViLTAiLCJzdWIiOiJsaW5rLXJlZGlyZWN0In0.ULDBJzMegzPWBJN4Y25quAJjb-K9=
CQbjoHgjxT3SBkg?" style=3D"color: #9333ea;text-decoration: none;display: in=
line-block;margin: 0 4px;"><img src=3D"https://substackcdn.com/image/fetch/=
$s_!LkrL!,w_270,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F=
%2Fsubstack.com%2Fimg%2Femail%2Fpublish-button%402x.png" srcset=3D"https://=
substackcdn.com/image/fetch/$s_!wgfj!,w_135,c_limit,f_auto,q_auto:good,fl_p=
rogressive:steep/https%3A%2F%2Fsubstack.com%2Fimg%2Femail%2Fpublish-button.=
png, https://substackcdn.com/image/fetch/$s_!LkrL!,w_270,c_limit,f_auto,q_a=
uto:good,fl_progressive:steep/https%3A%2F%2Fsubstack.com%2Fimg%2Femail%2Fpu=
blish-button%402x.png 2x, https://substackcdn.com/image/fetch/$s_!KjtY!,w_4=
05,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack.c=
om%2Fimg%2Femail%2Fpublish-button%403x.png 3x" width=3D"135" alt=3D"Start w=
riting" height=3D"40" style=3D"max-width: 550px;border: none !important;ver=
tical-align: middle;"></a></p></div></div></td><td></td></tr></tbody></tabl=
e><img src=3D"https://eotrx.substackcdn.com/open?token=3DeyJtIjoiPDIwMjYwMj=
EzMDgyOTE5LjMuOTJlMGFkYWVlMjdjOWFmMUBtZzEuc3Vic3RhY2suY29tPiIsInUiOjE5NjU5O=
Dg0LCJyIjoiZ2VvcmdlY2tAZ21haWwuY29tIiwiZCI6Im1nMS5zdWJzdGFjay5jb20iLCJwIjox=
ODc4MzIzOTcsInQiOiJuZXdzbGV0dGVyIiwiYSI6Im9ubHlfcGFpZCIsInMiOjEwODQwODksImM=
iOiJwb3N0IiwiZiI6ZmFsc2UsInBvc2l0aW9uIjoiYm90dG9tIiwiaWF0IjoxNzcwOTcxNTA3LC=
JleHAiOjE3NzM1NjM1MDcsImlzcyI6InB1Yi0wIiwic3ViIjoiZW8ifQ.k6GM1dCZWu74US5eRC=
njBp2QtTi0B2B1KidMPsVaUws" alt=3D"" width=3D"1" height=3D"1" border=3D"0" s=
tyle=3D"height:1px !important;width:1px !important;border-width:0 !importan=
t;margin-top:0 !important;margin-bottom:0 !important;margin-right:0 !import=
ant;margin-left:0 !important;padding-top:0 !important;padding-bottom:0 !imp=
ortant;padding-right:0 !important;padding-left:0 !important;"/><img width=
=3D"1" height=3D"1" alt=3D"" src=3D"https://email.mg1.substack.com/o/eJxEkE=
2O8yAMQE9TlhF_CbDgLJEBJx9qAhGYr5Pbj9ouZvuebD07AuFe2-2v2oklz42MJjD0whjujJi5Z=
XhCPtYdCzYgTCvQnzVOW_bPz-hUEKAXvZlgYd50UptAZ1Va1GYiy15yuXApFLfSCTepyUnkkABR=
muhgEw_Nz11MfYROEJ9TrCd7V60wUsYS0ddy3OsFOX15Tl5YY5VUznwJ3Rf6gq9-IBE2do2wxnq=
eo2S6VywQDkye2sC3OnIEyrV8FnGruXWs-R1r2zE-H5rv78M_HX2EVE_IxffX_cPo-67RsX2G3T=
I7azX77-VvAAAA__9dy27h"></body></html>
--53a1463f4835e6c56d10f4540ea2eec91d48eb51fa39e619ffccc2456a84--
